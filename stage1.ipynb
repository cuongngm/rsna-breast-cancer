{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba3e14b-13bf-4b4d-bad3-598b4785f6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare image, mask from 206 segmentations data\n",
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import time\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "import pydicom\n",
    "import numpy as np\n",
    "\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from monai.transforms import Resize\n",
    "\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "import torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.cuda.amp as amp\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d745bb17-a2dc-4257-9836-dd1bae12bdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    image_sizes = [128, 128, 128]\n",
    "    backbone = 'resnet18'\n",
    "    drop_rate = 0.\n",
    "    drop_path_rate = 0.\n",
    "    n_blocks = 4\n",
    "    out_dim = 5\n",
    "    loss_weights = [1, 1]\n",
    "    init_lr = 3e-3\n",
    "    batch_size = 4\n",
    "    num_workers = 4\n",
    "    n_epochs = 1000\n",
    "    device = torch.device('cuda')\n",
    "    p_mixup = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73a2258a-fe28-4d1f-8adf-8aa0d0c5483a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dicom(path):\n",
    "    dicom = pydicom.read_file(path)\n",
    "    data = dicom.pixel_array\n",
    "    data = cv2.resize(data, (CFG.image_sizes[0], CFG.image_sizes[1]), interpolation = cv2.INTER_LINEAR)\n",
    "    return data\n",
    "\n",
    "def standardize_pixel_array(dcm: pydicom.dataset.FileDataset) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Source : https://www.kaggle.com/competitions/rsna-2023-abdominal-trauma-detection/discussion/427217\n",
    "    \"\"\"\n",
    "    # Correct DICOM pixel_array if PixelRepresentation == 1.\n",
    "    pixel_array = dcm.pixel_array\n",
    "    if dcm.PixelRepresentation == 1:\n",
    "        bit_shift = dcm.BitsAllocated - dcm.BitsStored\n",
    "        dtype = pixel_array.dtype \n",
    "        pixel_array = (pixel_array << bit_shift).astype(dtype) >>  bit_shift\n",
    "#         pixel_array = pydicom.pixel_data_handlers.util.apply_modality_lut(new_array, dcm)\n",
    "\n",
    "    intercept = float(dcm.RescaleIntercept)\n",
    "    slope = float(dcm.RescaleSlope)\n",
    "    center = int(dcm.WindowCenter)\n",
    "    width = int(dcm.WindowWidth)\n",
    "    low = center - width / 2\n",
    "    high = center + width / 2    \n",
    "    \n",
    "    pixel_array = (pixel_array * slope) + intercept\n",
    "    pixel_array = np.clip(pixel_array, low, high)\n",
    "\n",
    "    return pixel_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c653f3db-330f-4489-b907-e293adff5916",
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(f\"data/stage2\").mkdir(parents=True, exist_ok=True)\n",
    "Path(f\"data/stage2/image\").mkdir(parents=True, exist_ok=True)\n",
    "Path(f\"data/stage2/mask\").mkdir(parents=True, exist_ok=True)\n",
    "seg_path = 'data/segmentations/'\n",
    "src_data = 'data/train_images'\n",
    "df = pd.read_parquet(\"data/train_dicom_tags.parquet\")\n",
    "df['StudyInstanceUID'] = df['SeriesInstanceUID'].apply(lambda x: x.split('.')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "832767a0-2fd9-462e-bdd4-b961223733e3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tqdm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m dataframe_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, filename \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtqdm\u001b[49m(\u001b[38;5;28menumerate\u001b[39m(os\u001b[38;5;241m.\u001b[39mlistdir(seg_path))):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m idx \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m10\u001b[39m:\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tqdm' is not defined"
     ]
    }
   ],
   "source": [
    "dataframe_list = []\n",
    "for idx, filename in tqdm(enumerate(os.listdir(seg_path))):\n",
    "    if idx > 10:\n",
    "        break\n",
    "    ex_path = os.path.join(seg_path, filename)\n",
    "    print(ex_path)\n",
    "    mask_org = nib.load(ex_path)\n",
    "    mask_org = mask_org.get_fdata()\n",
    "    mask_org = mask_org.transpose(1, 0, 2)[::-1, :, ::-1] # (d, w, h)\n",
    "  \n",
    "    shape = mask_org.shape\n",
    "    mask = np.zeros((5, shape[0], shape[1], shape[2]))\n",
    "    for cid in range(5):\n",
    "        mask[cid] = (mask_org == (cid + 1))\n",
    "    mask = mask.astype(np.uint8) * 255\n",
    "    mask = Resize(CFG.image_sizes)(mask).numpy()\n",
    "    \n",
    "    study_id = filename.split('.')[0]\n",
    "    row = df[df['StudyInstanceUID'] == study_id]\n",
    "    patient_id = row['PatientID'].unique().tolist()\n",
    "    assert len(patient_id) == 1, \"the study should be of a patient\"\n",
    "    patient_id = str(patient_id[0])\n",
    "\n",
    "    train_image_path = glob(f\"{src_data}/{patient_id}/{study_id}/*\")\n",
    "    train_image_path = sorted(train_image_path, key=lambda x:int(x.split(\"/\")[-1].replace(\".dcm\", \"\")))\n",
    "    n_scans = len(train_image_path)\n",
    "   \n",
    "    indices = np.quantile(list(range(n_scans)), np.linspace(0., 1., CFG.image_sizes[2])).round().astype(int)\n",
    "\n",
    "    t_paths = [train_image_path[i] for i in indices]\n",
    "    images = []\n",
    "    # old code\n",
    "    for filename in t_paths:\n",
    "        images.append(load_dicom(filename))\n",
    "    images = np.stack(images, -1)\n",
    "    images = images - np.min(images)\n",
    "    images = images / (np.max(images) + 1e-4)\n",
    "    images = (images * 255).astype(np.uint8)\n",
    "    \n",
    "    \n",
    "    image_save_path = f\"data/stage2/image/{study_id}.npy\"\n",
    "    mask_save_path = f\"data/stage2/mask/{study_id}.npy\"\n",
    "    np.save(image_save_path, images)\n",
    "    np.save(mask_save_path, mask)\n",
    "    dataframe_list.append([study_id, image_save_path, mask_save_path])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3068e2e9-7052-4d20-bda1-7c3b9a86216c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['6575', 'data/stage2/image/6575.npy', 'data/stage2/mask/6575.npy'],\n",
       " ['62556', 'data/stage2/image/62556.npy', 'data/stage2/mask/62556.npy'],\n",
       " ['60755', 'data/stage2/image/60755.npy', 'data/stage2/mask/60755.npy'],\n",
       " ['60302', 'data/stage2/image/60302.npy', 'data/stage2/mask/60302.npy'],\n",
       " ['31852', 'data/stage2/image/31852.npy', 'data/stage2/mask/31852.npy'],\n",
       " ['6172', 'data/stage2/image/6172.npy', 'data/stage2/mask/6172.npy'],\n",
       " ['8413', 'data/stage2/image/8413.npy', 'data/stage2/mask/8413.npy'],\n",
       " ['54830', 'data/stage2/image/54830.npy', 'data/stage2/mask/54830.npy'],\n",
       " ['30522', 'data/stage2/image/30522.npy', 'data/stage2/mask/30522.npy'],\n",
       " ['34232', 'data/stage2/image/34232.npy', 'data/stage2/mask/34232.npy'],\n",
       " ['39205', 'data/stage2/image/39205.npy', 'data/stage2/mask/39205.npy']]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "465b3a22-072a-43dd-b3fa-35164fe75d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_3d_df = pd.DataFrame(dataframe_list, columns=[\"StudyInstanceUID\", \"image_path\", \"mask_path\"])\n",
    "seg_3d_df['fold'] = -1\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "for idx, (train_idx, test_idx) in enumerate(gkf.split(X=seg_3d_df, groups=seg_3d_df['StudyInstanceUID'].values)):\n",
    "    seg_3d_df.loc[test_idx, 'fold'] = idx\n",
    "seg_3d_df.to_csv('data/stage1/seg_3d.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21cd4e3f-1719-4083-ac6e-b1654c3aa36d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'seg_3d_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 46\u001b[0m\n\u001b[1;32m     42\u001b[0m         image, mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(image)\u001b[38;5;241m.\u001b[39mfloat(), torch\u001b[38;5;241m.\u001b[39mtensor(mask)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m image, mask\n\u001b[0;32m---> 46\u001b[0m dataset_show \u001b[38;5;241m=\u001b[39m SEGDataset(\u001b[43mseg_3d_df\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m, transform\u001b[38;5;241m=\u001b[39mtransforms_train)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m2\u001b[39m):\n\u001b[1;32m     50\u001b[0m     f, axarr \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m4\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'seg_3d_df' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import monai.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "%matplotlib inline\n",
    "rcParams['figure.figsize'] = 20, 8\n",
    "\n",
    "transforms_train = transforms.Compose([\n",
    "    transforms.RandFlipd(keys=[\"image\", \"mask\"], prob=0.5, spatial_axis=1),\n",
    "    transforms.RandFlipd(keys=[\"image\", \"mask\"], prob=0.5, spatial_axis=2),\n",
    "    transforms.RandAffined(keys=[\"image\", \"mask\"], translate_range=[int(x*y) for x, y in zip(CFG.image_sizes, [0.3, 0.3, 0.3])], padding_mode='zeros', prob=0.7),\n",
    "    transforms.RandGridDistortiond(keys=(\"image\", \"mask\"), prob=0.5, distort_limit=(-0.01, 0.01), mode=\"nearest\"),    \n",
    "])\n",
    "\n",
    "transforms_valid = transforms.Compose([\n",
    "])\n",
    "\n",
    "\n",
    "class SEGDataset(Dataset):\n",
    "    def __init__(self, df, mode, transform):\n",
    "        self.df = df.reset_index()\n",
    "        self.mode = mode\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        infos = self.df.iloc[index]\n",
    "        image = np.load(infos['image_path'])\n",
    "        mask = np.load(infos['mask_path'])\n",
    "        \n",
    "        if image.ndim < 4:\n",
    "            image = np.expand_dims(image, 0).repeat(3, 0)\n",
    "        \n",
    "        res = self.transform({'image': image, 'mask': mask})\n",
    "        # image = res['image'] / 255.\n",
    "        # mask = res['mask']\n",
    "        image = image / 255.\n",
    "        mask = (mask > 127).astype(np.float32)\n",
    "        image, mask = torch.tensor(image).float(), torch.tensor(mask).float()\n",
    "        return image, mask\n",
    "\n",
    "\n",
    "dataset_show = SEGDataset(seg_3d_df, 'train', transform=transforms_train)\n",
    "                         \n",
    "\n",
    "for i in range(2):\n",
    "    f, axarr = plt.subplots(1,4)\n",
    "    for p in range(4):\n",
    "        idx = i*4+p\n",
    "        img, mask = dataset_show[idx]\n",
    "        print('debug')\n",
    "        print(img.shape)\n",
    "        print(mask.shape)\n",
    "        img = img[:, :, 60]\n",
    "        mask = mask[:, :, 60]\n",
    "        # mask[0] = mask[0] + mask[1]\n",
    "        # mask[1] = mask[2] + mask[3]\n",
    "        # mask[2] = mask[4]\n",
    "        mask = mask[:3]\n",
    "        img = img * 0.7 + mask * 0.3\n",
    "        axarr[p].imshow(img.transpose(0, 1).transpose(1,2).squeeze())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9e7f3b07-e3b7-4361-9eef-26f5525f6c72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 128, 128, 128])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import timm\n",
    "import segmentation_models_pytorch as smp\n",
    "from timm.layers import Conv2dSame\n",
    "from conv3d_same import Conv3dSame\n",
    "\n",
    "\n",
    "class TimmSegModel(nn.Module):\n",
    "    def __init__(self, backbone, segtype='unet', pretrained=False):\n",
    "        super(TimmSegModel, self).__init__()\n",
    "\n",
    "        self.encoder = timm.create_model(\n",
    "            backbone,\n",
    "            in_chans=3,\n",
    "            features_only=True,\n",
    "            drop_rate=CFG.drop_rate,\n",
    "            drop_path_rate=CFG.drop_path_rate,\n",
    "            pretrained=pretrained\n",
    "        )\n",
    "        g = self.encoder(torch.rand(1, 3, 64, 64))\n",
    "        encoder_channels = [1] + [_.shape[1] for _ in g]\n",
    "        decoder_channels = [256, 128, 64, 32, 16]\n",
    "        n_blocks = CFG.n_blocks\n",
    "        if segtype == 'unet':\n",
    "            self.decoder = smp.decoders.unet.decoder.UnetDecoder(\n",
    "                encoder_channels=encoder_channels[:n_blocks+1],\n",
    "                decoder_channels=decoder_channels[:n_blocks],\n",
    "                n_blocks=n_blocks,\n",
    "            )\n",
    "\n",
    "        self.segmentation_head = nn.Conv2d(decoder_channels[n_blocks-1], CFG.out_dim, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "\n",
    "    def forward(self,x):\n",
    "        global_features = [0] + self.encoder(x)[:CFG.n_blocks]\n",
    "        seg_features = self.decoder(*global_features)\n",
    "        seg_features = self.segmentation_head(seg_features)\n",
    "        return seg_features\n",
    "\n",
    "\n",
    "def convert_3d(module):\n",
    "    module_output = module\n",
    "    if isinstance(module, torch.nn.BatchNorm2d):\n",
    "        module_output = torch.nn.BatchNorm3d(\n",
    "            module.num_features,\n",
    "            module.eps,\n",
    "            module.momentum,\n",
    "            module.affine,\n",
    "            module.track_running_stats,\n",
    "        )\n",
    "        if module.affine:\n",
    "            with torch.no_grad():\n",
    "                module_output.weight = module.weight\n",
    "                module_output.bias = module.bias\n",
    "        module_output.running_mean = module.running_mean\n",
    "        module_output.running_var = module.running_var\n",
    "        module_output.num_batches_tracked = module.num_batches_tracked\n",
    "        if hasattr(module, \"qconfig\"):\n",
    "            module_output.qconfig = module.qconfig\n",
    "            \n",
    "    # elif isinstance(module, Conv2dSame):\n",
    "    #     module_output = Conv3dSame(\n",
    "    #         in_channels=module.in_channels,\n",
    "    #         out_channels=module.out_channels,\n",
    "    #         kernel_size=module.kernel_size[0],\n",
    "    #         stride=module.stride[0],\n",
    "    #         padding=module.padding[0],\n",
    "    #         dilation=module.dilation[0],\n",
    "    #         groups=module.groups,\n",
    "    #         bias=module.bias is not None,\n",
    "    #     )\n",
    "    #     module_output.weight = torch.nn.Parameter(module.weight.unsqueeze(-1).repeat(1,1,1,1,module.kernel_size[0]))\n",
    "\n",
    "    elif isinstance(module, torch.nn.Conv2d):\n",
    "        module_output = torch.nn.Conv3d(\n",
    "            in_channels=module.in_channels,\n",
    "            out_channels=module.out_channels,\n",
    "            kernel_size=module.kernel_size[0],\n",
    "            stride=module.stride[0],\n",
    "            padding=module.padding[0],\n",
    "            dilation=module.dilation[0],\n",
    "            groups=module.groups,\n",
    "            bias=module.bias is not None,\n",
    "            padding_mode=module.padding_mode\n",
    "        )\n",
    "        module_output.weight = torch.nn.Parameter(module.weight.unsqueeze(-1).repeat(1,1,1,1,module.kernel_size[0]))\n",
    "\n",
    "    elif isinstance(module, torch.nn.MaxPool2d):\n",
    "        module_output = torch.nn.MaxPool3d(\n",
    "            kernel_size=module.kernel_size,\n",
    "            stride=module.stride,\n",
    "            padding=module.padding,\n",
    "            dilation=module.dilation,\n",
    "            ceil_mode=module.ceil_mode,\n",
    "        )\n",
    "    elif isinstance(module, torch.nn.AvgPool2d):\n",
    "        module_output = torch.nn.AvgPool3d(\n",
    "            kernel_size=module.kernel_size,\n",
    "            stride=module.stride,\n",
    "            padding=module.padding,\n",
    "            ceil_mode=module.ceil_mode,\n",
    "        )\n",
    "\n",
    "    for name, child in module.named_children():\n",
    "        module_output.add_module(\n",
    "            name, convert_3d(child)\n",
    "        )\n",
    "    del module\n",
    "\n",
    "    return module_output\n",
    "\n",
    "\n",
    "m = TimmSegModel(CFG.backbone)\n",
    "m = convert_3d(m)\n",
    "m(torch.rand(1, 3, 128, 128, 128)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b44ad956-f34d-4ed9-9a44-e6d2d812bdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, Optional\n",
    "\n",
    "\n",
    "def binary_dice_score(\n",
    "    y_pred: torch.Tensor,\n",
    "    y_true: torch.Tensor,\n",
    "    threshold: Optional[float] = None,\n",
    "    nan_score_on_empty=False,\n",
    "    eps: float = 1e-7,\n",
    ") -> float:\n",
    "\n",
    "    if threshold is not None:\n",
    "        y_pred = (y_pred > threshold).to(y_true.dtype)\n",
    "\n",
    "    intersection = torch.sum(y_pred * y_true).item()\n",
    "    cardinality = (torch.sum(y_pred) + torch.sum(y_true)).item()\n",
    "\n",
    "    score = (2.0 * intersection) / (cardinality + eps)\n",
    "\n",
    "    has_targets = torch.sum(y_true) > 0\n",
    "    has_predicted = torch.sum(y_pred) > 0\n",
    "\n",
    "    if not has_targets:\n",
    "        if nan_score_on_empty:\n",
    "            score = np.nan\n",
    "        else:\n",
    "            score = float(not has_predicted)\n",
    "    return score\n",
    "\n",
    "\n",
    "def multilabel_dice_score(\n",
    "    y_true: torch.Tensor,\n",
    "    y_pred: torch.Tensor,\n",
    "    threshold=None,\n",
    "    eps=1e-7,\n",
    "    nan_score_on_empty=False,\n",
    "):\n",
    "    ious = []\n",
    "    num_classes = y_pred.size(0)\n",
    "    for class_index in range(num_classes):\n",
    "        iou = binary_dice_score(\n",
    "            y_pred=y_pred[class_index],\n",
    "            y_true=y_true[class_index],\n",
    "            threshold=threshold,\n",
    "            nan_score_on_empty=nan_score_on_empty,\n",
    "            eps=eps,\n",
    "        )\n",
    "        ious.append(iou)\n",
    "\n",
    "    return ious\n",
    "\n",
    "\n",
    "def dice_loss(input, target):\n",
    "    input = torch.sigmoid(input)\n",
    "    smooth = 1.0\n",
    "    iflat = input.view(-1)\n",
    "    tflat = target.view(-1)\n",
    "    intersection = (iflat * tflat).sum()\n",
    "    return 1 - ((2.0 * intersection + smooth) / (iflat.sum() + tflat.sum() + smooth))\n",
    "\n",
    "\n",
    "def bce_dice(input, target, loss_weights=CFG.loss_weights):\n",
    "    loss1 = loss_weights[0] * nn.BCEWithLogitsLoss()(input, target)\n",
    "    loss2 = loss_weights[1] * dice_loss(input, target)\n",
    "    return (loss1 + loss2) / sum(loss_weights)\n",
    "\n",
    "criterion = bce_dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "69eda6e5-fe16-4307-87fc-866eae9c0daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "def mixup(input, truth, clip=[0, 1]):\n",
    "    indices = torch.randperm(input.size(0))\n",
    "    shuffled_input = input[indices]\n",
    "    shuffled_labels = truth[indices]\n",
    "\n",
    "    lam = np.random.uniform(clip[0], clip[1])\n",
    "    input = input * lam + shuffled_input * (1 - lam)\n",
    "    return input, truth, shuffled_labels, lam\n",
    "\n",
    "\n",
    "def train_func(model, loader_train, optimizer, scaler=None):\n",
    "    model.train()\n",
    "    train_loss = []\n",
    "    bar = tqdm(loader_train)\n",
    "    for images, gt_masks in bar:\n",
    "        optimizer.zero_grad()\n",
    "        images = images.cuda()\n",
    "        gt_masks = gt_masks.cuda()\n",
    "\n",
    "        do_mixup = False\n",
    "        if random.random() < CFG.p_mixup:\n",
    "            do_mixup = True\n",
    "            images, gt_masks, gt_masks_sfl, lam = mixup(images, gt_masks)\n",
    "\n",
    "        with amp.autocast():\n",
    "            logits = model(images)\n",
    "            loss = criterion(logits, gt_masks)\n",
    "            if do_mixup:\n",
    "                loss2 = criterion(logits, gt_masks_sfl)\n",
    "                loss = loss * lam  + loss2 * (1 - lam)\n",
    "\n",
    "        train_loss.append(loss.item())\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        bar.set_description(f'smth:{np.mean(train_loss[-30:]):.4f}')\n",
    "\n",
    "    return np.mean(train_loss)\n",
    "\n",
    "\n",
    "def valid_func(model, loader_valid):\n",
    "    model.eval()\n",
    "    valid_loss = []\n",
    "    outputs = []\n",
    "    ths = [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]\n",
    "    batch_metrics = [[]] * 7\n",
    "    bar = tqdm(loader_valid)\n",
    "    with torch.no_grad():\n",
    "        for images, gt_masks in bar:\n",
    "            images = images.cuda()\n",
    "            gt_masks = gt_masks.cuda()\n",
    "\n",
    "            logits = model(images)\n",
    "            loss = criterion(logits, gt_masks)\n",
    "            valid_loss.append(loss.item())\n",
    "            for thi, th in enumerate(ths):\n",
    "                pred = (logits.sigmoid() > th).float().detach()\n",
    "                for i in range(logits.shape[0]):\n",
    "                    tmp = multilabel_dice_score(\n",
    "                        y_pred=logits[i].sigmoid().cpu(),\n",
    "                        y_true=gt_masks[i].cpu(),\n",
    "                        threshold=0.5,\n",
    "                    )\n",
    "                    batch_metrics[thi].extend(tmp)\n",
    "            bar.set_description(f'smth:{np.mean(valid_loss[-30:]):.4f}')\n",
    "            \n",
    "    metrics = [np.mean(this_metric) for this_metric in batch_metrics]\n",
    "    print('best th:', ths[np.argmax(metrics)], 'best dc:', np.max(metrics))\n",
    "\n",
    "    return np.mean(valid_loss), np.max(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "678716a6-cd01-40db-ba65-9abbd01831a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data1/ocr_ie/anaconda3/envs/rsna/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:139: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "/data1/ocr_ie/anaconda3/envs/rsna/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f125b4b0c40>]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# parameter\n",
    "rcParams['figure.figsize'] = 20, 2\n",
    "optimizer = optim.AdamW(m.parameters(), lr=CFG.init_lr)\n",
    "scheduler_cosine = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, 1000)\n",
    "lrs = []\n",
    "for epoch in range(1, 1000+1):\n",
    "    scheduler_cosine.step(epoch-1)\n",
    "    lrs.append(optimizer.param_groups[0][\"lr\"])\n",
    "plt.plot(range(len(lrs)), lrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "eb6f315c-1c80-4ba8-81d0-04d83d7c5753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "log_dir = './logs'\n",
    "model_dir = './weights'\n",
    "DEBUG = False\n",
    "Path(log_dir).mkdir(parents=True, exist_ok=True)\n",
    "Path(model_dir).mkdir(parents=True, exist_ok=True)\n",
    "def run(fold):\n",
    "    log_file = os.path.join(log_dir, f'{CFG.backbone}_fold{fold}.txt')\n",
    "    model_file = os.path.join(model_dir, f'{CFG.backbone}_fold{fold}_best.pth')\n",
    "    df_seg = pd.read_csv('data/stage1/seg_3d.csv')\n",
    "    train_ = df_seg[df_seg['fold'] != fold].reset_index(drop=True)\n",
    "    valid_ = df_seg[df_seg['fold'] == fold].reset_index(drop=True)\n",
    "    dataset_train = SEGDataset(train_, 'train', transform=transforms_train)\n",
    "    dataset_valid = SEGDataset(valid_, 'valid', transform=transforms_valid)\n",
    "    loader_train = torch.utils.data.DataLoader(dataset_train, batch_size=CFG.batch_size, shuffle=True, num_workers=CFG.num_workers)\n",
    "    loader_valid = torch.utils.data.DataLoader(dataset_valid, batch_size=CFG.batch_size, shuffle=False, num_workers=CFG.num_workers)\n",
    "    model = TimmSegModel(CFG.backbone, pretrained=True)\n",
    "    model = convert_3d(model)\n",
    "    model = model.to(CFG.device)\n",
    "\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=CFG.init_lr)\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "    from_epoch = 0\n",
    "    metric_best = 0.\n",
    "    loss_min = np.inf\n",
    "\n",
    "    scheduler_cosine = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, CFG.n_epochs)\n",
    "\n",
    "    print(len(dataset_train), len(dataset_valid))\n",
    "\n",
    "    for epoch in range(1, CFG.n_epochs + 1):\n",
    "        scheduler_cosine.step(epoch - 1)\n",
    "        print(time.ctime(), 'Epoch:', epoch)\n",
    "        train_loss = train_func(model, loader_train, optimizer, scaler)\n",
    "        valid_loss, metric = valid_func(model, loader_valid)\n",
    "        content = time.ctime() + ' ' + f'Fold {fold}, Epoch {epoch}, lr: {optimizer.param_groups[0][\"lr\"]:.7f}, train loss: {train_loss:.5f}, valid loss: {valid_loss:.5f}, metric: {(metric):.6f}.'\n",
    "        print(content)\n",
    "        with open(log_file, 'a') as appender:\n",
    "            appender.write(content + '\\n')\n",
    "\n",
    "        if metric > metric_best:\n",
    "            print(f'metric_best ({metric_best:.6f} --> {metric:.6f}). Saving model ...')\n",
    "            torch.save(model.state_dict(), model_file)\n",
    "            metric_best = metric\n",
    "\n",
    "        # Save Last\n",
    "        if not DEBUG:\n",
    "            torch.save(\n",
    "                {\n",
    "                    'epoch': epoch,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'scaler_state_dict': scaler.state_dict() if scaler else None,\n",
    "                    'score_best': metric_best,\n",
    "                },\n",
    "                model_file.replace('_best', '_last')\n",
    "            )\n",
    "\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c440f65-63ed-485a-8548-26759b28b191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164 42\n",
      "Thu Sep 21 15:44:53 2023 Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "smth:0.3038: 100%|| 41/41 [01:23<00:00,  2.04s/it]\n",
      "smth:0.3571: 100%|| 11/11 [00:37<00:00,  3.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best th: 0.2 best dc: 0.18754940003062384\n",
      "Thu Sep 21 15:46:54 2023 Fold 0, Epoch 1, lr: 0.0030000, train loss: 0.36867, valid loss: 0.35706, metric: 0.187549.\n",
      "metric_best (0.000000 --> 0.187549). Saving model ...\n",
      "Thu Sep 21 15:46:56 2023 Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "smth:0.2284: 100%|| 41/41 [01:45<00:00,  2.58s/it]\n",
      "smth:0.2807: 100%|| 11/11 [00:37<00:00,  3.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best th: 0.2 best dc: 0.2128234150168301\n",
      "Thu Sep 21 15:49:19 2023 Fold 0, Epoch 2, lr: 0.0030000, train loss: 0.23895, valid loss: 0.28074, metric: 0.212823.\n",
      "metric_best (0.187549 --> 0.212823). Saving model ...\n",
      "Thu Sep 21 15:49:23 2023 Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "smth:0.2083: 100%|| 41/41 [02:03<00:00,  3.01s/it]\n",
      "smth:0.2519: 100%|| 11/11 [00:38<00:00,  3.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best th: 0.2 best dc: 0.24233986012650024\n",
      "Thu Sep 21 15:52:05 2023 Fold 0, Epoch 3, lr: 0.0030000, train loss: 0.21403, valid loss: 0.25194, metric: 0.242340.\n",
      "metric_best (0.212823 --> 0.242340). Saving model ...\n",
      "Thu Sep 21 15:52:09 2023 Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "smth:0.2087: 100%|| 41/41 [02:17<00:00,  3.34s/it]\n",
      "smth:0.2162: 100%|| 11/11 [00:38<00:00,  3.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best th: 0.2 best dc: 0.27353575828246135\n",
      "Thu Sep 21 15:55:04 2023 Fold 0, Epoch 4, lr: 0.0029999, train loss: 0.20760, valid loss: 0.21619, metric: 0.273536.\n",
      "metric_best (0.242340 --> 0.273536). Saving model ...\n",
      "Thu Sep 21 15:55:09 2023 Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "smth:0.2009: 100%|| 41/41 [02:15<00:00,  3.31s/it]\n",
      "smth:0.2263: 100%|| 11/11 [00:39<00:00,  3.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best th: 0.2 best dc: 0.26965148102670367\n",
      "Thu Sep 21 15:58:04 2023 Fold 0, Epoch 5, lr: 0.0029999, train loss: 0.19799, valid loss: 0.22626, metric: 0.269651.\n",
      "Thu Sep 21 15:58:07 2023 Epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "smth:0.1875: 100%|| 41/41 [02:21<00:00,  3.46s/it]\n",
      "smth:0.2075: 100%|| 11/11 [00:46<00:00,  4.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best th: 0.2 best dc: 0.2788963579872684\n",
      "Thu Sep 21 16:01:16 2023 Fold 0, Epoch 6, lr: 0.0029998, train loss: 0.18647, valid loss: 0.20745, metric: 0.278896.\n",
      "metric_best (0.273536 --> 0.278896). Saving model ...\n",
      "Thu Sep 21 16:01:20 2023 Epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "smth:0.1947: 100%|| 41/41 [02:33<00:00,  3.74s/it]\n",
      "smth:0.1919: 100%|| 11/11 [00:46<00:00,  4.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best th: 0.2 best dc: 0.2910225749213796\n",
      "Thu Sep 21 16:04:40 2023 Fold 0, Epoch 7, lr: 0.0029997, train loss: 0.19003, valid loss: 0.19194, metric: 0.291023.\n",
      "metric_best (0.278896 --> 0.291023). Saving model ...\n",
      "Thu Sep 21 16:04:44 2023 Epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "smth:0.1748: 100%|| 41/41 [02:20<00:00,  3.44s/it]\n",
      "smth:0.1747: 100%|| 11/11 [00:44<00:00,  4.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best th: 0.2 best dc: 0.30567961974445956\n",
      "Thu Sep 21 16:07:49 2023 Fold 0, Epoch 8, lr: 0.0029996, train loss: 0.17955, valid loss: 0.17466, metric: 0.305680.\n",
      "metric_best (0.291023 --> 0.305680). Saving model ...\n",
      "Thu Sep 21 16:07:53 2023 Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "smth:0.1817: 100%|| 41/41 [02:34<00:00,  3.78s/it]\n",
      "smth:0.1931: 100%|| 11/11 [00:47<00:00,  4.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best th: 0.2 best dc: 0.29211701963786624\n",
      "Thu Sep 21 16:11:16 2023 Fold 0, Epoch 9, lr: 0.0029995, train loss: 0.17932, valid loss: 0.19307, metric: 0.292117.\n",
      "Thu Sep 21 16:11:19 2023 Epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "smth:0.1616: 100%|| 41/41 [02:35<00:00,  3.79s/it]\n",
      "smth:0.1748: 100%|| 11/11 [00:46<00:00,  4.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best th: 0.2 best dc: 0.3097809975508834\n",
      "Thu Sep 21 16:14:41 2023 Fold 0, Epoch 10, lr: 0.0029994, train loss: 0.16302, valid loss: 0.17475, metric: 0.309781.\n",
      "metric_best (0.305680 --> 0.309781). Saving model ...\n",
      "Thu Sep 21 16:14:45 2023 Epoch: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "smth:0.1543: 100%|| 41/41 [02:49<00:00,  4.13s/it]\n",
      "smth:0.1728: 100%|| 11/11 [00:47<00:00,  4.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best th: 0.2 best dc: 0.3038120823691837\n",
      "Thu Sep 21 16:18:22 2023 Fold 0, Epoch 11, lr: 0.0029993, train loss: 0.15973, valid loss: 0.17284, metric: 0.303812.\n",
      "Thu Sep 21 16:18:24 2023 Epoch: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "smth:0.1596: 100%|| 41/41 [02:44<00:00,  4.01s/it]\n",
      "smth:0.1770: 100%|| 11/11 [00:47<00:00,  4.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best th: 0.2 best dc: 0.3169500557898387\n",
      "Thu Sep 21 16:21:57 2023 Fold 0, Epoch 12, lr: 0.0029991, train loss: 0.15586, valid loss: 0.17704, metric: 0.316950.\n",
      "metric_best (0.309781 --> 0.316950). Saving model ...\n",
      "Thu Sep 21 16:22:01 2023 Epoch: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "smth:0.1379: 100%|| 41/41 [02:37<00:00,  3.84s/it]\n",
      "smth:0.1624: 100%|| 11/11 [00:42<00:00,  3.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best th: 0.2 best dc: 0.42331226641854997\n",
      "Thu Sep 21 16:25:21 2023 Fold 0, Epoch 13, lr: 0.0029989, train loss: 0.14201, valid loss: 0.16238, metric: 0.423312.\n",
      "metric_best (0.316950 --> 0.423312). Saving model ...\n",
      "Thu Sep 21 16:25:24 2023 Epoch: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "smth:0.1373: 100%|| 41/41 [02:40<00:00,  3.91s/it]\n",
      "smth:0.1808: 100%|| 11/11 [00:41<00:00,  3.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best th: 0.2 best dc: 0.44537800088566676\n",
      "Thu Sep 21 16:28:47 2023 Fold 0, Epoch 14, lr: 0.0029987, train loss: 0.13495, valid loss: 0.18077, metric: 0.445378.\n",
      "metric_best (0.423312 --> 0.445378). Saving model ...\n",
      "Thu Sep 21 16:28:52 2023 Epoch: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "smth:0.1409: 100%|| 41/41 [02:53<00:00,  4.23s/it]\n",
      "smth:0.1939: 100%|| 11/11 [00:43<00:00,  3.93s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best th: 0.2 best dc: 0.40415686619561514\n",
      "Thu Sep 21 16:32:28 2023 Fold 0, Epoch 15, lr: 0.0029985, train loss: 0.14354, valid loss: 0.19391, metric: 0.404157.\n",
      "Thu Sep 21 16:32:31 2023 Epoch: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "smth:0.1319: 100%|| 41/41 [02:47<00:00,  4.09s/it]\n",
      "smth:0.1564: 100%|| 11/11 [00:43<00:00,  4.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best th: 0.2 best dc: 0.5401029662110494\n",
      "Thu Sep 21 16:36:03 2023 Fold 0, Epoch 16, lr: 0.0029983, train loss: 0.13747, valid loss: 0.15642, metric: 0.540103.\n",
      "metric_best (0.445378 --> 0.540103). Saving model ...\n",
      "Thu Sep 21 16:36:07 2023 Epoch: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "smth:0.1209: 100%|| 41/41 [02:41<00:00,  3.94s/it]\n",
      "smth:0.1631: 100%|| 11/11 [00:47<00:00,  4.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best th: 0.2 best dc: 0.5577854797856365\n",
      "Thu Sep 21 16:39:36 2023 Fold 0, Epoch 17, lr: 0.0029981, train loss: 0.12598, valid loss: 0.16314, metric: 0.557785.\n",
      "metric_best (0.540103 --> 0.557785). Saving model ...\n",
      "Thu Sep 21 16:39:39 2023 Epoch: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "smth:0.1138: 100%|| 41/41 [02:44<00:00,  4.02s/it]\n",
      "smth:0.1907: 100%|| 11/11 [00:43<00:00,  4.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best th: 0.2 best dc: 0.5664354698292204\n",
      "Thu Sep 21 16:43:08 2023 Fold 0, Epoch 18, lr: 0.0029979, train loss: 0.11399, valid loss: 0.19071, metric: 0.566435.\n",
      "metric_best (0.557785 --> 0.566435). Saving model ...\n",
      "Thu Sep 21 16:43:13 2023 Epoch: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "smth:0.1214: 100%|| 41/41 [02:42<00:00,  3.96s/it]\n",
      "smth:0.1566: 100%|| 11/11 [00:43<00:00,  3.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best th: 0.2 best dc: 0.616050646553172\n",
      "Thu Sep 21 16:46:39 2023 Fold 0, Epoch 19, lr: 0.0029976, train loss: 0.12150, valid loss: 0.15659, metric: 0.616051.\n",
      "metric_best (0.566435 --> 0.616051). Saving model ...\n",
      "Thu Sep 21 16:46:42 2023 Epoch: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "smth:0.1104: 100%|| 41/41 [02:40<00:00,  3.91s/it]\n",
      "smth:0.1526: 100%|| 11/11 [00:44<00:00,  4.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best th: 0.2 best dc: 0.6721857806302997\n",
      "Thu Sep 21 16:50:08 2023 Fold 0, Epoch 20, lr: 0.0029973, train loss: 0.11412, valid loss: 0.15257, metric: 0.672186.\n",
      "metric_best (0.616051 --> 0.672186). Saving model ...\n",
      "Thu Sep 21 16:50:11 2023 Epoch: 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "smth:0.1023: 100%|| 41/41 [02:34<00:00,  3.77s/it]\n",
      "smth:0.1178: 100%|| 11/11 [00:42<00:00,  3.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best th: 0.2 best dc: 0.7520190096637335\n",
      "Thu Sep 21 16:53:29 2023 Fold 0, Epoch 21, lr: 0.0029970, train loss: 0.10397, valid loss: 0.11781, metric: 0.752019.\n",
      "metric_best (0.672186 --> 0.752019). Saving model ...\n",
      "Thu Sep 21 16:53:33 2023 Epoch: 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "smth:0.0941: 100%|| 41/41 [02:31<00:00,  3.69s/it]\n",
      "smth:0.1353: 100%|| 11/11 [00:41<00:00,  3.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best th: 0.2 best dc: 0.6627275820329361\n",
      "Thu Sep 21 16:56:46 2023 Fold 0, Epoch 22, lr: 0.0029967, train loss: 0.09519, valid loss: 0.13533, metric: 0.662728.\n",
      "Thu Sep 21 16:56:48 2023 Epoch: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "smth:0.0875: 100%|| 41/41 [02:12<00:00,  3.24s/it]\n",
      "smth:0.1206: 100%|| 11/11 [00:40<00:00,  3.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best th: 0.2 best dc: 0.7211742670951545\n",
      "Thu Sep 21 16:59:42 2023 Fold 0, Epoch 23, lr: 0.0029964, train loss: 0.08845, valid loss: 0.12058, metric: 0.721174.\n",
      "Thu Sep 21 16:59:44 2023 Epoch: 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "smth:0.0948: 100%|| 41/41 [02:22<00:00,  3.47s/it]\n",
      "smth:0.1133: 100%|| 11/11 [00:39<00:00,  3.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best th: 0.2 best dc: 0.7661105630663092\n",
      "Thu Sep 21 17:02:46 2023 Fold 0, Epoch 24, lr: 0.0029961, train loss: 0.09218, valid loss: 0.11328, metric: 0.766111.\n",
      "metric_best (0.752019 --> 0.766111). Saving model ...\n",
      "Thu Sep 21 17:02:51 2023 Epoch: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "smth:0.0860: 100%|| 41/41 [02:18<00:00,  3.37s/it]\n",
      "smth:0.1043: 100%|| 11/11 [00:41<00:00,  3.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best th: 0.2 best dc: 0.7869340160687331\n",
      "Thu Sep 21 17:05:50 2023 Fold 0, Epoch 25, lr: 0.0029957, train loss: 0.08302, valid loss: 0.10435, metric: 0.786934.\n",
      "metric_best (0.766111 --> 0.786934). Saving model ...\n",
      "Thu Sep 21 17:05:53 2023 Epoch: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "smth:0.0734: 100%|| 41/41 [02:10<00:00,  3.18s/it]\n",
      "smth:0.1031: 100%|| 11/11 [00:42<00:00,  3.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best th: 0.2 best dc: 0.8018956783244708\n",
      "Thu Sep 21 17:08:47 2023 Fold 0, Epoch 26, lr: 0.0029954, train loss: 0.07302, valid loss: 0.10310, metric: 0.801896.\n",
      "metric_best (0.786934 --> 0.801896). Saving model ...\n",
      "Thu Sep 21 17:08:50 2023 Epoch: 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "smth:0.0900: 100%|| 41/41 [02:17<00:00,  3.34s/it]\n",
      "smth:0.1081: 100%|| 11/11 [00:36<00:00,  3.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best th: 0.2 best dc: 0.7891342526093867\n",
      "Thu Sep 21 17:11:44 2023 Fold 0, Epoch 27, lr: 0.0029950, train loss: 0.08757, valid loss: 0.10812, metric: 0.789134.\n",
      "Thu Sep 21 17:11:46 2023 Epoch: 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "smth:0.0772: 100%|| 41/41 [01:14<00:00,  1.81s/it]\n",
      "smth:0.0974: 100%|| 11/11 [00:38<00:00,  3.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best th: 0.2 best dc: 0.7794927953139763\n",
      "Thu Sep 21 17:13:39 2023 Fold 0, Epoch 28, lr: 0.0029946, train loss: 0.07907, valid loss: 0.09745, metric: 0.779493.\n",
      "Thu Sep 21 17:13:41 2023 Epoch: 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "smth:0.0769: 100%|| 41/41 [01:41<00:00,  2.47s/it]\n",
      "smth:0.0972: 100%|| 11/11 [00:40<00:00,  3.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best th: 0.2 best dc: 0.8025109969736081\n",
      "Thu Sep 21 17:16:03 2023 Fold 0, Epoch 29, lr: 0.0029942, train loss: 0.07372, valid loss: 0.09723, metric: 0.802511.\n",
      "metric_best (0.801896 --> 0.802511). Saving model ...\n",
      "Thu Sep 21 17:16:07 2023 Epoch: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "smth:0.0811: 100%|| 41/41 [02:00<00:00,  2.95s/it]\n",
      "smth:0.0948: 100%|| 11/11 [00:40<00:00,  3.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best th: 0.2 best dc: 0.8145563527474465\n",
      "Thu Sep 21 17:18:49 2023 Fold 0, Epoch 30, lr: 0.0029938, train loss: 0.08022, valid loss: 0.09476, metric: 0.814556.\n",
      "metric_best (0.802511 --> 0.814556). Saving model ...\n",
      "Thu Sep 21 17:18:52 2023 Epoch: 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "smth:0.0711: 100%|| 41/41 [02:16<00:00,  3.33s/it]\n",
      "smth:0.0934: 100%|| 11/11 [00:39<00:00,  3.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best th: 0.2 best dc: 0.8197362810813547\n",
      "Thu Sep 21 17:21:48 2023 Fold 0, Epoch 31, lr: 0.0029933, train loss: 0.06851, valid loss: 0.09342, metric: 0.819736.\n",
      "metric_best (0.814556 --> 0.819736). Saving model ...\n",
      "Thu Sep 21 17:21:53 2023 Epoch: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "smth:0.0799: 100%|| 41/41 [02:19<00:00,  3.40s/it]\n",
      "smth:0.0999: 100%|| 11/11 [00:41<00:00,  3.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best th: 0.2 best dc: 0.8057534997808079\n",
      "Thu Sep 21 17:24:55 2023 Fold 0, Epoch 32, lr: 0.0029929, train loss: 0.07942, valid loss: 0.09990, metric: 0.805753.\n",
      "Thu Sep 21 17:24:57 2023 Epoch: 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "smth:0.0627: 100%|| 41/41 [02:34<00:00,  3.77s/it]\n",
      "smth:0.1182: 100%|| 11/11 [00:39<00:00,  3.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best th: 0.2 best dc: 0.7116414372148021\n",
      "Thu Sep 21 17:28:12 2023 Fold 0, Epoch 33, lr: 0.0029924, train loss: 0.06186, valid loss: 0.11817, metric: 0.711641.\n",
      "Thu Sep 21 17:28:14 2023 Epoch: 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "smth:0.0703: 100%|| 41/41 [02:34<00:00,  3.77s/it]\n",
      "smth:0.0953: 100%|| 11/11 [00:38<00:00,  3.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best th: 0.2 best dc: 0.8118044162227958\n",
      "Thu Sep 21 17:31:27 2023 Fold 0, Epoch 34, lr: 0.0029919, train loss: 0.06800, valid loss: 0.09526, metric: 0.811804.\n",
      "Thu Sep 21 17:31:30 2023 Epoch: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "smth:0.0645: 100%|| 41/41 [02:24<00:00,  3.53s/it]\n",
      "smth:0.0894: 100%|| 11/11 [00:41<00:00,  3.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best th: 0.2 best dc: 0.8376151389772994\n",
      "Thu Sep 21 17:34:37 2023 Fold 0, Epoch 35, lr: 0.0029915, train loss: 0.06601, valid loss: 0.08944, metric: 0.837615.\n",
      "metric_best (0.819736 --> 0.837615). Saving model ...\n",
      "Thu Sep 21 17:34:41 2023 Epoch: 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "smth:0.0676: 100%|| 41/41 [02:11<00:00,  3.20s/it]\n",
      "smth:0.0938: 100%|| 11/11 [00:38<00:00,  3.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best th: 0.2 best dc: 0.777588197824341\n",
      "Thu Sep 21 17:37:31 2023 Fold 0, Epoch 36, lr: 0.0029909, train loss: 0.06390, valid loss: 0.09382, metric: 0.777588.\n",
      "Thu Sep 21 17:37:33 2023 Epoch: 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "smth:0.0617: 100%|| 41/41 [02:10<00:00,  3.17s/it]\n",
      "smth:0.0928: 100%|| 11/11 [00:40<00:00,  3.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best th: 0.2 best dc: 0.8259845965180802\n",
      "Thu Sep 21 17:40:24 2023 Fold 0, Epoch 37, lr: 0.0029904, train loss: 0.06578, valid loss: 0.09282, metric: 0.825985.\n",
      "Thu Sep 21 17:40:26 2023 Epoch: 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "smth:0.0679: 100%|| 41/41 [02:17<00:00,  3.35s/it]\n",
      "smth:0.0909: 100%|| 11/11 [00:39<00:00,  3.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best th: 0.2 best dc: 0.8303788770860878\n",
      "Thu Sep 21 17:43:23 2023 Fold 0, Epoch 38, lr: 0.0029899, train loss: 0.06320, valid loss: 0.09087, metric: 0.830379.\n",
      "Thu Sep 21 17:43:26 2023 Epoch: 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "smth:0.0523: 100%|| 41/41 [02:10<00:00,  3.19s/it]\n",
      "smth:0.0825: 100%|| 11/11 [00:40<00:00,  3.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best th: 0.2 best dc: 0.8460292611847365\n",
      "Thu Sep 21 17:46:17 2023 Fold 0, Epoch 39, lr: 0.0029893, train loss: 0.05246, valid loss: 0.08246, metric: 0.846029.\n",
      "metric_best (0.837615 --> 0.846029). Saving model ...\n",
      "Thu Sep 21 17:46:20 2023 Epoch: 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "smth:0.0467: 100%|| 41/41 [02:11<00:00,  3.20s/it]\n",
      "smth:0.0823: 100%|| 11/11 [00:37<00:00,  3.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best th: 0.2 best dc: 0.8351603737993903\n",
      "Thu Sep 21 17:49:09 2023 Fold 0, Epoch 40, lr: 0.0029888, train loss: 0.05282, valid loss: 0.08231, metric: 0.835160.\n",
      "Thu Sep 21 17:49:11 2023 Epoch: 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "smth:0.0591: 100%|| 41/41 [02:09<00:00,  3.16s/it]\n",
      "smth:0.0817: 100%|| 11/11 [00:38<00:00,  3.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best th: 0.2 best dc: 0.8496225631861796\n",
      "Thu Sep 21 17:51:59 2023 Fold 0, Epoch 41, lr: 0.0029882, train loss: 0.05735, valid loss: 0.08170, metric: 0.849623.\n",
      "metric_best (0.846029 --> 0.849623). Saving model ...\n",
      "Thu Sep 21 17:52:04 2023 Epoch: 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "smth:0.0544: 100%|| 41/41 [02:18<00:00,  3.38s/it]\n",
      "smth:0.0855: 100%|| 11/11 [00:37<00:00,  3.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best th: 0.2 best dc: 0.8240307513229647\n",
      "Thu Sep 21 17:55:00 2023 Fold 0, Epoch 42, lr: 0.0029876, train loss: 0.05180, valid loss: 0.08554, metric: 0.824031.\n",
      "Thu Sep 21 17:55:03 2023 Epoch: 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "smth:0.0602: 100%|| 41/41 [02:17<00:00,  3.35s/it]\n",
      "smth:0.0804: 100%|| 11/11 [00:37<00:00,  3.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best th: 0.2 best dc: 0.8439690013177733\n",
      "Thu Sep 21 17:57:58 2023 Fold 0, Epoch 43, lr: 0.0029870, train loss: 0.06274, valid loss: 0.08042, metric: 0.843969.\n",
      "Thu Sep 21 17:58:01 2023 Epoch: 44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "smth:0.0688: 100%|| 41/41 [01:52<00:00,  2.75s/it]\n",
      "smth:0.0838: 100%|| 11/11 [00:38<00:00,  3.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best th: 0.2 best dc: 0.8328267722863919\n",
      "Thu Sep 21 18:00:32 2023 Fold 0, Epoch 44, lr: 0.0029863, train loss: 0.06488, valid loss: 0.08383, metric: 0.832827.\n",
      "Thu Sep 21 18:00:35 2023 Epoch: 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "smth:0.0714: 100%|| 41/41 [01:50<00:00,  2.69s/it]\n",
      "smth:0.0995: 100%|| 11/11 [00:39<00:00,  3.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best th: 0.2 best dc: 0.8164692534570179\n",
      "Thu Sep 21 18:03:05 2023 Fold 0, Epoch 45, lr: 0.0029857, train loss: 0.07018, valid loss: 0.09953, metric: 0.816469.\n",
      "Thu Sep 21 18:03:08 2023 Epoch: 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "smth:0.0580: 100%|| 41/41 [02:07<00:00,  3.10s/it]\n",
      "smth:0.0862: 100%|| 11/11 [00:37<00:00,  3.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best th: 0.2 best dc: 0.8467535918202362\n",
      "Thu Sep 21 18:05:53 2023 Fold 0, Epoch 46, lr: 0.0029850, train loss: 0.06150, valid loss: 0.08618, metric: 0.846754.\n",
      "Thu Sep 21 18:05:55 2023 Epoch: 47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "smth:0.0600: 100%|| 41/41 [02:14<00:00,  3.28s/it]\n",
      "smth:0.0910: 100%|| 11/11 [00:37<00:00,  3.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best th: 0.2 best dc: 0.8200525622628864\n",
      "Thu Sep 21 18:08:48 2023 Fold 0, Epoch 47, lr: 0.0029844, train loss: 0.06431, valid loss: 0.09102, metric: 0.820053.\n",
      "Thu Sep 21 18:08:50 2023 Epoch: 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "smth:0.0439: 100%|| 41/41 [02:00<00:00,  2.94s/it]\n",
      "smth:0.0867: 100%|| 11/11 [00:36<00:00,  3.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best th: 0.2 best dc: 0.8320975289184693\n",
      "Thu Sep 21 18:11:28 2023 Fold 0, Epoch 48, lr: 0.0029837, train loss: 0.04876, valid loss: 0.08672, metric: 0.832098.\n",
      "Thu Sep 21 18:11:30 2023 Epoch: 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "smth:0.0577: 100%|| 41/41 [02:07<00:00,  3.10s/it]\n",
      "smth:0.0766: 100%|| 11/11 [00:41<00:00,  3.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best th: 0.2 best dc: 0.8559229853163076\n",
      "Thu Sep 21 18:14:19 2023 Fold 0, Epoch 49, lr: 0.0029830, train loss: 0.05474, valid loss: 0.07664, metric: 0.855923.\n",
      "metric_best (0.849623 --> 0.855923). Saving model ...\n",
      "Thu Sep 21 18:14:23 2023 Epoch: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "smth:0.0532: 100%|| 41/41 [01:57<00:00,  2.87s/it]\n",
      "smth:0.0816: 100%|| 11/11 [00:38<00:00,  3.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best th: 0.2 best dc: 0.8573144544297522\n",
      "Thu Sep 21 18:16:59 2023 Fold 0, Epoch 50, lr: 0.0029823, train loss: 0.05079, valid loss: 0.08162, metric: 0.857314.\n",
      "metric_best (0.855923 --> 0.857314). Saving model ...\n",
      "Thu Sep 21 18:17:03 2023 Epoch: 51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "smth:0.0540:  24%|                                                                                                | 10/41 [00:57<02:15,  4.36s/it]"
     ]
    }
   ],
   "source": [
    "run(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49237f53-51f0-4bd2-a6ec-b2b6ae5f42f1",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
