{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "354dd632-f85a-480b-bedf-d72369208016",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import ast\n",
    "import cv2\n",
    "import time\n",
    "import timm\n",
    "# import timm4smp\n",
    "import pickle\n",
    "import random\n",
    "import pydicom\n",
    "import argparse\n",
    "import warnings\n",
    "import threading\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import albumentations\n",
    "import matplotlib.pyplot as plt\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.cuda.amp as amp\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from pylab import rcParams\n",
    "\n",
    "%matplotlib inline\n",
    "device = torch.device('cuda')\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0f6cefd-fa2b-4ccc-9254-2adf48744d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    data_dir = 'data'\n",
    "    image_size_seg = (128, 128, 128)\n",
    "    msk_size = image_size_seg[0]\n",
    "    backbone_seg = 'resnet18'\n",
    "    drop_rate = 0.\n",
    "    drop_path_rate = 0.\n",
    "    n_blocks = 4\n",
    "    out_dim_seg = 5\n",
    "    \n",
    "    # cls model\n",
    "    in_chans = 6\n",
    "    backbone_cls = 'tf_efficientnetv2_s_in21ft1k'\n",
    "    image_size_cls = 224\n",
    "    n_slice_per_c = 15\n",
    "    n_ch = 5\n",
    "    out_dim = 1\n",
    "    dropout = 0.1\n",
    "    batch_size_seg = 1\n",
    "    num_workers = 2\n",
    "    device = 'cuda'\n",
    "    seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45842887-da65-4208-9b5e-0a358a8e3876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seeding done!!!\n"
     ]
    }
   ],
   "source": [
    "def seeding(SEED):\n",
    "    np.random.seed(SEED)\n",
    "    random.seed(SEED)\n",
    "    os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "    torch.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    print('seeding done!!!')\n",
    "seeding(CFG.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be6e20b9-4730-4111-81d1-4ac99d887a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dicom(path):\n",
    "    dicom = pydicom.read_file(path)\n",
    "    data = dicom.pixel_array\n",
    "    data = cv2.resize(data, (CFG.image_size_seg[0], CFG.image_size_seg[1]), interpolation = cv2.INTER_LINEAR)\n",
    "    return data\n",
    "\n",
    "def load_dicom_line_par(path):\n",
    "\n",
    "    t_paths = sorted(glob(os.path.join(path, \"*\")), key=lambda x: int(x.split('/')[-1].split(\".\")[0]))\n",
    "    \n",
    "    n_scans = len(t_paths)\n",
    "    \n",
    "    indices = np.quantile(list(range(n_scans)), np.linspace(0., 1., CFG.image_size_seg[2])).round().astype(int)\n",
    "    t_paths = [t_paths[i] for i in indices]\n",
    "\n",
    "    images = []\n",
    "    for filename in t_paths:\n",
    "        images.append(load_dicom(filename))\n",
    "    images = np.stack(images, -1)\n",
    "    \n",
    "    images = images - np.min(images)\n",
    "    images = images / (np.max(images) + 1e-4)\n",
    "    images = (images * 255).astype(np.uint8)\n",
    "\n",
    "    return images\n",
    "\n",
    "class SegTestDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df.reset_index()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.iloc[index]\n",
    "        image = load_dicom_line_par(row.dicom_folder)\n",
    "        if image.ndim < 4:\n",
    "            image = np.expand_dims(image, 0)\n",
    "        image = image.astype(np.float32).repeat(3, 0)\n",
    "        image = image / 255.\n",
    "        return torch.tensor(image).float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9a883b0-201f-46ad-8a43-5c0f6041db7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   patient_id  fold\n",
      "0       10172     0\n",
      "1       11301     0\n",
      "2       11378     0\n",
      "3       12299     0\n",
      "4       13106     0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def prepare_folds(data_path=\"data/\", k=20):\n",
    "    \"\"\"\n",
    "    Prepare data folds for cross-validation.\n",
    "    MultilabelStratifiedKFold is used.\n",
    "\n",
    "    Args:\n",
    "        data_path (str, optional): Path to the data directory. Defaults to \"../input/\".\n",
    "        k (int, optional): Number of cross-validation folds. Defaults to 4.\n",
    "\n",
    "    Returns:\n",
    "        pandas DataFrame: DataFrame containing the patient IDs and their respective fold assignments.\n",
    "    \"\"\"\n",
    "    cols = [\n",
    "        'bowel_injury', 'extravasation_injury', 'kidney_low',\n",
    "        'kidney_high', 'liver_low', 'liver_high', 'spleen_low', 'spleen_high'\n",
    "    ]\n",
    "\n",
    "    df = pd.read_csv(data_path + \"train.csv\")\n",
    "\n",
    "    from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "    mskf = MultilabelStratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    splits = mskf.split(df, y=df[cols])\n",
    "\n",
    "    df['fold'] = -1\n",
    "    for i, (_, val_idx) in enumerate(splits):\n",
    "        df.loc[val_idx, \"fold\"] = i\n",
    "\n",
    "    df_folds = df[[\"patient_id\", \"fold\"]]\n",
    "    # df_folds.to_csv(data_path + f\"stage1/folds_{k}.csv\", index=False)\n",
    "    return df_folds\n",
    "\n",
    "\n",
    "df = prepare_folds()\n",
    "valid_ = df[df['fold'] == 0].reset_index(drop=True)\n",
    "print(valid_.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "42fd63c9-64d6-407d-9a7c-f03a06b0d08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid_.to_csv('data/stage1/fold0_offical.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "912937d9-e108-42b5-a0b2-821315d916bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "237\n",
      "   index  patient_id  series_id  aortic_hu  incomplete_organ  \\\n",
      "0     19       10172      50253      158.0                 0   \n",
      "1     93       11301       2703      165.0                 0   \n",
      "2     94       11301      57412      230.0                 0   \n",
      "3    100       11378      16846      465.0                 0   \n",
      "4    101       11378      53429      128.0                 0   \n",
      "\n",
      "                    dicom_folder  fold  \n",
      "0  data/train_images/10172/50253     0  \n",
      "1   data/train_images/11301/2703     0  \n",
      "2  data/train_images/11301/57412     0  \n",
      "3  data/train_images/11378/16846     0  \n",
      "4  data/train_images/11378/53429     0  \n"
     ]
    }
   ],
   "source": [
    "def is_folder_empty(folder_path):\n",
    "    return os.path.exists(folder_path) == 0\n",
    "\n",
    "df = pd.read_csv(os.path.join(CFG.data_dir, 'train_series_meta.csv'))\n",
    "df['dicom_folder'] = CFG.data_dir + '/train_images/' + df.patient_id.astype(str) + '/' + df.series_id.astype(str)\n",
    "\n",
    "df['IsEmpty'] = df['dicom_folder'].apply(is_folder_empty)\n",
    "df = df[~df['IsEmpty']]\n",
    "df = df.drop(columns=['IsEmpty'])\n",
    "df = df.reset_index()\n",
    "df = pd.merge(df, valid_, on='patient_id', how='inner')\n",
    "print(len(df))\n",
    "print(df.head())\n",
    "# df = df.merge(valid_, on='series_id', how='left')\n",
    "# print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0050a10b-cd57-43e8-9001-924776c4811d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_seg = SegTestDataset(df)\n",
    "loader_seg = torch.utils.data.DataLoader(dataset_seg, batch_size=CFG.batch_size_seg, shuffle=False, num_workers=CFG.num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96456077-812b-470a-bb48-eccfd015c16c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load segmodel successfull!\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import timm\n",
    "import segmentation_models_pytorch as smp\n",
    "from timm.layers import Conv2dSame\n",
    "# from conv3d_same import Conv3dSame\n",
    "\n",
    "\n",
    "class TimmSegModel(nn.Module):\n",
    "    def __init__(self, backbone, segtype='unet', pretrained=False):\n",
    "        super(TimmSegModel, self).__init__()\n",
    "\n",
    "        self.encoder = timm.create_model(\n",
    "            backbone,\n",
    "            in_chans=3,\n",
    "            features_only=True,\n",
    "            drop_rate=CFG.drop_rate,\n",
    "            drop_path_rate=CFG.drop_path_rate,\n",
    "            pretrained=pretrained\n",
    "        )\n",
    "        g = self.encoder(torch.rand(1, 3, 64, 64))\n",
    "        encoder_channels = [1] + [_.shape[1] for _ in g]\n",
    "        decoder_channels = [256, 128, 64, 32, 16]\n",
    "        n_blocks = CFG.n_blocks\n",
    "        if segtype == 'unet':\n",
    "            self.decoder = smp.decoders.unet.decoder.UnetDecoder(\n",
    "                encoder_channels=encoder_channels[:n_blocks+1],\n",
    "                decoder_channels=decoder_channels[:n_blocks],\n",
    "                n_blocks=n_blocks,\n",
    "            )\n",
    "\n",
    "        self.segmentation_head = nn.Conv2d(decoder_channels[n_blocks-1], CFG.out_dim_seg, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "\n",
    "    def forward(self,x):\n",
    "        global_features = [0] + self.encoder(x)[:CFG.n_blocks]\n",
    "        seg_features = self.decoder(*global_features)\n",
    "        seg_features = self.segmentation_head(seg_features)\n",
    "        return seg_features\n",
    "\n",
    "\n",
    "def convert_3d(module):\n",
    "    module_output = module\n",
    "    if isinstance(module, torch.nn.BatchNorm2d):\n",
    "        module_output = torch.nn.BatchNorm3d(\n",
    "            module.num_features,\n",
    "            module.eps,\n",
    "            module.momentum,\n",
    "            module.affine,\n",
    "            module.track_running_stats,\n",
    "        )\n",
    "        if module.affine:\n",
    "            with torch.no_grad():\n",
    "                module_output.weight = module.weight\n",
    "                module_output.bias = module.bias\n",
    "        module_output.running_mean = module.running_mean\n",
    "        module_output.running_var = module.running_var\n",
    "        module_output.num_batches_tracked = module.num_batches_tracked\n",
    "        if hasattr(module, \"qconfig\"):\n",
    "            module_output.qconfig = module.qconfig\n",
    "            \n",
    "    # elif isinstance(module, Conv2dSame):\n",
    "    #     module_output = Conv3dSame(\n",
    "    #         in_channels=module.in_channels,\n",
    "    #         out_channels=module.out_channels,\n",
    "    #         kernel_size=module.kernel_size[0],\n",
    "    #         stride=module.stride[0],\n",
    "    #         padding=module.padding[0],\n",
    "    #         dilation=module.dilation[0],\n",
    "    #         groups=module.groups,\n",
    "    #         bias=module.bias is not None,\n",
    "    #     )\n",
    "    #     module_output.weight = torch.nn.Parameter(module.weight.unsqueeze(-1).repeat(1,1,1,1,module.kernel_size[0]))\n",
    "\n",
    "    elif isinstance(module, torch.nn.Conv2d):\n",
    "        module_output = torch.nn.Conv3d(\n",
    "            in_channels=module.in_channels,\n",
    "            out_channels=module.out_channels,\n",
    "            kernel_size=module.kernel_size[0],\n",
    "            stride=module.stride[0],\n",
    "            padding=module.padding[0],\n",
    "            dilation=module.dilation[0],\n",
    "            groups=module.groups,\n",
    "            bias=module.bias is not None,\n",
    "            padding_mode=module.padding_mode\n",
    "        )\n",
    "        module_output.weight = torch.nn.Parameter(module.weight.unsqueeze(-1).repeat(1,1,1,1,module.kernel_size[0]))\n",
    "\n",
    "    elif isinstance(module, torch.nn.MaxPool2d):\n",
    "        module_output = torch.nn.MaxPool3d(\n",
    "            kernel_size=module.kernel_size,\n",
    "            stride=module.stride,\n",
    "            padding=module.padding,\n",
    "            dilation=module.dilation,\n",
    "            ceil_mode=module.ceil_mode,\n",
    "        )\n",
    "    elif isinstance(module, torch.nn.AvgPool2d):\n",
    "        module_output = torch.nn.AvgPool3d(\n",
    "            kernel_size=module.kernel_size,\n",
    "            stride=module.stride,\n",
    "            padding=module.padding,\n",
    "            ceil_mode=module.ceil_mode,\n",
    "        )\n",
    "\n",
    "    for name, child in module.named_children():\n",
    "        module_output.add_module(\n",
    "            name, convert_3d(child)\n",
    "        )\n",
    "    del module\n",
    "\n",
    "    return module_output\n",
    "\n",
    "\n",
    "# load model\n",
    "model_seg_path = 'weights'\n",
    "seg_model = TimmSegModel(CFG.backbone_seg, pretrained=False)\n",
    "seg_model = convert_3d(seg_model)\n",
    "seg_model = seg_model.to(CFG.device)\n",
    "load_model_file = os.path.join(model_seg_path, 'resnet18_fold0_best.pth')\n",
    "sd = torch.load(load_model_file)\n",
    "if 'model_state_dict' in sd.keys():\n",
    "    sd = sd['model_state_dict']\n",
    "sd = {k[7:] if k.startswith('module.') else k: sd[k] for k in sd.keys()}\n",
    "seg_model.load_state_dict(sd, strict=True)\n",
    "seg_model.eval()\n",
    "print('load segmodel successfull!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32c88d9b-5f15-4569-805e-a4e405376d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data1/ocr_ie/anaconda3/envs/rsna/lib/python3.8/site-packages/timm/models/_factory.py:114: UserWarning: Mapping deprecated model name tf_efficientnetv2_s_in21ft1k to current tf_efficientnetv2_s.in21k_ft_in1k.\n",
      "  model = create_fn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cls_model succesfull for 1 models!\n"
     ]
    }
   ],
   "source": [
    "from itertools import repeat\n",
    "\n",
    "\n",
    "class SpatialDropout(nn.Module):\n",
    "    def __init__(self, drop=0.5):\n",
    "        super(SpatialDropout, self).__init__()\n",
    "        self.drop = drop\n",
    "        \n",
    "    def forward(self, inputs, noise_shape=None):\n",
    "        \"\"\"\n",
    "        @param: inputs, tensor\n",
    "        @param: noise_shape, tuple\n",
    "        \"\"\"\n",
    "        outputs = inputs.clone()\n",
    "        if noise_shape is None:\n",
    "            noise_shape = (inputs.shape[0], *repeat(1, inputs.dim()-2), inputs.shape[-1]) \n",
    "        \n",
    "        self.noise_shape = noise_shape\n",
    "        if not self.training or self.drop == 0:\n",
    "            return inputs\n",
    "        else:\n",
    "            noises = self._make_noises(inputs)\n",
    "            if self.drop == 1:\n",
    "                noises.fill_(0.0)\n",
    "            else:\n",
    "                noises.bernoulli_(1 - self.drop).div_(1 - self.drop)\n",
    "            noises = noises.expand_as(inputs)    \n",
    "            outputs.mul_(noises)\n",
    "            return outputs\n",
    "            \n",
    "    def _make_noises(self, inputs):\n",
    "        return inputs.new().resize_(self.noise_shape)\n",
    "\n",
    "\n",
    "class MLPAttentionNetwork(nn.Module):\n",
    " \n",
    "    def __init__(self, hidden_dim, attention_dim=None):\n",
    "        super(MLPAttentionNetwork, self).__init__()\n",
    " \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.attention_dim = attention_dim\n",
    "        if self.attention_dim is None:\n",
    "            self.attention_dim = self.hidden_dim\n",
    "        # W * x + b\n",
    "        self.proj_w = nn.Linear(self.hidden_dim, self.attention_dim, bias=True)\n",
    "        # v.T\n",
    "        self.proj_v = nn.Linear(self.attention_dim, 1, bias=False)\n",
    " \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        :param x: seq_len, batch_size, hidden_dim\n",
    "        :return: batch_size * seq_len, batch_size * hidden_dim\n",
    "        \"\"\"\n",
    "        # print(f\"x shape:{x.shape}\")\n",
    "        batch_size, seq_len, _ = x.size()\n",
    "        # flat_inputs = x.reshape(-1, self.hidden_dim) # (batch_size*seq_len, hidden_dim)\n",
    "        # print(f\"flat_inputs shape:{flat_inputs.shape}\")\n",
    "        \n",
    "        H = torch.tanh(self.proj_w(x)) # (batch_size, seq_len, hidden_dim)\n",
    "        # print(f\"H shape:{H.shape}\")\n",
    "        \n",
    "        att_scores = torch.softmax(self.proj_v(H),axis=1) # (batch_size, seq_len)\n",
    "        # print(f\"att_scores shape:{att_scores.shape}\")\n",
    "        \n",
    "        attn_x = (x * att_scores).sum(1) # (batch_size, hidden_dim)\n",
    "        # print(f\"attn_x shape:{attn_x.shape}\")\n",
    "        return attn_x\n",
    "\n",
    "class TimmModel2(nn.Module):\n",
    "    def __init__(self, backbone, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.encoder = timm.create_model(\n",
    "            backbone,\n",
    "            in_chans=CFG.in_chans,\n",
    "            num_classes=CFG.out_dim,\n",
    "            features_only=False,\n",
    "            drop_rate=CFG.drop_rate,\n",
    "            drop_path_rate=CFG.drop_path_rate,\n",
    "            pretrained=pretrained\n",
    "        )\n",
    "        \n",
    "        hdim = self.encoder.conv_head.out_channels\n",
    "        self.encoder.classifier = nn.Identity()\n",
    "        \n",
    "        self.spatialdropout = SpatialDropout(CFG.dropout)\n",
    "        self.gru = nn.GRU(hdim, 256, 2, batch_first=True, bidirectional=True)\n",
    "        self.mlp_attention_layer = MLPAttentionNetwork(512)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(0),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(256, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):  # (bs, nslice, ch, sz, sz)\n",
    "        bs = x.shape[0]\n",
    "        x = x.view(bs * CFG.n_slice_per_c, CFG.in_chans, CFG.image_size_cls, CFG.image_size_cls)\n",
    "        feat = self.encoder(x)\n",
    "        feat = self.spatialdropout(feat)\n",
    "        feat = feat.view(bs, CFG.n_slice_per_c, -1)\n",
    "        feat, _ = self.gru(feat)\n",
    "        feat = self.mlp_attention_layer(feat) # [bs, 512]\n",
    "        # feat = feat.contiguous().view(bs * CFG.n_slice_per_c, -1)\n",
    "        feat = self.head(feat)\n",
    "        # feat = feat.view(bs, CFG.n_slice_per_c).contiguous()\n",
    "        # feat = self.mean_layer(feat)\n",
    "        feat = feat.view(bs, -1)\n",
    "        return feat\n",
    "\n",
    "\n",
    "# load cls model\n",
    "model_cls_path = 'weights'\n",
    "cls_models = []\n",
    "\n",
    "for idx_fold in range(1):\n",
    "    cls_model = TimmModel2(CFG.backbone_cls, pretrained=False)\n",
    "    load_cls_model_file = os.path.join(model_cls_path, f'filter_stage2_tf_efficientnetv2_s_in21ft1k_fold{idx_fold}_last.pth')\n",
    "    sd = torch.load(load_cls_model_file, map_location='cpu')\n",
    "    if 'model_state_dict' in sd.keys():\n",
    "        sd = sd['model_state_dict']\n",
    "    sd = {k[7:] if k.startswith('module.') else k: sd[k] for k in sd.keys()}\n",
    "    cls_model.load_state_dict(sd, strict=True)\n",
    "    cls_model = cls_model.to(device)\n",
    "    cls_model.eval()\n",
    "    cls_models.append(cls_model)\n",
    "print(f'load cls_model succesfull for {len(cls_models)} models!')\n",
    "\n",
    "\n",
    "# class Timm1BoneModel(nn.Module):\n",
    "#     def __init__(self, backbone, image_size, pretrained=False):\n",
    "#         super(Timm1BoneModel, self).__init__()\n",
    "#         self.image_size = image_size\n",
    "\n",
    "#         self.encoder = timm.create_model(\n",
    "#             backbone,\n",
    "#             in_chans=CFG.in_chans,\n",
    "#             num_classes=1,\n",
    "#             features_only=False,\n",
    "#             drop_rate=0,\n",
    "#             drop_path_rate=0,\n",
    "#             pretrained=pretrained\n",
    "#         )\n",
    "\n",
    "#         if 'efficient' in backbone:\n",
    "#             hdim = self.encoder.conv_head.out_channels\n",
    "#             self.encoder.classifier = nn.Identity()\n",
    "#         elif 'convnext' in backbone or 'nfnet' in backbone:\n",
    "#             hdim = self.encoder.head.fc.in_features\n",
    "#             self.encoder.head.fc = nn.Identity()\n",
    "\n",
    "#         self.lstm = nn.LSTM(hdim, 256, num_layers=2, dropout=0, bidirectional=True, batch_first=True)\n",
    "#         self.head = nn.Sequential(\n",
    "#             nn.Linear(512, 256),\n",
    "#             nn.BatchNorm1d(256),\n",
    "#             nn.Dropout(0),\n",
    "#             nn.LeakyReLU(0.1),\n",
    "#             nn.Linear(256, 1),\n",
    "#         )\n",
    "\n",
    "\n",
    "#     def forward(self, x):  # (bs, nslice, ch, sz, sz)\n",
    "#         bs = x.shape[0]\n",
    "#         x = x.view(bs * CFG.n_slice_per_c, CFG.in_chans, self.image_size_cls, self.image_size_cls)\n",
    "#         feat = self.encoder(x)\n",
    "#         feat = feat.view(bs, CFG.n_slice_per_c, -1)\n",
    "#         feat, _ = self.lstm(feat)\n",
    "#         feat = feat.contiguous().view(bs * CFG.n_slice_per_c, -1)\n",
    "#         feat = self.head(feat)\n",
    "#         feat = feat.view(bs, CFG.n_slice_per_c).contiguous()\n",
    "\n",
    "#         return feat\n",
    "\n",
    "\n",
    "# load cls model\n",
    "# model_cls_path = 'weights'\n",
    "# cls_models = []\n",
    "\n",
    "# for idx_fold in range(1):\n",
    "#     cls_model = Timm2BoneModel(CFG.backbone_cls, pretrained=False)\n",
    "#     load_cls_model_file = os.path.join(model_cls_path, f'filter_stage2_tf_efficientnetv2_s_in21ft1k_fold{idx_fold}_best078.pth')\n",
    "#     sd = torch.load(load_cls_model_file, map_location='cpu')\n",
    "#     if 'model_state_dict' in sd.keys():\n",
    "#         sd = sd['model_state_dict']\n",
    "#     sd = {k[7:] if k.startswith('module.') else k: sd[k] for k in sd.keys()}\n",
    "#     cls_model.load_state_dict(sd, strict=True)\n",
    "#     cls_model = cls_model.to(device)\n",
    "#     cls_model.eval()\n",
    "#     cls_models.append(cls_model)\n",
    "# print(f'load cls_model succesfull for {len(cls_models)} models!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fcaa6278-1ed9-4588-abdf-771131097354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start with index 0\n",
      "path data/train_images/10172/50253 with total 394 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[ 0.4385],\n",
      "        [ 0.5184],\n",
      "        [-0.5392],\n",
      "        [-5.5657],\n",
      "        [-0.4836]], device='cuda:0')\n",
      "tensor([[0.6079, 0.6268, 0.3684, 0.0038, 0.3814]], device='cuda:0')\n",
      "start with index 1\n",
      "path data/train_images/11301/2703 with total 170 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-5.1624],\n",
      "        [ 3.1177],\n",
      "        [-3.1212],\n",
      "        [-3.7280],\n",
      "        [-6.4215]], device='cuda:0')\n",
      "tensor([[0.0057, 0.9576, 0.0422, 0.0235, 0.0016]], device='cuda:0')\n",
      "start with index 2\n",
      "path data/train_images/11301/57412 with total 116 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-4.3892],\n",
      "        [ 3.5958],\n",
      "        [-1.9903],\n",
      "        [-4.0156],\n",
      "        [-6.1013]], device='cuda:0')\n",
      "tensor([[0.0123, 0.9733, 0.1202, 0.0177, 0.0022]], device='cuda:0')\n",
      "start with index 3\n",
      "path data/train_images/11378/16846 with total 571 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-4.6862],\n",
      "        [-4.8059],\n",
      "        [-1.2102],\n",
      "        [ 2.9938],\n",
      "        [-5.2542]], device='cuda:0')\n",
      "tensor([[0.0091, 0.0081, 0.2297, 0.9523, 0.0052]], device='cuda:0')\n",
      "start with index 4\n",
      "path data/train_images/11378/53429 with total 578 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-2.5756],\n",
      "        [-5.4519],\n",
      "        [ 0.1726],\n",
      "        [ 2.4502],\n",
      "        [-4.1791]], device='cuda:0')\n",
      "tensor([[0.0707, 0.0043, 0.5430, 0.9206, 0.0151]], device='cuda:0')\n",
      "start with index 5\n",
      "path data/train_images/12299/29733 with total 103 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-3.7774],\n",
      "        [-0.3361],\n",
      "        [-3.7526],\n",
      "        [-1.8271],\n",
      "        [-6.6126]], device='cuda:0')\n",
      "tensor([[0.0224, 0.4168, 0.0229, 0.1386, 0.0013]], device='cuda:0')\n",
      "start with index 6\n",
      "path data/train_images/12299/47275 with total 127 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-2.8193],\n",
      "        [-1.1322],\n",
      "        [-3.8417],\n",
      "        [-1.8285],\n",
      "        [-8.4266]], device='cuda:0')\n",
      "tensor([[5.6291e-02, 2.4376e-01, 2.1006e-02, 1.3842e-01, 2.1891e-04]],\n",
      "       device='cuda:0')\n",
      "start with index 7\n",
      "path data/train_images/13106/12049 with total 378 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-0.8632],\n",
      "        [ 0.3340],\n",
      "        [ 0.9756],\n",
      "        [ 1.1346],\n",
      "        [-0.7092]], device='cuda:0')\n",
      "tensor([[0.2967, 0.5827, 0.7262, 0.7567, 0.3298]], device='cuda:0')\n",
      "start with index 8\n",
      "path data/train_images/13106/5011 with total 297 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-1.9572],\n",
      "        [ 1.2378],\n",
      "        [ 0.9561],\n",
      "        [ 2.2463],\n",
      "        [ 0.1883]], device='cuda:0')\n",
      "tensor([[0.1238, 0.7752, 0.7223, 0.9043, 0.5469]], device='cuda:0')\n",
      "start with index 9\n",
      "path data/train_images/13182/45080 with total 666 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[ 1.3584],\n",
      "        [-0.4726],\n",
      "        [-5.4409],\n",
      "        [-3.3083],\n",
      "        [-5.4234]], device='cuda:0')\n",
      "tensor([[0.7955, 0.3840, 0.0043, 0.0353, 0.0044]], device='cuda:0')\n",
      "start with index 10\n",
      "path data/train_images/13250/26989 with total 145 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-3.4918],\n",
      "        [-0.8731],\n",
      "        [-2.1963],\n",
      "        [-1.8742],\n",
      "        [-6.6829]], device='cuda:0')\n",
      "tensor([[0.0295, 0.2946, 0.1001, 0.1331, 0.0013]], device='cuda:0')\n",
      "start with index 11\n",
      "path data/train_images/13250/64604 with total 92 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-3.3597],\n",
      "        [-0.6294],\n",
      "        [-4.3727],\n",
      "        [-3.4340],\n",
      "        [-7.2233]], device='cuda:0')\n",
      "tensor([[0.0336, 0.3476, 0.0125, 0.0312, 0.0007]], device='cuda:0')\n",
      "start with index 12\n",
      "path data/train_images/13403/21078 with total 62 scan\n",
      "except process fail 3\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-4.0053],\n",
      "        [-4.8306],\n",
      "        [-0.0883],\n",
      "        [ 2.0821],\n",
      "        [-5.8741]], device='cuda:0')\n",
      "tensor([[0.0179, 0.0079, 0.4780, 0.8892, 0.0028]], device='cuda:0')\n",
      "start with index 13\n",
      "path data/train_images/13403/64814 with total 225 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-2.2189],\n",
      "        [-4.0069],\n",
      "        [-2.4608],\n",
      "        [-6.1503],\n",
      "        [-0.7728]], device='cuda:0')\n",
      "tensor([[0.0981, 0.0179, 0.0787, 0.0021, 0.3159]], device='cuda:0')\n",
      "start with index 14\n",
      "path data/train_images/13623/19360 with total 71 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-3.4244],\n",
      "        [ 5.6769],\n",
      "        [ 2.8084],\n",
      "        [ 0.5356],\n",
      "        [-6.5378]], device='cuda:0')\n",
      "tensor([[0.0315, 0.9966, 0.9431, 0.6308, 0.0014]], device='cuda:0')\n",
      "start with index 15\n",
      "path data/train_images/13623/24645 with total 189 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-1.6153],\n",
      "        [ 2.5674],\n",
      "        [ 1.1101],\n",
      "        [-4.9218],\n",
      "        [-5.2963]], device='cuda:0')\n",
      "tensor([[0.1659, 0.9287, 0.7522, 0.0072, 0.0050]], device='cuda:0')\n",
      "start with index 16\n",
      "path data/train_images/14616/23054 with total 582 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-3.5179],\n",
      "        [-3.8111],\n",
      "        [-0.4975],\n",
      "        [ 0.9254],\n",
      "        [-1.3441]], device='cuda:0')\n",
      "tensor([[0.0288, 0.0216, 0.3781, 0.7161, 0.2068]], device='cuda:0')\n",
      "start with index 17\n",
      "path data/train_images/14616/32437 with total 386 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-2.5536],\n",
      "        [-0.5696],\n",
      "        [-3.9542],\n",
      "        [-1.2896],\n",
      "        [-0.9688]], device='cuda:0')\n",
      "tensor([[0.0722, 0.3613, 0.0188, 0.2159, 0.2751]], device='cuda:0')\n",
      "start with index 18\n",
      "path data/train_images/14831/40855 with total 177 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-7.4653],\n",
      "        [-5.0703],\n",
      "        [-0.7923],\n",
      "        [-2.4265],\n",
      "        [-1.8776]], device='cuda:0')\n",
      "tensor([[0.0006, 0.0062, 0.3117, 0.0812, 0.1327]], device='cuda:0')\n",
      "start with index 19\n",
      "path data/train_images/14831/58727 with total 108 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-6.9543],\n",
      "        [-5.4378],\n",
      "        [-2.5835],\n",
      "        [-2.0912],\n",
      "        [-4.8913]], device='cuda:0')\n",
      "tensor([[0.0010, 0.0043, 0.0702, 0.1100, 0.0075]], device='cuda:0')\n",
      "start with index 20\n",
      "path data/train_images/14846/42425 with total 743 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-1.4457],\n",
      "        [-4.1226],\n",
      "        [-2.5826],\n",
      "        [-2.5424],\n",
      "        [-5.3928]], device='cuda:0')\n",
      "tensor([[0.1907, 0.0159, 0.0703, 0.0729, 0.0045]], device='cuda:0')\n",
      "start with index 21\n",
      "path data/train_images/15404/26757 with total 117 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-4.3037],\n",
      "        [-4.9832],\n",
      "        [-0.9113],\n",
      "        [-1.3912],\n",
      "        [-5.2735]], device='cuda:0')\n",
      "tensor([[0.0133, 0.0068, 0.2867, 0.1992, 0.0051]], device='cuda:0')\n",
      "start with index 22\n",
      "path data/train_images/15419/46641 with total 217 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-1.9684],\n",
      "        [ 0.4875],\n",
      "        [-0.9485],\n",
      "        [-1.7568],\n",
      "        [-4.9578]], device='cuda:0')\n",
      "tensor([[0.1226, 0.6195, 0.2792, 0.1472, 0.0070]], device='cuda:0')\n",
      "start with index 23\n",
      "path data/train_images/15620/3836 with total 122 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[ 0.2517],\n",
      "        [ 5.6882],\n",
      "        [-2.8179],\n",
      "        [-0.5461],\n",
      "        [-1.7109]], device='cuda:0')\n",
      "tensor([[0.5626, 0.9966, 0.0564, 0.3668, 0.1530]], device='cuda:0')\n",
      "start with index 24\n",
      "path data/train_images/15620/59366 with total 166 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[ 0.3360],\n",
      "        [ 5.2035],\n",
      "        [-1.9891],\n",
      "        [-0.5262],\n",
      "        [-5.1447]], device='cuda:0')\n",
      "tensor([[0.5832, 0.9945, 0.1203, 0.3714, 0.0058]], device='cuda:0')\n",
      "start with index 25\n",
      "path data/train_images/16198/10772 with total 64 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-3.7154],\n",
      "        [ 2.0891],\n",
      "        [-1.4278],\n",
      "        [-1.4298],\n",
      "        [-6.4859]], device='cuda:0')\n",
      "tensor([[0.0238, 0.8898, 0.1934, 0.1931, 0.0015]], device='cuda:0')\n",
      "start with index 26\n",
      "path data/train_images/16198/24428 with total 90 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-2.6716],\n",
      "        [-2.2843],\n",
      "        [-5.4560],\n",
      "        [-4.0211],\n",
      "        [-6.3900]], device='cuda:0')\n",
      "tensor([[0.0647, 0.0924, 0.0043, 0.0176, 0.0017]], device='cuda:0')\n",
      "start with index 27\n",
      "path data/train_images/16202/36885 with total 740 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-2.7568],\n",
      "        [-0.7993],\n",
      "        [-5.5061],\n",
      "        [-3.0834],\n",
      "        [-6.8159]], device='cuda:0')\n",
      "tensor([[0.0597, 0.3102, 0.0040, 0.0438, 0.0011]], device='cuda:0')\n",
      "start with index 28\n",
      "path data/train_images/16368/15406 with total 119 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-1.0394],\n",
      "        [-3.5768],\n",
      "        [-3.3811],\n",
      "        [ 0.4791],\n",
      "        [-4.6491]], device='cuda:0')\n",
      "tensor([[0.2613, 0.0272, 0.0329, 0.6175, 0.0095]], device='cuda:0')\n",
      "start with index 29\n",
      "path data/train_images/16450/30471 with total 157 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-1.2529],\n",
      "        [-0.4364],\n",
      "        [-5.0133],\n",
      "        [-4.5779],\n",
      "        [-4.0052]], device='cuda:0')\n",
      "tensor([[0.2222, 0.3926, 0.0066, 0.0102, 0.0179]], device='cuda:0')\n",
      "start with index 30\n",
      "path data/train_images/16450/32436 with total 106 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-3.6777],\n",
      "        [-0.8846],\n",
      "        [-3.2123],\n",
      "        [-3.4350],\n",
      "        [-3.0974]], device='cuda:0')\n",
      "tensor([[0.0247, 0.2922, 0.0387, 0.0312, 0.0432]], device='cuda:0')\n",
      "start with index 31\n",
      "path data/train_images/16691/35894 with total 1060 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-4.5389],\n",
      "        [-2.0330],\n",
      "        [-8.1318],\n",
      "        [-5.1614],\n",
      "        [-3.4620]], device='cuda:0')\n",
      "tensor([[0.0106, 0.1158, 0.0003, 0.0057, 0.0304]], device='cuda:0')\n",
      "start with index 32\n",
      "path data/train_images/16691/60898 with total 1028 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-5.4861],\n",
      "        [-2.2229],\n",
      "        [-6.7390],\n",
      "        [-7.7587],\n",
      "        [-6.9601]], device='cuda:0')\n",
      "tensor([[0.0041, 0.0977, 0.0012, 0.0004, 0.0009]], device='cuda:0')\n",
      "start with index 33\n",
      "path data/train_images/17439/54088 with total 732 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-3.8011],\n",
      "        [-1.6745],\n",
      "        [-2.0074],\n",
      "        [-3.0319],\n",
      "        [-5.0798]], device='cuda:0')\n",
      "tensor([[0.0219, 0.1578, 0.1184, 0.0460, 0.0062]], device='cuda:0')\n",
      "start with index 34\n",
      "path data/train_images/1900/48371 with total 669 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[ 4.3160],\n",
      "        [-3.1470],\n",
      "        [-5.4440],\n",
      "        [-5.6251],\n",
      "        [-6.7344]], device='cuda:0')\n",
      "tensor([[0.9868, 0.0412, 0.0043, 0.0036, 0.0012]], device='cuda:0')\n",
      "start with index 35\n",
      "path data/train_images/19160/13111 with total 167 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[ 0.0852],\n",
      "        [-0.5554],\n",
      "        [-1.2385],\n",
      "        [-3.6701],\n",
      "        [-5.7392]], device='cuda:0')\n",
      "tensor([[0.5213, 0.3646, 0.2247, 0.0248, 0.0032]], device='cuda:0')\n",
      "start with index 36\n",
      "path data/train_images/19160/54793 with total 95 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[ 2.5446],\n",
      "        [-0.2019],\n",
      "        [-3.9757],\n",
      "        [-2.4922],\n",
      "        [-6.3081]], device='cuda:0')\n",
      "tensor([[0.9272, 0.4497, 0.0184, 0.0764, 0.0018]], device='cuda:0')\n",
      "start with index 37\n",
      "path data/train_images/19263/38576 with total 183 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[ 2.0484],\n",
      "        [-2.7754],\n",
      "        [-5.8068],\n",
      "        [-5.2778],\n",
      "        [-4.9544]], device='cuda:0')\n",
      "tensor([[0.8858, 0.0587, 0.0030, 0.0051, 0.0070]], device='cuda:0')\n",
      "start with index 38\n",
      "path data/train_images/19263/42431 with total 166 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[ 2.8368],\n",
      "        [ 0.5418],\n",
      "        [-5.2368],\n",
      "        [-5.1866],\n",
      "        [-5.2501]], device='cuda:0')\n",
      "tensor([[0.9446, 0.6322, 0.0053, 0.0056, 0.0052]], device='cuda:0')\n",
      "start with index 39\n",
      "path data/train_images/19314/42836 with total 687 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-4.9464],\n",
      "        [-3.2579],\n",
      "        [-1.6640],\n",
      "        [-3.9100],\n",
      "        [-4.8560]], device='cuda:0')\n",
      "tensor([[0.0071, 0.0370, 0.1592, 0.0196, 0.0077]], device='cuda:0')\n",
      "start with index 40\n",
      "path data/train_images/19344/25973 with total 228 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[ 2.3378],\n",
      "        [-4.0258],\n",
      "        [-2.4798],\n",
      "        [-2.8261],\n",
      "        [-2.9512]], device='cuda:0')\n",
      "tensor([[0.9120, 0.0175, 0.0773, 0.0559, 0.0497]], device='cuda:0')\n",
      "start with index 41\n",
      "path data/train_images/19344/55832 with total 513 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[ 3.0980],\n",
      "        [-4.5124],\n",
      "        [-3.2988],\n",
      "        [-1.6846],\n",
      "        [-3.9312]], device='cuda:0')\n",
      "tensor([[0.9568, 0.0109, 0.0356, 0.1565, 0.0192]], device='cuda:0')\n",
      "start with index 42\n",
      "path data/train_images/19865/24191 with total 684 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[ 1.4333],\n",
      "        [ 0.8521],\n",
      "        [ 1.9466],\n",
      "        [-2.6224],\n",
      "        [-6.4728]], device='cuda:0')\n",
      "tensor([[0.8074, 0.7010, 0.8751, 0.0677, 0.0015]], device='cuda:0')\n",
      "start with index 43\n",
      "path data/train_images/19865/54445 with total 675 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-2.5957],\n",
      "        [-0.9657],\n",
      "        [-1.6390],\n",
      "        [-2.1464],\n",
      "        [-5.9850]], device='cuda:0')\n",
      "tensor([[0.0694, 0.2757, 0.1626, 0.1047, 0.0025]], device='cuda:0')\n",
      "start with index 44\n",
      "path data/train_images/19916/42815 with total 83 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-5.8961],\n",
      "        [-4.0550],\n",
      "        [ 0.2420],\n",
      "        [-2.6796],\n",
      "        [-7.1445]], device='cuda:0')\n",
      "tensor([[0.0027, 0.0170, 0.5602, 0.0642, 0.0008]], device='cuda:0')\n",
      "start with index 45\n",
      "path data/train_images/20689/14184 with total 644 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-5.6468],\n",
      "        [-2.2024],\n",
      "        [-1.3527],\n",
      "        [-6.0333],\n",
      "        [-6.9250]], device='cuda:0')\n",
      "tensor([[0.0035, 0.0995, 0.2054, 0.0024, 0.0010]], device='cuda:0')\n",
      "start with index 46\n",
      "path data/train_images/20689/48572 with total 466 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-4.0235],\n",
      "        [-0.8182],\n",
      "        [-0.6094],\n",
      "        [-2.9155],\n",
      "        [-6.6342]], device='cuda:0')\n",
      "tensor([[0.0176, 0.3061, 0.3522, 0.0514, 0.0013]], device='cuda:0')\n",
      "start with index 47\n",
      "path data/train_images/21407/39514 with total 104 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[ 1.2584],\n",
      "        [ 3.6179],\n",
      "        [-5.1667],\n",
      "        [-3.2279],\n",
      "        [-4.2006]], device='cuda:0')\n",
      "tensor([[0.7787, 0.9739, 0.0057, 0.0381, 0.0148]], device='cuda:0')\n",
      "start with index 48\n",
      "path data/train_images/21407/52478 with total 159 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-1.2553],\n",
      "        [ 2.0158],\n",
      "        [-3.3203],\n",
      "        [-3.3753],\n",
      "        [-4.3728]], device='cuda:0')\n",
      "tensor([[0.2218, 0.8824, 0.0349, 0.0331, 0.0125]], device='cuda:0')\n",
      "start with index 49\n",
      "path data/train_images/21734/35796 with total 709 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-0.6032],\n",
      "        [-3.1740],\n",
      "        [ 0.0727],\n",
      "        [-3.0445],\n",
      "        [-5.9148]], device='cuda:0')\n",
      "tensor([[0.3536, 0.0402, 0.5182, 0.0455, 0.0027]], device='cuda:0')\n",
      "start with index 50\n",
      "path data/train_images/21734/4209 with total 276 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-4.6750],\n",
      "        [-2.8130],\n",
      "        [-1.5853],\n",
      "        [-2.4868],\n",
      "        [-5.0588]], device='cuda:0')\n",
      "tensor([[0.0092, 0.0566, 0.1701, 0.0768, 0.0063]], device='cuda:0')\n",
      "start with index 51\n",
      "path data/train_images/22005/35053 with total 632 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-2.5196],\n",
      "        [-0.8276],\n",
      "        [-0.8354],\n",
      "        [-1.4928],\n",
      "        [-5.2702]], device='cuda:0')\n",
      "tensor([[0.0745, 0.3041, 0.3025, 0.1835, 0.0051]], device='cuda:0')\n",
      "start with index 52\n",
      "path data/train_images/22113/21664 with total 623 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-2.1918],\n",
      "        [-5.2612],\n",
      "        [-3.7852],\n",
      "        [-5.6683],\n",
      "        [-4.8017]], device='cuda:0')\n",
      "tensor([[0.1005, 0.0052, 0.0222, 0.0034, 0.0081]], device='cuda:0')\n",
      "start with index 53\n",
      "path data/train_images/22132/52078 with total 473 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-1.9673],\n",
      "        [-1.5232],\n",
      "        [-4.6937],\n",
      "        [-2.5005],\n",
      "        [-5.0886]], device='cuda:0')\n",
      "tensor([[0.1227, 0.1790, 0.0091, 0.0758, 0.0061]], device='cuda:0')\n",
      "start with index 54\n",
      "path data/train_images/22132/62262 with total 384 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-1.5482],\n",
      "        [ 0.3716],\n",
      "        [-2.6660],\n",
      "        [-2.2794],\n",
      "        [-6.9955]], device='cuda:0')\n",
      "tensor([[0.1753, 0.5919, 0.0650, 0.0928, 0.0009]], device='cuda:0')\n",
      "start with index 55\n",
      "path data/train_images/2288/58403 with total 104 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-1.0589],\n",
      "        [ 2.1648],\n",
      "        [-0.1908],\n",
      "        [ 1.8617],\n",
      "        [-4.2420]], device='cuda:0')\n",
      "tensor([[0.2575, 0.8970, 0.4524, 0.8655, 0.0142]], device='cuda:0')\n",
      "start with index 56\n",
      "path data/train_images/23139/39950 with total 206 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-3.7787],\n",
      "        [-1.7298],\n",
      "        [-3.5096],\n",
      "        [-1.3147],\n",
      "        [-5.3608]], device='cuda:0')\n",
      "tensor([[0.0223, 0.1506, 0.0290, 0.2117, 0.0047]], device='cuda:0')\n",
      "start with index 57\n",
      "path data/train_images/23311/2339 with total 431 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-3.8758],\n",
      "        [-3.7317],\n",
      "        [-2.1432],\n",
      "        [-1.9638],\n",
      "        [-2.8052]], device='cuda:0')\n",
      "tensor([[0.0203, 0.0234, 0.1050, 0.1231, 0.0570]], device='cuda:0')\n",
      "start with index 58\n",
      "path data/train_images/23311/2828 with total 536 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-3.4652],\n",
      "        [ 1.7843],\n",
      "        [-3.9364],\n",
      "        [-1.1681],\n",
      "        [-2.9062]], device='cuda:0')\n",
      "tensor([[0.0303, 0.8562, 0.0191, 0.2372, 0.0518]], device='cuda:0')\n",
      "start with index 59\n",
      "path data/train_images/23602/13693 with total 727 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-3.2187],\n",
      "        [-3.3326],\n",
      "        [-5.4694],\n",
      "        [-1.9081],\n",
      "        [-3.6770]], device='cuda:0')\n",
      "tensor([[0.0385, 0.0345, 0.0042, 0.1292, 0.0247]], device='cuda:0')\n",
      "start with index 60\n",
      "path data/train_images/23737/29004 with total 126 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-3.7934],\n",
      "        [ 1.0664],\n",
      "        [-1.2114],\n",
      "        [-3.0770],\n",
      "        [-4.0927]], device='cuda:0')\n",
      "tensor([[0.0220, 0.7439, 0.2295, 0.0441, 0.0164]], device='cuda:0')\n",
      "start with index 61\n",
      "path data/train_images/23737/49921 with total 176 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-6.0122],\n",
      "        [ 3.1469],\n",
      "        [-1.7985],\n",
      "        [ 0.8260],\n",
      "        [-6.1106]], device='cuda:0')\n",
      "tensor([[0.0024, 0.9588, 0.1420, 0.6955, 0.0022]], device='cuda:0')\n",
      "start with index 62\n",
      "path data/train_images/23979/1788 with total 282 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-5.1233],\n",
      "        [-2.8870],\n",
      "        [-2.7522],\n",
      "        [-0.9710],\n",
      "        [-4.8685]], device='cuda:0')\n",
      "tensor([[0.0059, 0.0528, 0.0600, 0.2747, 0.0076]], device='cuda:0')\n",
      "start with index 63\n",
      "path data/train_images/23979/629 with total 225 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-2.6945],\n",
      "        [ 0.9344],\n",
      "        [-1.7700],\n",
      "        [-1.5641],\n",
      "        [-5.3232]], device='cuda:0')\n",
      "tensor([[0.0633, 0.7180, 0.1455, 0.1731, 0.0049]], device='cuda:0')\n",
      "start with index 64\n",
      "path data/train_images/24229/27769 with total 146 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-2.8737],\n",
      "        [-3.5454],\n",
      "        [-0.2154],\n",
      "        [ 0.2828],\n",
      "        [-5.6646]], device='cuda:0')\n",
      "tensor([[0.0535, 0.0280, 0.4464, 0.5702, 0.0035]], device='cuda:0')\n",
      "start with index 65\n",
      "path data/train_images/24229/62614 with total 107 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-4.6240],\n",
      "        [-3.7665],\n",
      "        [-0.2144],\n",
      "        [-2.2175],\n",
      "        [-6.7680]], device='cuda:0')\n",
      "tensor([[0.0097, 0.0226, 0.4466, 0.0982, 0.0011]], device='cuda:0')\n",
      "start with index 66\n",
      "path data/train_images/24306/29547 with total 169 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-0.6425],\n",
      "        [ 2.1287],\n",
      "        [-3.8083],\n",
      "        [-2.9494],\n",
      "        [-4.8746]], device='cuda:0')\n",
      "tensor([[0.3447, 0.8937, 0.0217, 0.0498, 0.0076]], device='cuda:0')\n",
      "start with index 67\n",
      "path data/train_images/24306/51975 with total 181 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-3.0207],\n",
      "        [ 1.0326],\n",
      "        [-2.0609],\n",
      "        [-3.2090],\n",
      "        [-2.3890]], device='cuda:0')\n",
      "tensor([[0.0465, 0.7374, 0.1130, 0.0388, 0.0840]], device='cuda:0')\n",
      "start with index 68\n",
      "path data/train_images/24652/13893 with total 171 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-3.3660],\n",
      "        [-7.0122],\n",
      "        [-0.7368],\n",
      "        [-4.8954],\n",
      "        [-5.9551]], device='cuda:0')\n",
      "tensor([[0.0334, 0.0009, 0.3237, 0.0074, 0.0026]], device='cuda:0')\n",
      "start with index 69\n",
      "path data/train_images/25321/1487 with total 204 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[ 5.2589],\n",
      "        [-3.2147],\n",
      "        [ 0.7439],\n",
      "        [ 0.9822],\n",
      "        [-3.4923]], device='cuda:0')\n",
      "tensor([[0.9948, 0.0386, 0.6778, 0.7275, 0.0295]], device='cuda:0')\n",
      "start with index 70\n",
      "path data/train_images/26231/4819 with total 621 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[ 0.1733],\n",
      "        [-4.6303],\n",
      "        [-1.7218],\n",
      "        [-3.1819],\n",
      "        [-4.4130]], device='cuda:0')\n",
      "tensor([[0.5432, 0.0097, 0.1516, 0.0399, 0.0120]], device='cuda:0')\n",
      "start with index 71\n",
      "path data/train_images/26231/51172 with total 302 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-2.1576],\n",
      "        [-3.3947],\n",
      "        [-4.2860],\n",
      "        [-4.6354],\n",
      "        [-6.2330]], device='cuda:0')\n",
      "tensor([[0.1036, 0.0325, 0.0136, 0.0096, 0.0020]], device='cuda:0')\n",
      "start with index 72\n",
      "path data/train_images/26272/42791 with total 653 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[ 0.1262],\n",
      "        [-3.8663],\n",
      "        [-4.9141],\n",
      "        [-3.9650],\n",
      "        [-3.3923]], device='cuda:0')\n",
      "tensor([[0.5315, 0.0205, 0.0073, 0.0186, 0.0325]], device='cuda:0')\n",
      "start with index 73\n",
      "path data/train_images/263/44610 with total 191 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-2.9283],\n",
      "        [-5.5974],\n",
      "        [-3.4292],\n",
      "        [-1.5513],\n",
      "        [-5.5931]], device='cuda:0')\n",
      "tensor([[0.0508, 0.0037, 0.0314, 0.1749, 0.0037]], device='cuda:0')\n",
      "start with index 74\n",
      "path data/train_images/27289/13087 with total 1508 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-3.1630],\n",
      "        [-3.0272],\n",
      "        [-1.7649],\n",
      "        [-3.5586],\n",
      "        [-6.2428]], device='cuda:0')\n",
      "tensor([[0.0406, 0.0462, 0.1462, 0.0277, 0.0019]], device='cuda:0')\n",
      "start with index 75\n",
      "path data/train_images/27289/24214 with total 704 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-1.3662],\n",
      "        [-0.9738],\n",
      "        [-4.9924],\n",
      "        [-3.2570],\n",
      "        [-5.8524]], device='cuda:0')\n",
      "tensor([[0.2032, 0.2741, 0.0067, 0.0371, 0.0029]], device='cuda:0')\n",
      "start with index 76\n",
      "path data/train_images/27773/32785 with total 1061 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-4.4382],\n",
      "        [ 3.0542],\n",
      "        [-5.4213],\n",
      "        [-6.5908],\n",
      "        [-3.6206]], device='cuda:0')\n",
      "tensor([[0.0117, 0.9550, 0.0044, 0.0014, 0.0261]], device='cuda:0')\n",
      "start with index 77\n",
      "path data/train_images/28381/50943 with total 759 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[ 0.5030],\n",
      "        [ 0.9315],\n",
      "        [-0.7147],\n",
      "        [-2.2245],\n",
      "        [-3.4228]], device='cuda:0')\n",
      "tensor([[0.6232, 0.7174, 0.3286, 0.0976, 0.0316]], device='cuda:0')\n",
      "start with index 78\n",
      "path data/train_images/28381/53911 with total 357 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-0.3951],\n",
      "        [ 2.9079],\n",
      "        [ 0.4002],\n",
      "        [-1.2700],\n",
      "        [-3.8831]], device='cuda:0')\n",
      "tensor([[0.4025, 0.9482, 0.5987, 0.2192, 0.0202]], device='cuda:0')\n",
      "start with index 79\n",
      "path data/train_images/28581/56748 with total 801 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-4.9069],\n",
      "        [-3.2968],\n",
      "        [-1.6596],\n",
      "        [-4.6845],\n",
      "        [-3.1963]], device='cuda:0')\n",
      "tensor([[0.0073, 0.0357, 0.1598, 0.0092, 0.0393]], device='cuda:0')\n",
      "start with index 80\n",
      "path data/train_images/28927/23912 with total 61 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-2.4525],\n",
      "        [-1.0561],\n",
      "        [-4.3210],\n",
      "        [-3.2762],\n",
      "        [-6.0746]], device='cuda:0')\n",
      "tensor([[0.0793, 0.2580, 0.0131, 0.0364, 0.0023]], device='cuda:0')\n",
      "start with index 81\n",
      "path data/train_images/28927/44525 with total 204 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-3.7744],\n",
      "        [-3.6185],\n",
      "        [-3.0431],\n",
      "        [-6.9179],\n",
      "        [-5.3089]], device='cuda:0')\n",
      "tensor([[0.0224, 0.0261, 0.0455, 0.0010, 0.0049]], device='cuda:0')\n",
      "start with index 82\n",
      "path data/train_images/29319/17263 with total 1009 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-5.2282],\n",
      "        [ 2.4288],\n",
      "        [-1.9110],\n",
      "        [-2.0417],\n",
      "        [-4.3967]], device='cuda:0')\n",
      "tensor([[0.0053, 0.9190, 0.1289, 0.1149, 0.0122]], device='cuda:0')\n",
      "start with index 83\n",
      "path data/train_images/29319/9369 with total 633 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-3.6300],\n",
      "        [-0.6535],\n",
      "        [-4.6131],\n",
      "        [-3.5151],\n",
      "        [-5.5647]], device='cuda:0')\n",
      "tensor([[0.0258, 0.3422, 0.0098, 0.0289, 0.0038]], device='cuda:0')\n",
      "start with index 84\n",
      "path data/train_images/2940/24146 with total 180 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-4.0034],\n",
      "        [-3.7311],\n",
      "        [-2.3167],\n",
      "        [-3.3097],\n",
      "        [-3.9053]], device='cuda:0')\n",
      "tensor([[0.0179, 0.0234, 0.0898, 0.0352, 0.0197]], device='cuda:0')\n",
      "start with index 85\n",
      "path data/train_images/2940/36847 with total 93 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-1.7107],\n",
      "        [-2.3828],\n",
      "        [-4.2606],\n",
      "        [-0.9233],\n",
      "        [-2.7248]], device='cuda:0')\n",
      "tensor([[0.1531, 0.0845, 0.0139, 0.2843, 0.0615]], device='cuda:0')\n",
      "start with index 86\n",
      "path data/train_images/29433/24643 with total 309 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-2.8585],\n",
      "        [-2.3544],\n",
      "        [-0.7331],\n",
      "        [-4.3527],\n",
      "        [-6.8122]], device='cuda:0')\n",
      "tensor([[0.0542, 0.0867, 0.3245, 0.0127, 0.0011]], device='cuda:0')\n",
      "start with index 87\n",
      "path data/train_images/29433/44804 with total 538 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-3.2036],\n",
      "        [-3.9127],\n",
      "        [-0.3869],\n",
      "        [-4.6521],\n",
      "        [-6.2392]], device='cuda:0')\n",
      "tensor([[0.0390, 0.0196, 0.4045, 0.0095, 0.0019]], device='cuda:0')\n",
      "start with index 88\n",
      "path data/train_images/29692/37953 with total 223 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-2.0293],\n",
      "        [-5.5648],\n",
      "        [-6.5936],\n",
      "        [-3.9111],\n",
      "        [-1.4515]], device='cuda:0')\n",
      "tensor([[0.1162, 0.0038, 0.0014, 0.0196, 0.1898]], device='cuda:0')\n",
      "start with index 89\n",
      "path data/train_images/2978/13271 with total 182 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-0.3845],\n",
      "        [-0.4099],\n",
      "        [-3.8397],\n",
      "        [-3.4618],\n",
      "        [-3.5108]], device='cuda:0')\n",
      "tensor([[0.4050, 0.3989, 0.0210, 0.0304, 0.0290]], device='cuda:0')\n",
      "start with index 90\n",
      "path data/train_images/2978/30248 with total 80 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-2.9929],\n",
      "        [-0.6319],\n",
      "        [-1.0318],\n",
      "        [-1.6266],\n",
      "        [-5.2151]], device='cuda:0')\n",
      "tensor([[0.0477, 0.3471, 0.2627, 0.1643, 0.0054]], device='cuda:0')\n",
      "start with index 91\n",
      "path data/train_images/29881/35631 with total 175 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-2.8137],\n",
      "        [-4.5950],\n",
      "        [-1.8675],\n",
      "        [-2.7350],\n",
      "        [-5.2042]], device='cuda:0')\n",
      "tensor([[0.0566, 0.0100, 0.1338, 0.0609, 0.0055]], device='cuda:0')\n",
      "start with index 92\n",
      "path data/train_images/30497/43659 with total 383 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-1.7037],\n",
      "        [-2.4084],\n",
      "        [-2.9377],\n",
      "        [-3.1742],\n",
      "        [-5.6387]], device='cuda:0')\n",
      "tensor([[0.1540, 0.0825, 0.0503, 0.0401, 0.0035]], device='cuda:0')\n",
      "start with index 93\n",
      "path data/train_images/31289/22767 with total 169 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-2.2661],\n",
      "        [-3.7692],\n",
      "        [ 1.1990],\n",
      "        [ 2.4818],\n",
      "        [-5.0329]], device='cuda:0')\n",
      "tensor([[0.0940, 0.0225, 0.7683, 0.9229, 0.0065]], device='cuda:0')\n",
      "start with index 94\n",
      "path data/train_images/31289/63310 with total 205 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-0.4999],\n",
      "        [-2.2140],\n",
      "        [-0.0860],\n",
      "        [ 0.2681],\n",
      "        [-5.4665]], device='cuda:0')\n",
      "tensor([[0.3776, 0.0985, 0.4785, 0.5666, 0.0042]], device='cuda:0')\n",
      "start with index 95\n",
      "path data/train_images/31293/5213 with total 113 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[ 2.1881],\n",
      "        [ 3.0327],\n",
      "        [-2.8203],\n",
      "        [-1.0180],\n",
      "        [-3.9305]], device='cuda:0')\n",
      "tensor([[0.8992, 0.9540, 0.0562, 0.2654, 0.0193]], device='cuda:0')\n",
      "start with index 96\n",
      "path data/train_images/31293/60873 with total 190 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[ 1.9299],\n",
      "        [ 2.2513],\n",
      "        [-3.8475],\n",
      "        [-4.1585],\n",
      "        [-3.9400]], device='cuda:0')\n",
      "tensor([[0.8732, 0.9048, 0.0209, 0.0154, 0.0191]], device='cuda:0')\n",
      "start with index 97\n",
      "path data/train_images/31339/40176 with total 61 scan\n",
      "except process fail 4\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-2.3527],\n",
      "        [-2.9109],\n",
      "        [-2.6806],\n",
      "        [-0.1391],\n",
      "        [ 2.0821]], device='cuda:0')\n",
      "tensor([[0.0869, 0.0516, 0.0641, 0.4653, 0.8892]], device='cuda:0')\n",
      "start with index 98\n",
      "path data/train_images/31339/56722 with total 100 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[ 0.0525],\n",
      "        [ 3.3764],\n",
      "        [-0.3899],\n",
      "        [-1.4483],\n",
      "        [-3.9718]], device='cuda:0')\n",
      "tensor([[0.5131, 0.9670, 0.4037, 0.1903, 0.0185]], device='cuda:0')\n",
      "start with index 99\n",
      "path data/train_images/31728/23062 with total 170 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-5.5789],\n",
      "        [ 0.4349],\n",
      "        [-5.1302],\n",
      "        [-1.2931],\n",
      "        [-8.0183]], device='cuda:0')\n",
      "tensor([[3.7626e-03, 6.0703e-01, 5.8808e-03, 2.1533e-01, 3.2927e-04]],\n",
      "       device='cuda:0')\n",
      "start with index 100\n",
      "path data/train_images/31777/29038 with total 162 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-3.8674],\n",
      "        [-1.7825],\n",
      "        [-3.7801],\n",
      "        [-2.5014],\n",
      "        [-4.5802]], device='cuda:0')\n",
      "tensor([[0.0205, 0.1440, 0.0223, 0.0758, 0.0101]], device='cuda:0')\n",
      "start with index 101\n",
      "path data/train_images/31853/1368 with total 108 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-2.4431],\n",
      "        [-1.5772],\n",
      "        [ 0.1804],\n",
      "        [ 0.4034],\n",
      "        [-6.8514]], device='cuda:0')\n",
      "tensor([[0.0799, 0.1712, 0.5450, 0.5995, 0.0011]], device='cuda:0')\n",
      "start with index 102\n",
      "path data/train_images/31919/42229 with total 93 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-5.2480],\n",
      "        [-4.6683],\n",
      "        [-0.0593],\n",
      "        [-0.2300],\n",
      "        [-4.5333]], device='cuda:0')\n",
      "tensor([[0.0052, 0.0093, 0.4852, 0.4427, 0.0106]], device='cuda:0')\n",
      "start with index 103\n",
      "path data/train_images/31985/61748 with total 701 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-3.8427],\n",
      "        [-6.1238],\n",
      "        [-0.3444],\n",
      "        [-1.9156],\n",
      "        [-6.4439]], device='cuda:0')\n",
      "tensor([[0.0210, 0.0022, 0.4147, 0.1284, 0.0016]], device='cuda:0')\n",
      "start with index 104\n",
      "path data/train_images/32613/15943 with total 344 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-4.3031],\n",
      "        [-3.7620],\n",
      "        [-1.1792],\n",
      "        [ 0.5998],\n",
      "        [-4.9820]], device='cuda:0')\n",
      "tensor([[0.0133, 0.0227, 0.2352, 0.6456, 0.0068]], device='cuda:0')\n",
      "start with index 105\n",
      "path data/train_images/32613/31599 with total 357 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-2.7944],\n",
      "        [-4.3782],\n",
      "        [-1.4011],\n",
      "        [-1.8820],\n",
      "        [-4.8255]], device='cuda:0')\n",
      "tensor([[0.0576, 0.0124, 0.1976, 0.1322, 0.0080]], device='cuda:0')\n",
      "start with index 106\n",
      "path data/train_images/33029/2191 with total 484 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-1.8855],\n",
      "        [-3.3730],\n",
      "        [-0.8911],\n",
      "        [-1.8811],\n",
      "        [-6.6335]], device='cuda:0')\n",
      "tensor([[0.1318, 0.0331, 0.2909, 0.1323, 0.0013]], device='cuda:0')\n",
      "start with index 107\n",
      "path data/train_images/33029/36791 with total 488 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-3.3468],\n",
      "        [-2.2621],\n",
      "        [-2.6268],\n",
      "        [-3.2529],\n",
      "        [-6.9530]], device='cuda:0')\n",
      "tensor([[0.0340, 0.0943, 0.0674, 0.0372, 0.0010]], device='cuda:0')\n",
      "start with index 108\n",
      "path data/train_images/33648/23313 with total 241 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-4.2112],\n",
      "        [ 1.9572],\n",
      "        [-6.5005],\n",
      "        [-6.0175],\n",
      "        [-4.5888]], device='cuda:0')\n",
      "tensor([[0.0146, 0.8762, 0.0015, 0.0024, 0.0101]], device='cuda:0')\n",
      "start with index 109\n",
      "path data/train_images/33648/29865 with total 519 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-2.7540],\n",
      "        [ 0.3001],\n",
      "        [-3.1067],\n",
      "        [-3.7306],\n",
      "        [-6.2664]], device='cuda:0')\n",
      "tensor([[0.0599, 0.5745, 0.0428, 0.0234, 0.0019]], device='cuda:0')\n",
      "start with index 110\n",
      "path data/train_images/34140/10704 with total 447 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-5.4626],\n",
      "        [-0.1304],\n",
      "        [-5.1724],\n",
      "        [-6.6904],\n",
      "        [-4.6564]], device='cuda:0')\n",
      "tensor([[0.0042, 0.4674, 0.0056, 0.0012, 0.0094]], device='cuda:0')\n",
      "start with index 111\n",
      "path data/train_images/34140/60725 with total 447 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-5.5783],\n",
      "        [-1.0602],\n",
      "        [-0.3915],\n",
      "        [-4.6992],\n",
      "        [-3.1668]], device='cuda:0')\n",
      "tensor([[0.0038, 0.2573, 0.4033, 0.0090, 0.0404]], device='cuda:0')\n",
      "start with index 112\n",
      "path data/train_images/34838/23397 with total 312 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[ 3.9159],\n",
      "        [-3.6998],\n",
      "        [-4.3403],\n",
      "        [-4.2309],\n",
      "        [-2.2030]], device='cuda:0')\n",
      "tensor([[0.9805, 0.0241, 0.0129, 0.0143, 0.0995]], device='cuda:0')\n",
      "start with index 113\n",
      "path data/train_images/34838/6287 with total 312 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[ 3.3666],\n",
      "        [-0.8556],\n",
      "        [-8.1332],\n",
      "        [-4.1081],\n",
      "        [-3.0049]], device='cuda:0')\n",
      "tensor([[9.6665e-01, 2.9825e-01, 2.9354e-04, 1.6173e-02, 4.7206e-02]],\n",
      "       device='cuda:0')\n",
      "start with index 114\n",
      "path data/train_images/34870/32068 with total 383 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-0.8234],\n",
      "        [-1.7406],\n",
      "        [-1.8289],\n",
      "        [ 1.2411],\n",
      "        [-4.7710]], device='cuda:0')\n",
      "tensor([[0.3050, 0.1492, 0.1384, 0.7758, 0.0084]], device='cuda:0')\n",
      "start with index 115\n",
      "path data/train_images/35056/49753 with total 677 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[ 1.6729],\n",
      "        [ 1.6546],\n",
      "        [ 1.4317],\n",
      "        [-0.9008],\n",
      "        [-5.5392]], device='cuda:0')\n",
      "tensor([[0.8420, 0.8395, 0.8072, 0.2889, 0.0039]], device='cuda:0')\n",
      "start with index 116\n",
      "path data/train_images/35079/55300 with total 106 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[ 2.3677],\n",
      "        [-3.4604],\n",
      "        [-2.5111],\n",
      "        [-2.7883],\n",
      "        [-6.9314]], device='cuda:0')\n",
      "tensor([[0.9143, 0.0305, 0.0751, 0.0580, 0.0010]], device='cuda:0')\n",
      "start with index 117\n",
      "path data/train_images/35794/42578 with total 316 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-5.0731],\n",
      "        [-3.4716],\n",
      "        [ 0.3530],\n",
      "        [ 2.1651],\n",
      "        [-5.6592]], device='cuda:0')\n",
      "tensor([[0.0062, 0.0301, 0.5874, 0.8971, 0.0035]], device='cuda:0')\n",
      "start with index 118\n",
      "path data/train_images/36131/53721 with total 231 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-1.6431],\n",
      "        [ 0.1806],\n",
      "        [-1.9282],\n",
      "        [-3.6946],\n",
      "        [-6.7076]], device='cuda:0')\n",
      "tensor([[0.1620, 0.5450, 0.1269, 0.0243, 0.0012]], device='cuda:0')\n",
      "start with index 119\n",
      "path data/train_images/36356/40908 with total 155 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[ 0.0304],\n",
      "        [-3.6823],\n",
      "        [-0.2244],\n",
      "        [-2.3480],\n",
      "        [-3.7879]], device='cuda:0')\n",
      "tensor([[0.5076, 0.0245, 0.4441, 0.0872, 0.0221]], device='cuda:0')\n",
      "start with index 120\n",
      "path data/train_images/36356/4330 with total 70 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-1.6154],\n",
      "        [-1.2342],\n",
      "        [-1.5904],\n",
      "        [-1.5602],\n",
      "        [-6.3056]], device='cuda:0')\n",
      "tensor([[0.1658, 0.2254, 0.1693, 0.1736, 0.0018]], device='cuda:0')\n",
      "start with index 121\n",
      "path data/train_images/37117/34371 with total 288 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-0.5244],\n",
      "        [-0.3894],\n",
      "        [-3.9186],\n",
      "        [-0.4219],\n",
      "        [-5.2673]], device='cuda:0')\n",
      "tensor([[0.3718, 0.4039, 0.0195, 0.3961, 0.0051]], device='cuda:0')\n",
      "start with index 122\n",
      "path data/train_images/37117/46308 with total 298 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-2.1153],\n",
      "        [ 0.1552],\n",
      "        [-2.3095],\n",
      "        [-1.6956],\n",
      "        [-6.2089]], device='cuda:0')\n",
      "tensor([[0.1076, 0.5387, 0.0903, 0.1550, 0.0020]], device='cuda:0')\n",
      "start with index 123\n",
      "path data/train_images/37551/62680 with total 184 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-5.6017],\n",
      "        [ 4.6374],\n",
      "        [ 3.3379],\n",
      "        [-1.1687],\n",
      "        [-6.3165]], device='cuda:0')\n",
      "tensor([[0.0037, 0.9904, 0.9657, 0.2371, 0.0018]], device='cuda:0')\n",
      "start with index 124\n",
      "path data/train_images/37575/45842 with total 223 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[ 0.5459],\n",
      "        [-0.6351],\n",
      "        [-2.8394],\n",
      "        [-1.7203],\n",
      "        [-4.2073]], device='cuda:0')\n",
      "tensor([[0.6332, 0.3464, 0.0552, 0.1518, 0.0147]], device='cuda:0')\n",
      "start with index 125\n",
      "path data/train_images/37820/22201 with total 402 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[ 0.6504],\n",
      "        [ 0.4628],\n",
      "        [-0.4180],\n",
      "        [-5.5253],\n",
      "        [-0.6494]], device='cuda:0')\n",
      "tensor([[0.6571, 0.6137, 0.3970, 0.0040, 0.3431]], device='cuda:0')\n",
      "start with index 126\n",
      "path data/train_images/37820/601 with total 410 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-0.7457],\n",
      "        [ 0.6701],\n",
      "        [ 0.7390],\n",
      "        [-3.7517],\n",
      "        [-0.6870]], device='cuda:0')\n",
      "tensor([[0.3218, 0.6615, 0.6768, 0.0229, 0.3347]], device='cuda:0')\n",
      "start with index 127\n",
      "path data/train_images/37942/63754 with total 677 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-0.9245],\n",
      "        [-3.0127],\n",
      "        [-4.2341],\n",
      "        [-2.6910],\n",
      "        [-6.7328]], device='cuda:0')\n",
      "tensor([[0.2840, 0.0469, 0.0143, 0.0635, 0.0012]], device='cuda:0')\n",
      "start with index 128\n",
      "path data/train_images/38192/19338 with total 158 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[ 1.5251],\n",
      "        [-2.9590],\n",
      "        [-0.9985],\n",
      "        [-6.7289],\n",
      "        [-4.7060]], device='cuda:0')\n",
      "tensor([[0.8213, 0.0493, 0.2692, 0.0012, 0.0090]], device='cuda:0')\n",
      "start with index 129\n",
      "path data/train_images/38192/50868 with total 77 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-1.0578],\n",
      "        [-2.8245],\n",
      "        [-2.1103],\n",
      "        [-6.1789],\n",
      "        [-4.6326]], device='cuda:0')\n",
      "tensor([[0.2577, 0.0560, 0.1081, 0.0021, 0.0096]], device='cuda:0')\n",
      "start with index 130\n",
      "path data/train_images/38336/22631 with total 166 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-0.2364],\n",
      "        [ 0.6364],\n",
      "        [-0.9698],\n",
      "        [-2.2733],\n",
      "        [-2.6807]], device='cuda:0')\n",
      "tensor([[0.4412, 0.6539, 0.2749, 0.0934, 0.0641]], device='cuda:0')\n",
      "start with index 131\n",
      "path data/train_images/38336/55646 with total 173 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[ 1.2848],\n",
      "        [-0.4239],\n",
      "        [-3.2015],\n",
      "        [-3.6119],\n",
      "        [-2.1889]], device='cuda:0')\n",
      "tensor([[0.7833, 0.3956, 0.0391, 0.0263, 0.1008]], device='cuda:0')\n",
      "start with index 132\n",
      "path data/train_images/3881/19714 with total 601 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-2.8250],\n",
      "        [-1.7117],\n",
      "        [-2.0917],\n",
      "        [-4.4232],\n",
      "        [-6.8769]], device='cuda:0')\n",
      "tensor([[0.0560, 0.1529, 0.1099, 0.0119, 0.0010]], device='cuda:0')\n",
      "start with index 133\n",
      "path data/train_images/39021/17903 with total 665 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-4.1003],\n",
      "        [-1.2086],\n",
      "        [-1.4455],\n",
      "        [-6.0200],\n",
      "        [-4.7735]], device='cuda:0')\n",
      "tensor([[0.0163, 0.2300, 0.1907, 0.0024, 0.0084]], device='cuda:0')\n",
      "start with index 134\n",
      "path data/train_images/394/8611 with total 221 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-4.4528],\n",
      "        [-4.5021],\n",
      "        [ 0.0840],\n",
      "        [-0.0775],\n",
      "        [-6.3547]], device='cuda:0')\n",
      "tensor([[0.0115, 0.0110, 0.5210, 0.4806, 0.0017]], device='cuda:0')\n",
      "start with index 135\n",
      "path data/train_images/39728/32152 with total 668 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[ 0.0054],\n",
      "        [-0.8729],\n",
      "        [-3.6194],\n",
      "        [-2.0881],\n",
      "        [-5.2165]], device='cuda:0')\n",
      "tensor([[0.5014, 0.2947, 0.0261, 0.1103, 0.0054]], device='cuda:0')\n",
      "start with index 136\n",
      "path data/train_images/40922/60157 with total 533 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[0.2111],\n",
      "        [0.4785],\n",
      "        [4.8633],\n",
      "        [0.7115],\n",
      "        [0.3130]], device='cuda:0')\n",
      "tensor([[0.5526, 0.6174, 0.9923, 0.6707, 0.5776]], device='cuda:0')\n",
      "start with index 137\n",
      "path data/train_images/41055/58272 with total 284 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-3.2062],\n",
      "        [ 3.5515],\n",
      "        [-0.2375],\n",
      "        [ 1.6792],\n",
      "        [-3.7133]], device='cuda:0')\n",
      "tensor([[0.0389, 0.9721, 0.4409, 0.8428, 0.0238]], device='cuda:0')\n",
      "start with index 138\n",
      "path data/train_images/41055/6983 with total 165 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-3.3882],\n",
      "        [ 2.8082],\n",
      "        [ 1.0879],\n",
      "        [-0.4598],\n",
      "        [-5.6383]], device='cuda:0')\n",
      "tensor([[0.0327, 0.9431, 0.7480, 0.3870, 0.0035]], device='cuda:0')\n",
      "start with index 139\n",
      "path data/train_images/41599/61839 with total 200 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-2.8604],\n",
      "        [-3.8050],\n",
      "        [-5.8453],\n",
      "        [-4.5458],\n",
      "        [-6.8812]], device='cuda:0')\n",
      "tensor([[0.0541, 0.0218, 0.0029, 0.0105, 0.0010]], device='cuda:0')\n",
      "start with index 140\n",
      "path data/train_images/43024/37372 with total 185 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-1.9960],\n",
      "        [-3.2859],\n",
      "        [-2.2803],\n",
      "        [-3.8200],\n",
      "        [-3.3677]], device='cuda:0')\n",
      "tensor([[0.1196, 0.0361, 0.0928, 0.0215, 0.0333]], device='cuda:0')\n",
      "start with index 141\n",
      "path data/train_images/43024/8491 with total 84 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-2.7627],\n",
      "        [ 2.4662],\n",
      "        [ 0.8925],\n",
      "        [-2.6835],\n",
      "        [-4.0607]], device='cuda:0')\n",
      "tensor([[0.0594, 0.9217, 0.7094, 0.0640, 0.0169]], device='cuda:0')\n",
      "start with index 142\n",
      "path data/train_images/4313/17911 with total 208 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-3.9550],\n",
      "        [-7.2645],\n",
      "        [-3.0817],\n",
      "        [-2.6237],\n",
      "        [-0.4306]], device='cuda:0')\n",
      "tensor([[0.0188, 0.0007, 0.0439, 0.0676, 0.3940]], device='cuda:0')\n",
      "start with index 143\n",
      "path data/train_images/43294/33093 with total 152 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-1.7202],\n",
      "        [-2.4589],\n",
      "        [-4.6764],\n",
      "        [-2.8984],\n",
      "        [-3.7996]], device='cuda:0')\n",
      "tensor([[0.1518, 0.0788, 0.0092, 0.0522, 0.0219]], device='cuda:0')\n",
      "start with index 144\n",
      "path data/train_images/43294/5868 with total 68 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-4.4490],\n",
      "        [-2.1168],\n",
      "        [-1.0377],\n",
      "        [-2.7799],\n",
      "        [-4.5766]], device='cuda:0')\n",
      "tensor([[0.0116, 0.1075, 0.2616, 0.0584, 0.0102]], device='cuda:0')\n",
      "start with index 145\n",
      "path data/train_images/4453/45286 with total 613 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-2.0621],\n",
      "        [-3.7878],\n",
      "        [-4.6301],\n",
      "        [-3.0430],\n",
      "        [-4.1358]], device='cuda:0')\n",
      "tensor([[0.1128, 0.0221, 0.0097, 0.0455, 0.0157]], device='cuda:0')\n",
      "start with index 146\n",
      "path data/train_images/4453/7286 with total 389 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-3.0218],\n",
      "        [-4.5911],\n",
      "        [-3.9366],\n",
      "        [-3.0024],\n",
      "        [-3.2638]], device='cuda:0')\n",
      "tensor([[0.0465, 0.0100, 0.0191, 0.0473, 0.0368]], device='cuda:0')\n",
      "start with index 147\n",
      "path data/train_images/45303/44615 with total 289 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-3.3402],\n",
      "        [-4.1805],\n",
      "        [-1.3721],\n",
      "        [-3.2525],\n",
      "        [ 0.2996]], device='cuda:0')\n",
      "tensor([[0.0342, 0.0151, 0.2023, 0.0372, 0.5743]], device='cuda:0')\n",
      "start with index 148\n",
      "path data/train_images/45303/46118 with total 221 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-3.6739],\n",
      "        [-2.0083],\n",
      "        [-3.6450],\n",
      "        [-4.9704],\n",
      "        [ 1.0834]], device='cuda:0')\n",
      "tensor([[0.0247, 0.1183, 0.0255, 0.0069, 0.7471]], device='cuda:0')\n",
      "start with index 149\n",
      "path data/train_images/46358/58160 with total 649 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-1.6958],\n",
      "        [-1.7989],\n",
      "        [-3.4491],\n",
      "        [-3.3957],\n",
      "        [-1.6571]], device='cuda:0')\n",
      "tensor([[0.1550, 0.1420, 0.0308, 0.0324, 0.1601]], device='cuda:0')\n",
      "start with index 150\n",
      "path data/train_images/46391/58531 with total 557 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-0.8484],\n",
      "        [-3.4007],\n",
      "        [-6.0879],\n",
      "        [-5.5426],\n",
      "        [-6.3304]], device='cuda:0')\n",
      "tensor([[0.2998, 0.0323, 0.0023, 0.0039, 0.0018]], device='cuda:0')\n",
      "start with index 151\n",
      "path data/train_images/46391/61296 with total 774 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-0.3186],\n",
      "        [-1.2623],\n",
      "        [-4.8690],\n",
      "        [-5.1008],\n",
      "        [-5.9960]], device='cuda:0')\n",
      "tensor([[0.4210, 0.2206, 0.0076, 0.0061, 0.0025]], device='cuda:0')\n",
      "start with index 152\n",
      "path data/train_images/46771/26641 with total 194 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-0.4374],\n",
      "        [-5.7575],\n",
      "        [-2.3715],\n",
      "        [-3.9398],\n",
      "        [-5.9268]], device='cuda:0')\n",
      "tensor([[0.3924, 0.0031, 0.0854, 0.0191, 0.0027]], device='cuda:0')\n",
      "start with index 153\n",
      "path data/train_images/470/19119 with total 128 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-2.0677],\n",
      "        [-2.2561],\n",
      "        [-3.4492],\n",
      "        [-2.5955],\n",
      "        [-7.1086]], device='cuda:0')\n",
      "tensor([[0.1123, 0.0948, 0.0308, 0.0694, 0.0008]], device='cuda:0')\n",
      "start with index 154\n",
      "path data/train_images/470/27211 with total 78 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[ 0.7181],\n",
      "        [-0.5968],\n",
      "        [-4.5838],\n",
      "        [-3.9201],\n",
      "        [-5.5540]], device='cuda:0')\n",
      "tensor([[0.6722, 0.3551, 0.0101, 0.0195, 0.0039]], device='cuda:0')\n",
      "start with index 155\n",
      "path data/train_images/47794/34804 with total 202 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-2.6664],\n",
      "        [ 2.9223],\n",
      "        [-3.9069],\n",
      "        [-3.0469],\n",
      "        [-6.6422]], device='cuda:0')\n",
      "tensor([[0.0650, 0.9489, 0.0197, 0.0454, 0.0013]], device='cuda:0')\n",
      "start with index 156\n",
      "path data/train_images/47794/3560 with total 271 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-3.6409],\n",
      "        [-4.9868],\n",
      "        [-5.7208],\n",
      "        [-1.9385],\n",
      "        [-7.2042]], device='cuda:0')\n",
      "tensor([[0.0256, 0.0068, 0.0033, 0.1258, 0.0007]], device='cuda:0')\n",
      "start with index 157\n",
      "path data/train_images/4791/28079 with total 226 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[ 3.7765],\n",
      "        [ 1.5744],\n",
      "        [-3.5554],\n",
      "        [-5.5877],\n",
      "        [-4.4380]], device='cuda:0')\n",
      "tensor([[0.9776, 0.8284, 0.0278, 0.0037, 0.0117]], device='cuda:0')\n",
      "start with index 158\n",
      "path data/train_images/4791/4622 with total 192 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[ 3.9755],\n",
      "        [ 3.8438],\n",
      "        [-4.6298],\n",
      "        [-4.8243],\n",
      "        [-3.4404]], device='cuda:0')\n",
      "tensor([[0.9816, 0.9790, 0.0097, 0.0080, 0.0311]], device='cuda:0')\n",
      "start with index 159\n",
      "path data/train_images/4813/12584 with total 227 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[ 5.8850],\n",
      "        [-3.9408],\n",
      "        [-5.3051],\n",
      "        [-4.2764],\n",
      "        [-3.5562]], device='cuda:0')\n",
      "tensor([[0.9972, 0.0191, 0.0049, 0.0137, 0.0278]], device='cuda:0')\n",
      "start with index 160\n",
      "path data/train_images/48681/13095 with total 189 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[ 2.5674],\n",
      "        [-5.7941],\n",
      "        [-2.3734],\n",
      "        [-2.2263],\n",
      "        [-4.8225]], device='cuda:0')\n",
      "tensor([[0.9287, 0.0030, 0.0852, 0.0974, 0.0080]], device='cuda:0')\n",
      "start with index 161\n",
      "path data/train_images/48681/45912 with total 174 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[ 1.8940],\n",
      "        [-5.2397],\n",
      "        [-1.6046],\n",
      "        [-1.3257],\n",
      "        [-4.9125]], device='cuda:0')\n",
      "tensor([[0.8692, 0.0053, 0.1673, 0.2099, 0.0073]], device='cuda:0')\n",
      "start with index 162\n",
      "path data/train_images/48766/30186 with total 152 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[ 0.3769],\n",
      "        [-1.3103],\n",
      "        [-2.4724],\n",
      "        [ 2.0770],\n",
      "        [-5.1167]], device='cuda:0')\n",
      "tensor([[0.5931, 0.2124, 0.0778, 0.8886, 0.0060]], device='cuda:0')\n",
      "start with index 163\n",
      "path data/train_images/49225/21599 with total 525 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-2.1696],\n",
      "        [-1.4832],\n",
      "        [-5.5044],\n",
      "        [-3.8460],\n",
      "        [-5.1922]], device='cuda:0')\n",
      "tensor([[0.1025, 0.1849, 0.0041, 0.0209, 0.0055]], device='cuda:0')\n",
      "start with index 164\n",
      "path data/train_images/49225/40788 with total 220 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-3.4565],\n",
      "        [-2.6364],\n",
      "        [-1.4966],\n",
      "        [-3.8565],\n",
      "        [-5.8407]], device='cuda:0')\n",
      "tensor([[0.0306, 0.0668, 0.1829, 0.0207, 0.0029]], device='cuda:0')\n",
      "start with index 165\n",
      "path data/train_images/49350/41306 with total 218 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[ 3.3419],\n",
      "        [-2.9200],\n",
      "        [-2.7097],\n",
      "        [-6.5967],\n",
      "        [-3.7204]], device='cuda:0')\n",
      "tensor([[0.9658, 0.0512, 0.0624, 0.0014, 0.0237]], device='cuda:0')\n",
      "start with index 166\n",
      "path data/train_images/49350/56770 with total 248 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[ 2.0300],\n",
      "        [-1.1158],\n",
      "        [-1.0719],\n",
      "        [-3.3307],\n",
      "        [-4.4412]], device='cuda:0')\n",
      "tensor([[0.8839, 0.2468, 0.2550, 0.0345, 0.0116]], device='cuda:0')\n",
      "start with index 167\n",
      "path data/train_images/49541/17652 with total 233 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[ 1.4068],\n",
      "        [-3.4829],\n",
      "        [-4.3882],\n",
      "        [-2.4176],\n",
      "        [-4.3257]], device='cuda:0')\n",
      "tensor([[0.8033, 0.0298, 0.0123, 0.0818, 0.0131]], device='cuda:0')\n",
      "start with index 168\n",
      "path data/train_images/49541/46472 with total 262 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[ 1.3174],\n",
      "        [-4.2469],\n",
      "        [-1.6541],\n",
      "        [-1.9943],\n",
      "        [-5.7371]], device='cuda:0')\n",
      "tensor([[0.7888, 0.0141, 0.1606, 0.1198, 0.0032]], device='cuda:0')\n",
      "start with index 169\n",
      "path data/train_images/50657/20667 with total 211 scan\n",
      "except process fail 4\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[ 0.0748],\n",
      "        [ 1.2539],\n",
      "        [-3.1268],\n",
      "        [-2.3369],\n",
      "        [ 2.0821]], device='cuda:0')\n",
      "tensor([[0.5187, 0.7780, 0.0420, 0.0881, 0.8892]], device='cuda:0')\n",
      "start with index 170\n",
      "path data/train_images/51531/2749 with total 668 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-3.9057],\n",
      "        [ 3.9926],\n",
      "        [ 2.1380],\n",
      "        [-1.6550],\n",
      "        [-5.8905]], device='cuda:0')\n",
      "tensor([[0.0197, 0.9819, 0.8945, 0.1604, 0.0028]], device='cuda:0')\n",
      "start with index 171\n",
      "path data/train_images/51885/62292 with total 674 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-5.8978],\n",
      "        [-4.1307],\n",
      "        [-5.6540],\n",
      "        [-4.2781],\n",
      "        [-2.2279]], device='cuda:0')\n",
      "tensor([[0.0027, 0.0158, 0.0035, 0.0137, 0.0973]], device='cuda:0')\n",
      "start with index 172\n",
      "path data/train_images/52130/18548 with total 659 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-1.8548],\n",
      "        [ 1.3786],\n",
      "        [-1.3327],\n",
      "        [-5.1346],\n",
      "        [-4.5798]], device='cuda:0')\n",
      "tensor([[0.1353, 0.7988, 0.2087, 0.0059, 0.0102]], device='cuda:0')\n",
      "start with index 173\n",
      "path data/train_images/52446/52489 with total 185 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-2.1258],\n",
      "        [-3.8345],\n",
      "        [-4.6974],\n",
      "        [-4.5224],\n",
      "        [-4.2478]], device='cuda:0')\n",
      "tensor([[0.1066, 0.0212, 0.0090, 0.0107, 0.0141]], device='cuda:0')\n",
      "start with index 174\n",
      "path data/train_images/52446/9612 with total 78 scan\n",
      "except process fail 4\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[ 0.5720],\n",
      "        [-3.1733],\n",
      "        [-5.9257],\n",
      "        [-3.2607],\n",
      "        [ 2.0821]], device='cuda:0')\n",
      "tensor([[0.6392, 0.0402, 0.0027, 0.0369, 0.8892]], device='cuda:0')\n",
      "start with index 175\n",
      "path data/train_images/52513/19554 with total 166 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[ 1.5116],\n",
      "        [ 2.2822],\n",
      "        [-1.8938],\n",
      "        [-3.6414],\n",
      "        [-6.4900]], device='cuda:0')\n",
      "tensor([[0.8193, 0.9074, 0.1308, 0.0255, 0.0015]], device='cuda:0')\n",
      "start with index 176\n",
      "path data/train_images/52513/38121 with total 117 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-2.1355],\n",
      "        [ 2.9839],\n",
      "        [ 1.9869],\n",
      "        [-3.3432],\n",
      "        [-7.8520]], device='cuda:0')\n",
      "tensor([[1.0570e-01, 9.5184e-01, 8.7941e-01, 3.4119e-02, 3.8883e-04]],\n",
      "       device='cuda:0')\n",
      "start with index 177\n",
      "path data/train_images/5260/52307 with total 155 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-5.2370],\n",
      "        [-0.2801],\n",
      "        [-3.8090],\n",
      "        [-3.0711],\n",
      "        [-6.2926]], device='cuda:0')\n",
      "tensor([[0.0053, 0.4304, 0.0217, 0.0443, 0.0018]], device='cuda:0')\n",
      "start with index 178\n",
      "path data/train_images/53018/35602 with total 119 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[ 3.5164],\n",
      "        [ 2.1755],\n",
      "        [-1.6968],\n",
      "        [-1.2522],\n",
      "        [-4.3263]], device='cuda:0')\n",
      "tensor([[0.9712, 0.8980, 0.1549, 0.2223, 0.0130]], device='cuda:0')\n",
      "start with index 179\n",
      "path data/train_images/53018/49615 with total 199 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[ 2.5247],\n",
      "        [ 4.2270],\n",
      "        [ 0.9940],\n",
      "        [-0.2703],\n",
      "        [-3.8115]], device='cuda:0')\n",
      "tensor([[0.9259, 0.9856, 0.7299, 0.4328, 0.0216]], device='cuda:0')\n",
      "start with index 180\n",
      "path data/train_images/54049/30308 with total 722 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-2.5127],\n",
      "        [-3.7572],\n",
      "        [-2.9499],\n",
      "        [-3.4711],\n",
      "        [-5.9409]], device='cuda:0')\n",
      "tensor([[0.0750, 0.0228, 0.0497, 0.0301, 0.0026]], device='cuda:0')\n",
      "start with index 181\n",
      "path data/train_images/54431/22887 with total 120 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-3.1672],\n",
      "        [ 4.0361],\n",
      "        [-4.2081],\n",
      "        [-4.2391],\n",
      "        [-5.2716]], device='cuda:0')\n",
      "tensor([[0.0404, 0.9826, 0.0147, 0.0142, 0.0051]], device='cuda:0')\n",
      "start with index 182\n",
      "path data/train_images/54596/1808 with total 144 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-3.3813],\n",
      "        [-1.9513],\n",
      "        [-2.7188],\n",
      "        [-4.8420],\n",
      "        [-3.3657]], device='cuda:0')\n",
      "tensor([[0.0329, 0.1244, 0.0619, 0.0078, 0.0334]], device='cuda:0')\n",
      "start with index 183\n",
      "path data/train_images/54641/35500 with total 124 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-2.4040],\n",
      "        [-0.1085],\n",
      "        [-2.6604],\n",
      "        [-4.7894],\n",
      "        [-2.8626]], device='cuda:0')\n",
      "tensor([[0.0829, 0.4729, 0.0654, 0.0082, 0.0540]], device='cuda:0')\n",
      "start with index 184\n",
      "path data/train_images/54641/48019 with total 165 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-1.5219],\n",
      "        [-0.3659],\n",
      "        [-3.7853],\n",
      "        [-6.3250],\n",
      "        [-3.7672]], device='cuda:0')\n",
      "tensor([[0.1792, 0.4095, 0.0222, 0.0018, 0.0226]], device='cuda:0')\n",
      "start with index 185\n",
      "path data/train_images/54852/22157 with total 108 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-5.2706],\n",
      "        [-0.3276],\n",
      "        [ 2.0151],\n",
      "        [-1.6051],\n",
      "        [-4.1276]], device='cuda:0')\n",
      "tensor([[0.0051, 0.4188, 0.8824, 0.1673, 0.0159]], device='cuda:0')\n",
      "start with index 186\n",
      "path data/train_images/54938/51456 with total 651 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-2.7908],\n",
      "        [-3.6608],\n",
      "        [ 0.1371],\n",
      "        [-3.8502],\n",
      "        [-3.8957]], device='cuda:0')\n",
      "tensor([[0.0578, 0.0251, 0.5342, 0.0208, 0.0199]], device='cuda:0')\n",
      "start with index 187\n",
      "path data/train_images/54953/14060 with total 181 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[ 1.5549],\n",
      "        [-2.0763],\n",
      "        [-1.6223],\n",
      "        [-1.9318],\n",
      "        [-4.3167]], device='cuda:0')\n",
      "tensor([[0.8256, 0.1114, 0.1649, 0.1266, 0.0132]], device='cuda:0')\n",
      "start with index 188\n",
      "path data/train_images/54997/27062 with total 688 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-6.9558],\n",
      "        [-8.2499],\n",
      "        [-3.4229],\n",
      "        [-3.1592],\n",
      "        [-4.0588]], device='cuda:0')\n",
      "tensor([[0.0010, 0.0003, 0.0316, 0.0407, 0.0170]], device='cuda:0')\n",
      "start with index 189\n",
      "path data/train_images/55207/35138 with total 649 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[ 0.0677],\n",
      "        [-6.3307],\n",
      "        [-1.3137],\n",
      "        [-1.8827],\n",
      "        [-5.3587]], device='cuda:0')\n",
      "tensor([[0.5169, 0.0018, 0.2119, 0.1321, 0.0047]], device='cuda:0')\n",
      "start with index 190\n",
      "path data/train_images/55321/35799 with total 393 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[ 0.3611],\n",
      "        [ 1.0438],\n",
      "        [-3.3444],\n",
      "        [-0.0868],\n",
      "        [ 0.1441]], device='cuda:0')\n",
      "tensor([[0.5893, 0.7396, 0.0341, 0.4783, 0.5360]], device='cuda:0')\n",
      "start with index 191\n",
      "path data/train_images/55321/61313 with total 391 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[ 0.2387],\n",
      "        [ 0.3734],\n",
      "        [ 4.6060],\n",
      "        [-0.2071],\n",
      "        [ 0.0356]], device='cuda:0')\n",
      "tensor([[0.5594, 0.5923, 0.9901, 0.4484, 0.5089]], device='cuda:0')\n",
      "start with index 192\n",
      "path data/train_images/55530/38981 with total 156 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-1.2006],\n",
      "        [-3.6934],\n",
      "        [-1.9958],\n",
      "        [-3.5317],\n",
      "        [-4.9597]], device='cuda:0')\n",
      "tensor([[0.2314, 0.0243, 0.1196, 0.0284, 0.0070]], device='cuda:0')\n",
      "start with index 193\n",
      "path data/train_images/55530/40964 with total 80 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-1.4555],\n",
      "        [-3.8877],\n",
      "        [-2.2268],\n",
      "        [-1.2957],\n",
      "        [-6.7596]], device='cuda:0')\n",
      "tensor([[0.1892, 0.0201, 0.0974, 0.2149, 0.0012]], device='cuda:0')\n",
      "start with index 194\n",
      "path data/train_images/55882/35367 with total 792 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-2.9476],\n",
      "        [-1.6309],\n",
      "        [-0.1432],\n",
      "        [-3.3124],\n",
      "        [-3.5740]], device='cuda:0')\n",
      "tensor([[0.0498, 0.1637, 0.4643, 0.0351, 0.0273]], device='cuda:0')\n",
      "start with index 195\n",
      "path data/train_images/55947/29400 with total 230 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[ 5.1617],\n",
      "        [-4.4156],\n",
      "        [-6.7800],\n",
      "        [-5.7763],\n",
      "        [-7.4177]], device='cuda:0')\n",
      "tensor([[9.9430e-01, 1.1943e-02, 1.1349e-03, 3.0906e-03, 6.0018e-04]],\n",
      "       device='cuda:0')\n",
      "start with index 196\n",
      "path data/train_images/56071/51494 with total 201 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-5.0718],\n",
      "        [-2.7259],\n",
      "        [-0.3198],\n",
      "        [-0.9440],\n",
      "        [-3.8644]], device='cuda:0')\n",
      "tensor([[0.0062, 0.0615, 0.4207, 0.2801, 0.0205]], device='cuda:0')\n",
      "start with index 197\n",
      "path data/train_images/56685/43353 with total 653 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-1.5459],\n",
      "        [-0.8401],\n",
      "        [-2.6063],\n",
      "        [-4.2889],\n",
      "        [-5.8670]], device='cuda:0')\n",
      "tensor([[0.1757, 0.3015, 0.0687, 0.0135, 0.0028]], device='cuda:0')\n",
      "start with index 198\n",
      "path data/train_images/56810/10919 with total 619 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-4.8943],\n",
      "        [ 4.0684],\n",
      "        [-4.5798],\n",
      "        [-3.5581],\n",
      "        [-5.7852]], device='cuda:0')\n",
      "tensor([[0.0074, 0.9832, 0.0102, 0.0277, 0.0031]], device='cuda:0')\n",
      "start with index 199\n",
      "path data/train_images/56810/3148 with total 616 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-5.3567],\n",
      "        [ 2.4778],\n",
      "        [-2.8436],\n",
      "        [-4.5333],\n",
      "        [-4.9918]], device='cuda:0')\n",
      "tensor([[0.0047, 0.9226, 0.0550, 0.0106, 0.0067]], device='cuda:0')\n",
      "start with index 200\n",
      "path data/train_images/57038/2381 with total 104 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-2.0521],\n",
      "        [-0.3577],\n",
      "        [-4.8470],\n",
      "        [-3.3044],\n",
      "        [-4.5995]], device='cuda:0')\n",
      "tensor([[0.1138, 0.4115, 0.0078, 0.0354, 0.0100]], device='cuda:0')\n",
      "start with index 201\n",
      "path data/train_images/57038/32429 with total 179 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-1.3596],\n",
      "        [-0.8106],\n",
      "        [-4.6193],\n",
      "        [-4.0661],\n",
      "        [-5.2063]], device='cuda:0')\n",
      "tensor([[0.2043, 0.3078, 0.0098, 0.0169, 0.0055]], device='cuda:0')\n",
      "start with index 202\n",
      "path data/train_images/57149/27710 with total 748 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-3.9324],\n",
      "        [-5.7869],\n",
      "        [-3.4709],\n",
      "        [-2.9585],\n",
      "        [-3.2597]], device='cuda:0')\n",
      "tensor([[0.0192, 0.0031, 0.0302, 0.0493, 0.0370]], device='cuda:0')\n",
      "start with index 203\n",
      "path data/train_images/5775/5791 with total 166 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-0.5316],\n",
      "        [-1.6438],\n",
      "        [ 1.3784],\n",
      "        [-0.0595],\n",
      "        [-3.8510]], device='cuda:0')\n",
      "tensor([[0.3701, 0.1619, 0.7987, 0.4851, 0.0208]], device='cuda:0')\n",
      "start with index 204\n",
      "path data/train_images/58078/44980 with total 937 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-5.9080],\n",
      "        [-2.6099],\n",
      "        [-1.7686],\n",
      "        [-0.4113],\n",
      "        [-4.2891]], device='cuda:0')\n",
      "tensor([[0.0027, 0.0685, 0.1457, 0.3986, 0.0135]], device='cuda:0')\n",
      "start with index 205\n",
      "path data/train_images/58465/4486 with total 225 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-4.4962],\n",
      "        [-4.9475],\n",
      "        [-2.5079],\n",
      "        [-2.9513],\n",
      "        [ 0.7763]], device='cuda:0')\n",
      "tensor([[0.0110, 0.0071, 0.0753, 0.0497, 0.6849]], device='cuda:0')\n",
      "start with index 206\n",
      "path data/train_images/58465/62600 with total 465 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-3.1720],\n",
      "        [-3.7403],\n",
      "        [-3.3834],\n",
      "        [-3.4929],\n",
      "        [ 2.3287]], device='cuda:0')\n",
      "tensor([[0.0402, 0.0232, 0.0328, 0.0295, 0.9112]], device='cuda:0')\n",
      "start with index 207\n",
      "path data/train_images/5914/18543 with total 171 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-4.8892],\n",
      "        [ 3.7244],\n",
      "        [-0.5347],\n",
      "        [-2.5146],\n",
      "        [-4.7076]], device='cuda:0')\n",
      "tensor([[0.0075, 0.9764, 0.3694, 0.0748, 0.0089]], device='cuda:0')\n",
      "start with index 208\n",
      "path data/train_images/5914/59834 with total 190 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-4.9376],\n",
      "        [ 2.7528],\n",
      "        [-3.0636],\n",
      "        [-4.7026],\n",
      "        [-2.3662]], device='cuda:0')\n",
      "tensor([[0.0071, 0.9401, 0.0446, 0.0090, 0.0858]], device='cuda:0')\n",
      "start with index 209\n",
      "path data/train_images/59273/35540 with total 124 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-4.6491],\n",
      "        [ 2.5954],\n",
      "        [-2.2567],\n",
      "        [-2.9072],\n",
      "        [-7.4228]], device='cuda:0')\n",
      "tensor([[9.4793e-03, 9.3056e-01, 9.4774e-02, 5.1798e-02, 5.9711e-04]],\n",
      "       device='cuda:0')\n",
      "start with index 210\n",
      "path data/train_images/59273/61925 with total 185 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-6.2135],\n",
      "        [-0.7188],\n",
      "        [-0.2316],\n",
      "        [-4.6888],\n",
      "        [-5.5501]], device='cuda:0')\n",
      "tensor([[0.0020, 0.3277, 0.4424, 0.0091, 0.0039]], device='cuda:0')\n",
      "start with index 211\n",
      "path data/train_images/59299/44533 with total 99 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[ 0.0623],\n",
      "        [-4.2538],\n",
      "        [-3.2644],\n",
      "        [ 0.1362],\n",
      "        [-6.5994]], device='cuda:0')\n",
      "tensor([[0.5156, 0.0140, 0.0368, 0.5340, 0.0014]], device='cuda:0')\n",
      "start with index 212\n",
      "path data/train_images/59299/55910 with total 162 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-1.3551],\n",
      "        [-4.3192],\n",
      "        [-4.1280],\n",
      "        [-0.3545],\n",
      "        [-5.6827]], device='cuda:0')\n",
      "tensor([[0.2050, 0.0131, 0.0159, 0.4123, 0.0034]], device='cuda:0')\n",
      "start with index 213\n",
      "path data/train_images/60115/54532 with total 225 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-5.5066],\n",
      "        [ 1.0766],\n",
      "        [-3.3609],\n",
      "        [-3.9419],\n",
      "        [-5.6491]], device='cuda:0')\n",
      "tensor([[0.0040, 0.7459, 0.0335, 0.0190, 0.0035]], device='cuda:0')\n",
      "start with index 214\n",
      "path data/train_images/61464/50606 with total 738 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-1.8545],\n",
      "        [-1.0032],\n",
      "        [ 0.4030],\n",
      "        [ 3.1164],\n",
      "        [-5.6519]], device='cuda:0')\n",
      "tensor([[0.1353, 0.2683, 0.5994, 0.9576, 0.0035]], device='cuda:0')\n",
      "start with index 215\n",
      "path data/train_images/6203/11056 with total 170 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-1.5888],\n",
      "        [ 1.3340],\n",
      "        [-1.2709],\n",
      "        [-1.9894],\n",
      "        [-5.1027]], device='cuda:0')\n",
      "tensor([[0.1696, 0.7915, 0.2191, 0.1203, 0.0060]], device='cuda:0')\n",
      "start with index 216\n",
      "path data/train_images/6203/65224 with total 76 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-1.2721],\n",
      "        [-3.1216],\n",
      "        [-2.8818],\n",
      "        [-4.2846],\n",
      "        [-0.8843]], device='cuda:0')\n",
      "tensor([[0.2189, 0.0422, 0.0531, 0.0136, 0.2923]], device='cuda:0')\n",
      "start with index 217\n",
      "path data/train_images/62062/46426 with total 533 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-3.3948],\n",
      "        [ 0.0626],\n",
      "        [-1.5133],\n",
      "        [-2.2563],\n",
      "        [-6.2586]], device='cuda:0')\n",
      "tensor([[0.0325, 0.5156, 0.1804, 0.0948, 0.0019]], device='cuda:0')\n",
      "start with index 218\n",
      "path data/train_images/62062/56444 with total 567 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-2.1460],\n",
      "        [ 2.0572],\n",
      "        [ 0.2499],\n",
      "        [-3.1643],\n",
      "        [-6.5402]], device='cuda:0')\n",
      "tensor([[0.1047, 0.8867, 0.5621, 0.0405, 0.0014]], device='cuda:0')\n",
      "start with index 219\n",
      "path data/train_images/62179/7486 with total 718 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-4.3640],\n",
      "        [-3.3870],\n",
      "        [-4.3969],\n",
      "        [-2.6020],\n",
      "        [-5.5288]], device='cuda:0')\n",
      "tensor([[0.0126, 0.0327, 0.0122, 0.0690, 0.0040]], device='cuda:0')\n",
      "start with index 220\n",
      "path data/train_images/62376/22122 with total 800 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-4.8764],\n",
      "        [-3.6026],\n",
      "        [-5.3965],\n",
      "        [-3.3076],\n",
      "        [-5.3713]], device='cuda:0')\n",
      "tensor([[0.0076, 0.0265, 0.0045, 0.0353, 0.0046]], device='cuda:0')\n",
      "start with index 221\n",
      "path data/train_images/63443/21654 with total 281 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-1.0162],\n",
      "        [-5.7415],\n",
      "        [ 0.2154],\n",
      "        [-4.4243],\n",
      "        [-5.1168]], device='cuda:0')\n",
      "tensor([[0.2658, 0.0032, 0.5536, 0.0118, 0.0060]], device='cuda:0')\n",
      "start with index 222\n",
      "path data/train_images/63443/8174 with total 165 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-1.9392],\n",
      "        [-4.4886],\n",
      "        [-3.6577],\n",
      "        [ 1.0310],\n",
      "        [-6.4257]], device='cuda:0')\n",
      "tensor([[0.1257, 0.0111, 0.0251, 0.7371, 0.0016]], device='cuda:0')\n",
      "start with index 223\n",
      "path data/train_images/63662/1386 with total 706 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-3.5199],\n",
      "        [-7.1768],\n",
      "        [-5.4432],\n",
      "        [-4.4886],\n",
      "        [-4.8643]], device='cuda:0')\n",
      "tensor([[0.0288, 0.0008, 0.0043, 0.0111, 0.0077]], device='cuda:0')\n",
      "start with index 224\n",
      "path data/train_images/65415/60059 with total 117 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-0.4355],\n",
      "        [ 1.2347],\n",
      "        [-0.5418],\n",
      "        [-6.2250],\n",
      "        [ 0.1412]], device='cuda:0')\n",
      "tensor([[0.3928, 0.7746, 0.3678, 0.0020, 0.5352]], device='cuda:0')\n",
      "start with index 225\n",
      "path data/train_images/6773/43137 with total 116 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-4.2182],\n",
      "        [-2.0457],\n",
      "        [-3.0121],\n",
      "        [-3.3490],\n",
      "        [-6.4093]], device='cuda:0')\n",
      "tensor([[0.0145, 0.1145, 0.0469, 0.0339, 0.0016]], device='cuda:0')\n",
      "start with index 226\n",
      "path data/train_images/6773/64013 with total 159 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-2.5163],\n",
      "        [-2.0346],\n",
      "        [-2.3801],\n",
      "        [-3.9153],\n",
      "        [-6.5379]], device='cuda:0')\n",
      "tensor([[0.0747, 0.1156, 0.0847, 0.0195, 0.0014]], device='cuda:0')\n",
      "start with index 227\n",
      "path data/train_images/766/23185 with total 297 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-5.3027],\n",
      "        [-0.4259],\n",
      "        [-3.4399],\n",
      "        [-2.4396],\n",
      "        [-6.1717]], device='cuda:0')\n",
      "tensor([[0.0050, 0.3951, 0.0311, 0.0802, 0.0021]], device='cuda:0')\n",
      "start with index 228\n",
      "path data/train_images/766/49801 with total 665 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-5.7506],\n",
      "        [ 0.1157],\n",
      "        [-4.0910],\n",
      "        [-1.6903],\n",
      "        [-5.6271]], device='cuda:0')\n",
      "tensor([[0.0032, 0.5289, 0.0164, 0.1557, 0.0036]], device='cuda:0')\n",
      "start with index 229\n",
      "path data/train_images/8464/21220 with total 201 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-3.7760],\n",
      "        [ 0.1590],\n",
      "        [-0.7624],\n",
      "        [-1.9592],\n",
      "        [-2.7826]], device='cuda:0')\n",
      "tensor([[0.0224, 0.5397, 0.3181, 0.1235, 0.0583]], device='cuda:0')\n",
      "start with index 230\n",
      "path data/train_images/8464/5733 with total 184 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-2.0318],\n",
      "        [ 1.8214],\n",
      "        [-0.2790],\n",
      "        [ 0.1340],\n",
      "        [-5.5964]], device='cuda:0')\n",
      "tensor([[0.1159, 0.8607, 0.4307, 0.5334, 0.0037]], device='cuda:0')\n",
      "start with index 231\n",
      "path data/train_images/8537/51204 with total 735 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-4.4063],\n",
      "        [-4.1511],\n",
      "        [-1.4003],\n",
      "        [-0.6872],\n",
      "        [-5.6432]], device='cuda:0')\n",
      "tensor([[0.0121, 0.0155, 0.1978, 0.3347, 0.0035]], device='cuda:0')\n",
      "start with index 232\n",
      "path data/train_images/878/31368 with total 210 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-3.4751],\n",
      "        [ 0.0478],\n",
      "        [-2.2335],\n",
      "        [-4.1697],\n",
      "        [-3.5311]], device='cuda:0')\n",
      "tensor([[0.0300, 0.5119, 0.0968, 0.0152, 0.0284]], device='cuda:0')\n",
      "start with index 233\n",
      "path data/train_images/878/43708 with total 168 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-2.9568],\n",
      "        [ 0.9195],\n",
      "        [-2.1047],\n",
      "        [-5.0494],\n",
      "        [-4.4365]], device='cuda:0')\n",
      "tensor([[0.0494, 0.7149, 0.1086, 0.0064, 0.0117]], device='cuda:0')\n",
      "start with index 234\n",
      "path data/train_images/8848/41663 with total 427 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[ 3.2183],\n",
      "        [ 2.7682],\n",
      "        [-5.1143],\n",
      "        [-4.7752],\n",
      "        [-4.8744]], device='cuda:0')\n",
      "tensor([[0.9615, 0.9409, 0.0060, 0.0084, 0.0076]], device='cuda:0')\n",
      "start with index 235\n",
      "path data/train_images/8848/7384 with total 466 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[ 5.3140],\n",
      "        [ 1.3738],\n",
      "        [-5.3510],\n",
      "        [-2.4117],\n",
      "        [-3.3334]], device='cuda:0')\n",
      "tensor([[0.9951, 0.7980, 0.0047, 0.0823, 0.0344]], device='cuda:0')\n",
      "start with index 236\n",
      "path data/train_images/9190/44739 with total 614 scan\n",
      "cropped_images torch.Size([75, 224, 224, 6])\n",
      "logits tensor([[-2.9545],\n",
      "        [-5.0664],\n",
      "        [-2.7854],\n",
      "        [-3.0778],\n",
      "        [-4.2598]], device='cuda:0')\n",
      "tensor([[0.0495, 0.0063, 0.0581, 0.0440, 0.0139]], device='cuda:0')\n",
      "1324.8517653942108\n"
     ]
    }
   ],
   "source": [
    "output = []\n",
    "\n",
    "a = time.time()\n",
    "with torch.no_grad():\n",
    "    for batch_id, images in enumerate(loader_seg):\n",
    "        # if batch_id < 96:\n",
    "        #     continue\n",
    "        print('start with index {}'.format(batch_id))\n",
    "        images = images.cuda()\n",
    "        # seg\n",
    "        pmask = seg_model(images).sigmoid()\n",
    "        pmask = pmask.squeeze(0)\n",
    "   \n",
    "        mask = pmask.detach().cpu().numpy()\n",
    "        paths = df.loc[batch_id, 'dicom_folder']\n",
    "        \n",
    "        study_id = paths.split('/')[-1]\n",
    "        patient_id = paths.split('/')[-2]\n",
    "        t_paths = sorted(glob(os.path.join(paths, \"*\")), key=lambda x: int(x.split('/')[-1].split(\".\")[0]))\n",
    "        n_scans = len(t_paths)\n",
    "        print(f'path {paths} with total {n_scans} scan')\n",
    "        cls_inp = []\n",
    "        cropped_images = [None] * 5\n",
    "        \n",
    "        for cid in range(5):\n",
    "            bone = []\n",
    "            try:\n",
    "                msk_b = mask[cid] > 0.2\n",
    "                msk_c = mask[cid] > 0.05\n",
    "                x = np.where(msk_b.sum(1).sum(1) > 0)[0]\n",
    "                y = np.where(msk_b.sum(0).sum(1) > 0)[0]\n",
    "                z = np.where(msk_b.sum(0).sum(0) > 0)[0]\n",
    "    \n",
    "                if len(x) == 0 or len(y) == 0 or len(z) == 0:\n",
    "                    x = np.where(msk_c.sum(1).sum(1) > 0)[0]\n",
    "                    y = np.where(msk_c.sum(0).sum(1) > 0)[0]\n",
    "                    z = np.where(msk_c.sum(0).sum(0) > 0)[0]\n",
    "    \n",
    "                x1, x2 = max(0, x[0] - 1), min(mask.shape[1], x[-1] + 1)\n",
    "                y1, y2 = max(0, y[0] - 1), min(mask.shape[2], y[-1] + 1)\n",
    "                z1, z2 = max(0, z[0] - 1), min(mask.shape[3], z[-1] + 1)\n",
    "                zz1, zz2 = int(z1 / CFG.msk_size * n_scans), int(z2 / CFG.msk_size * n_scans)\n",
    "                inds = np.linspace(zz1 ,zz2-1, CFG.n_slice_per_c).astype(int)\n",
    "                inds_ = np.linspace(z1 ,z2-1, CFG.n_slice_per_c).astype(int)\n",
    "                for sid, (ind, ind_) in enumerate(zip(inds, inds_)):\n",
    "                    \n",
    "                    msk_this = mask[cid, :, :, ind_]\n",
    "                    images = []\n",
    "                    for i in range(-CFG.n_ch // 2 + 1, CFG.n_ch // 2 + 1):\n",
    "                        try:\n",
    "                            dicom = pydicom.read_file(t_paths[ind+i])\n",
    "                            images.append(dicom.pixel_array)\n",
    "                        except:\n",
    "                            images.append(np.zeros((512, 512)))\n",
    "                    data = np.stack(images, -1)\n",
    "                    data = data - np.min(data)\n",
    "                    data = data / (np.max(data) + 1e-4)\n",
    "                    data = (data * 255).astype(np.uint8)\n",
    "                    \n",
    "                    msk_this = msk_this[x1:x2, y1:y2]\n",
    "                    xx1 = int(x1 / CFG.msk_size * data.shape[0])\n",
    "                    xx2 = int(x2 / CFG.msk_size * data.shape[0])\n",
    "                    yy1 = int(y1 / CFG.msk_size * data.shape[1])\n",
    "                    yy2 = int(y2 / CFG.msk_size * data.shape[1])\n",
    "    \n",
    "                    data = data[xx1:xx2, yy1:yy2]\n",
    "                    data = np.stack([cv2.resize(data[:, :, i], (CFG.image_size_cls, CFG.image_size_cls), interpolation = cv2.INTER_LINEAR) for i in range(CFG.n_ch)], -1)\n",
    "                    msk_this = (msk_this * 255).astype(np.uint8)\n",
    "                    msk_this = cv2.resize(msk_this, (CFG.image_size_cls, CFG.image_size_cls), interpolation = cv2.INTER_LINEAR)\n",
    "    \n",
    "                    data = np.concatenate([data, msk_this[:, :, np.newaxis]], -1)\n",
    "                    bone.append(torch.tensor(data))\n",
    "            except:\n",
    "                bone = []\n",
    "                print('except process fail', cid)\n",
    "                for sid in range(CFG.n_slice_per_c):\n",
    "                    bone.append(torch.zeros((CFG.image_size_cls, CFG.image_size_cls, CFG.n_ch + 1)).int())\n",
    "            # print('bone', len(bone))\n",
    "            cropped_images[cid] = torch.stack(bone, 0)\n",
    "\n",
    "        cropped_images = torch.cat(cropped_images, 0)\n",
    "        print('cropped_images', cropped_images.size())\n",
    "        cls_inp = cropped_images.permute(0, 3, 1, 2).float() / 255.\n",
    "        cls_inp = cls_inp.to(CFG.device)\n",
    "        # cls_inp = cls_inp.unsqueeze(0) # (1, 15*5, 6, 224, 224)\n",
    "        cls_inp = cls_inp.view(5, 15, 6, CFG.image_size_cls, CFG.image_size_cls).contiguous()\n",
    "        pred_cls = []\n",
    "        for _, model in enumerate(cls_models):\n",
    "            logits = model(cls_inp)\n",
    "            print('logits', logits)\n",
    "            # logits = logits.sigmoid().view(-1, 5, CFG.n_slice_per_c)\n",
    "            logits = logits.sigmoid().view(-1, 5)\n",
    "            print(logits)\n",
    "            pred_cls.append(logits)\n",
    "        pred_cls = torch.stack(pred_cls, 0).mean(0)\n",
    "        output.append(pred_cls.cpu())\n",
    "        # logits = cls_model(cls_inp)\n",
    "        # print('logits', logits.size())\n",
    "        # logits = logits.sigmoid().view(-1, 5, CFG.n_slice_per_c)\n",
    "        # output.append(logits.cpu())\n",
    "\n",
    "map_cls = {0: 'liver', 1: 'spleen', 2: 'kidney', 3: 'kidney', 4: 'bowel'}\n",
    "print(time.time() - a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a8d7a024-67ce-46f4-bd39-a1fec26f5579",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('data/train_dict.json', 'r') as fr:\n",
    "    aohus = json.load(fr)\n",
    "\n",
    "\n",
    "def norm_to_one(x):\n",
    "    s = sum(x)\n",
    "    x=[xx/s for xx in x]\n",
    "    return x\n",
    "\n",
    "\n",
    "def post_process(preds, df):\n",
    "    all = []\n",
    "    # weight mean extra\n",
    "    train = pd.read_csv(f'{CFG.data_dir}/train.csv')\n",
    "    features_bowel = ['bowel_healthy', 'bowel_injury']\n",
    "    features = ['extravasation_healthy', 'extravasation_injury']\n",
    "    \n",
    "    extra = train[features].mean().tolist()\n",
    "    extra = norm_to_one([extra[0], extra[1] * 6])\n",
    "    # bowel = train[features_bowel].mean().tolist()\n",
    "    # bowel = norm_to_one([bowel[0], bowel[1] * 6])\n",
    "    print('extravasation value', extra)\n",
    "    # print('bowel value', bowel)\n",
    "    # extra[1] = extra[1] * 6\n",
    "    # extra[2] = extra[2] * 28\n",
    "    # for idx, (pred, aohu) in enumerate(zip(preds, aohus)):\n",
    "    #     if str(aohu) in data_aohu.keys():\n",
    "    #         aohu_weight = data_aohu[str(aohu)]\n",
    "    #     else:\n",
    "    #         aohu_weight = 1\n",
    "    for idx, pred in enumerate(preds):\n",
    "        liver_pred, spleen_pred, kidney_left_pred, kidney_right_pred, bowel_pred = pred\n",
    "        liver_healthy, liver_low, liver_high = (1 - liver_pred), liver_pred / 6, liver_pred / 6\n",
    "        # liver_healthy, liver_low, liver_high = 0.897998, 0.223392, 0.019701\n",
    "        spleen_healthy, spleen_low, spleen_high = (1 - spleen_pred), spleen_pred / 6, spleen_pred / 6\n",
    "        # spleen_healthy, spleen_low, spleen_high = 0.887512, 0.171641, 0.049253\n",
    "        kidney_pred = (kidney_left_pred + kidney_right_pred) / 2\n",
    "        kidney_healthy, kidney_low, kidney_high = (1 - kidney_pred), kidney_pred / 6, kidney_pred / 6\n",
    "        # kidney_healthy, kidney_low, kidney_high = 0.942167, 0.099189, 0.141749\n",
    "        bowel_healthy, bowel_injury = (1 - bowel_pred), bowel_pred / 2\n",
    "        # bowel_healthy, bowel_injury = 0.979663, 0.135402\n",
    "        all.append([df.loc[idx, 'patient_id'], bowel_healthy, bowel_injury, extra[0], extra[1], kidney_healthy,\n",
    "                    kidney_low, kidney_high, liver_healthy, liver_low, liver_high,\n",
    "                    spleen_healthy, spleen_low, spleen_high])\n",
    "    return all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d89439a-9746-4a4e-ac8e-ffba1496231a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extravasation value [0.7106341933928141, 0.2893658066071859]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mapping = {0: 'liver', 1: 'spleen', 2: 'kidney', 3: 'kidney', 4: 'bowel'}\n",
    "outputs = torch.cat(output)\n",
    "preds = outputs\n",
    "\n",
    "# preds, _ = torch.max(outputs, dim=2)\n",
    "# print(preds)\n",
    "# preds = (outputs.mean(-1)).clamp(0.0001, 0.9999)\n",
    "preds = preds.detach().cpu().numpy()\n",
    "preds = post_process(preds, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b8fb8969-bf06-4dab-ab19-81e3afe88e98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>bowel_healthy</th>\n",
       "      <th>bowel_injury</th>\n",
       "      <th>extravasation_healthy</th>\n",
       "      <th>extravasation_injury</th>\n",
       "      <th>kidney_healthy</th>\n",
       "      <th>kidney_low</th>\n",
       "      <th>kidney_high</th>\n",
       "      <th>liver_healthy</th>\n",
       "      <th>liver_low</th>\n",
       "      <th>liver_high</th>\n",
       "      <th>spleen_healthy</th>\n",
       "      <th>spleen_low</th>\n",
       "      <th>spleen_high</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>263</td>\n",
       "      <td>0.996290</td>\n",
       "      <td>0.001855</td>\n",
       "      <td>0.710634</td>\n",
       "      <td>0.289366</td>\n",
       "      <td>0.896853</td>\n",
       "      <td>0.017191</td>\n",
       "      <td>0.017191</td>\n",
       "      <td>0.949229</td>\n",
       "      <td>0.008462</td>\n",
       "      <td>0.008462</td>\n",
       "      <td>0.996306</td>\n",
       "      <td>0.000616</td>\n",
       "      <td>0.000616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>394</td>\n",
       "      <td>0.998264</td>\n",
       "      <td>0.000868</td>\n",
       "      <td>0.710634</td>\n",
       "      <td>0.289366</td>\n",
       "      <td>0.499183</td>\n",
       "      <td>0.083470</td>\n",
       "      <td>0.083470</td>\n",
       "      <td>0.988489</td>\n",
       "      <td>0.001919</td>\n",
       "      <td>0.001919</td>\n",
       "      <td>0.989036</td>\n",
       "      <td>0.001827</td>\n",
       "      <td>0.001827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>470</td>\n",
       "      <td>0.996143</td>\n",
       "      <td>0.001928</td>\n",
       "      <td>0.710634</td>\n",
       "      <td>0.289366</td>\n",
       "      <td>0.985217</td>\n",
       "      <td>0.002464</td>\n",
       "      <td>0.002464</td>\n",
       "      <td>0.327805</td>\n",
       "      <td>0.112033</td>\n",
       "      <td>0.112033</td>\n",
       "      <td>0.644929</td>\n",
       "      <td>0.059178</td>\n",
       "      <td>0.059178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>470</td>\n",
       "      <td>0.999183</td>\n",
       "      <td>0.000409</td>\n",
       "      <td>0.710634</td>\n",
       "      <td>0.289366</td>\n",
       "      <td>0.949890</td>\n",
       "      <td>0.008352</td>\n",
       "      <td>0.008352</td>\n",
       "      <td>0.887727</td>\n",
       "      <td>0.018712</td>\n",
       "      <td>0.018712</td>\n",
       "      <td>0.905172</td>\n",
       "      <td>0.015805</td>\n",
       "      <td>0.015805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>766</td>\n",
       "      <td>0.996414</td>\n",
       "      <td>0.001793</td>\n",
       "      <td>0.710634</td>\n",
       "      <td>0.289366</td>\n",
       "      <td>0.913907</td>\n",
       "      <td>0.014349</td>\n",
       "      <td>0.014349</td>\n",
       "      <td>0.996829</td>\n",
       "      <td>0.000528</td>\n",
       "      <td>0.000528</td>\n",
       "      <td>0.471110</td>\n",
       "      <td>0.088148</td>\n",
       "      <td>0.088148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     patient_id  bowel_healthy  bowel_injury  extravasation_healthy  \\\n",
       "73          263       0.996290      0.001855               0.710634   \n",
       "134         394       0.998264      0.000868               0.710634   \n",
       "154         470       0.996143      0.001928               0.710634   \n",
       "153         470       0.999183      0.000409               0.710634   \n",
       "228         766       0.996414      0.001793               0.710634   \n",
       "\n",
       "     extravasation_injury  kidney_healthy  kidney_low  kidney_high  \\\n",
       "73               0.289366        0.896853    0.017191     0.017191   \n",
       "134              0.289366        0.499183    0.083470     0.083470   \n",
       "154              0.289366        0.985217    0.002464     0.002464   \n",
       "153              0.289366        0.949890    0.008352     0.008352   \n",
       "228              0.289366        0.913907    0.014349     0.014349   \n",
       "\n",
       "     liver_healthy  liver_low  liver_high  spleen_healthy  spleen_low  \\\n",
       "73        0.949229   0.008462    0.008462        0.996306    0.000616   \n",
       "134       0.988489   0.001919    0.001919        0.989036    0.001827   \n",
       "154       0.327805   0.112033    0.112033        0.644929    0.059178   \n",
       "153       0.887727   0.018712    0.018712        0.905172    0.015805   \n",
       "228       0.996829   0.000528    0.000528        0.471110    0.088148   \n",
       "\n",
       "     spleen_high  \n",
       "73      0.000616  \n",
       "134     0.001827  \n",
       "154     0.059178  \n",
       "153     0.015805  \n",
       "228     0.088148  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df = pd.DataFrame(preds, columns=['patient_id', 'bowel_healthy', 'bowel_injury', 'extravasation_healthy', 'extravasation_injury',\n",
    "                                      'kidney_healthy', 'kidney_low', 'kidney_high', 'liver_healthy', 'liver_low', 'liver_high',\n",
    "                                      'spleen_healthy', 'spleen_low', 'spleen_high'])\n",
    "sub_df = sub_df.sort_values(by='patient_id')\n",
    "sub_df.head(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3acec42b-1c56-4c6e-b690-7e179a409be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# with open('data/train_dict.json', 'w') as fw:\n",
    "    \n",
    "sub_df = sub_df.groupby('patient_id').mean().reset_index()\n",
    "# sub_df = sub_df.fillna(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7dd883da-fdf0-417c-9019-2eb5c64b96c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>bowel_healthy</th>\n",
       "      <th>bowel_injury</th>\n",
       "      <th>extravasation_healthy</th>\n",
       "      <th>extravasation_injury</th>\n",
       "      <th>kidney_healthy</th>\n",
       "      <th>kidney_low</th>\n",
       "      <th>kidney_high</th>\n",
       "      <th>liver_healthy</th>\n",
       "      <th>liver_low</th>\n",
       "      <th>liver_high</th>\n",
       "      <th>spleen_healthy</th>\n",
       "      <th>spleen_low</th>\n",
       "      <th>spleen_high</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>263</td>\n",
       "      <td>0.996290</td>\n",
       "      <td>0.001855</td>\n",
       "      <td>0.710634</td>\n",
       "      <td>0.289366</td>\n",
       "      <td>0.896853</td>\n",
       "      <td>0.017191</td>\n",
       "      <td>0.017191</td>\n",
       "      <td>0.949229</td>\n",
       "      <td>0.008462</td>\n",
       "      <td>0.008462</td>\n",
       "      <td>0.996306</td>\n",
       "      <td>0.000616</td>\n",
       "      <td>0.000616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>394</td>\n",
       "      <td>0.998264</td>\n",
       "      <td>0.000868</td>\n",
       "      <td>0.710634</td>\n",
       "      <td>0.289366</td>\n",
       "      <td>0.499183</td>\n",
       "      <td>0.083470</td>\n",
       "      <td>0.083470</td>\n",
       "      <td>0.988489</td>\n",
       "      <td>0.001919</td>\n",
       "      <td>0.001919</td>\n",
       "      <td>0.989036</td>\n",
       "      <td>0.001827</td>\n",
       "      <td>0.001827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>470</td>\n",
       "      <td>0.997663</td>\n",
       "      <td>0.001169</td>\n",
       "      <td>0.710634</td>\n",
       "      <td>0.289366</td>\n",
       "      <td>0.967554</td>\n",
       "      <td>0.005408</td>\n",
       "      <td>0.005408</td>\n",
       "      <td>0.607766</td>\n",
       "      <td>0.065372</td>\n",
       "      <td>0.065372</td>\n",
       "      <td>0.775050</td>\n",
       "      <td>0.037492</td>\n",
       "      <td>0.037492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>766</td>\n",
       "      <td>0.997165</td>\n",
       "      <td>0.001417</td>\n",
       "      <td>0.710634</td>\n",
       "      <td>0.289366</td>\n",
       "      <td>0.929134</td>\n",
       "      <td>0.011811</td>\n",
       "      <td>0.011811</td>\n",
       "      <td>0.995938</td>\n",
       "      <td>0.000677</td>\n",
       "      <td>0.000677</td>\n",
       "      <td>0.537997</td>\n",
       "      <td>0.077000</td>\n",
       "      <td>0.077000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>878</td>\n",
       "      <td>0.979931</td>\n",
       "      <td>0.010035</td>\n",
       "      <td>0.710634</td>\n",
       "      <td>0.289366</td>\n",
       "      <td>0.943247</td>\n",
       "      <td>0.009459</td>\n",
       "      <td>0.009459</td>\n",
       "      <td>0.960277</td>\n",
       "      <td>0.006620</td>\n",
       "      <td>0.006620</td>\n",
       "      <td>0.386555</td>\n",
       "      <td>0.102241</td>\n",
       "      <td>0.102241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1900</td>\n",
       "      <td>0.998812</td>\n",
       "      <td>0.000594</td>\n",
       "      <td>0.710634</td>\n",
       "      <td>0.289366</td>\n",
       "      <td>0.996052</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.013177</td>\n",
       "      <td>0.164471</td>\n",
       "      <td>0.164471</td>\n",
       "      <td>0.958792</td>\n",
       "      <td>0.006868</td>\n",
       "      <td>0.006868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2288</td>\n",
       "      <td>0.985826</td>\n",
       "      <td>0.007087</td>\n",
       "      <td>0.710634</td>\n",
       "      <td>0.289366</td>\n",
       "      <td>0.341038</td>\n",
       "      <td>0.109827</td>\n",
       "      <td>0.109827</td>\n",
       "      <td>0.742488</td>\n",
       "      <td>0.042919</td>\n",
       "      <td>0.042919</td>\n",
       "      <td>0.102959</td>\n",
       "      <td>0.149507</td>\n",
       "      <td>0.149507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2940</td>\n",
       "      <td>0.959369</td>\n",
       "      <td>0.020315</td>\n",
       "      <td>0.710634</td>\n",
       "      <td>0.289366</td>\n",
       "      <td>0.894200</td>\n",
       "      <td>0.017633</td>\n",
       "      <td>0.017633</td>\n",
       "      <td>0.914503</td>\n",
       "      <td>0.014249</td>\n",
       "      <td>0.014249</td>\n",
       "      <td>0.946050</td>\n",
       "      <td>0.008992</td>\n",
       "      <td>0.008992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2978</td>\n",
       "      <td>0.982794</td>\n",
       "      <td>0.008603</td>\n",
       "      <td>0.710634</td>\n",
       "      <td>0.289366</td>\n",
       "      <td>0.880377</td>\n",
       "      <td>0.019937</td>\n",
       "      <td>0.019937</td>\n",
       "      <td>0.773608</td>\n",
       "      <td>0.037732</td>\n",
       "      <td>0.037732</td>\n",
       "      <td>0.626991</td>\n",
       "      <td>0.062168</td>\n",
       "      <td>0.062168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3881</td>\n",
       "      <td>0.998970</td>\n",
       "      <td>0.000515</td>\n",
       "      <td>0.710634</td>\n",
       "      <td>0.289366</td>\n",
       "      <td>0.939118</td>\n",
       "      <td>0.010147</td>\n",
       "      <td>0.010147</td>\n",
       "      <td>0.944011</td>\n",
       "      <td>0.009331</td>\n",
       "      <td>0.009331</td>\n",
       "      <td>0.847058</td>\n",
       "      <td>0.025490</td>\n",
       "      <td>0.025490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4313</td>\n",
       "      <td>0.606005</td>\n",
       "      <td>0.196997</td>\n",
       "      <td>0.710634</td>\n",
       "      <td>0.289366</td>\n",
       "      <td>0.944253</td>\n",
       "      <td>0.009291</td>\n",
       "      <td>0.009291</td>\n",
       "      <td>0.981201</td>\n",
       "      <td>0.003133</td>\n",
       "      <td>0.003133</td>\n",
       "      <td>0.999301</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>0.000117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4453</td>\n",
       "      <td>0.973713</td>\n",
       "      <td>0.013143</td>\n",
       "      <td>0.710634</td>\n",
       "      <td>0.289366</td>\n",
       "      <td>0.969590</td>\n",
       "      <td>0.005068</td>\n",
       "      <td>0.005068</td>\n",
       "      <td>0.920355</td>\n",
       "      <td>0.013274</td>\n",
       "      <td>0.013274</td>\n",
       "      <td>0.983908</td>\n",
       "      <td>0.002682</td>\n",
       "      <td>0.002682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4791</td>\n",
       "      <td>0.978631</td>\n",
       "      <td>0.010685</td>\n",
       "      <td>0.710634</td>\n",
       "      <td>0.289366</td>\n",
       "      <td>0.987716</td>\n",
       "      <td>0.002047</td>\n",
       "      <td>0.002047</td>\n",
       "      <td>0.020406</td>\n",
       "      <td>0.163266</td>\n",
       "      <td>0.163266</td>\n",
       "      <td>0.096275</td>\n",
       "      <td>0.150621</td>\n",
       "      <td>0.150621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4813</td>\n",
       "      <td>0.972244</td>\n",
       "      <td>0.013878</td>\n",
       "      <td>0.710634</td>\n",
       "      <td>0.289366</td>\n",
       "      <td>0.990678</td>\n",
       "      <td>0.001554</td>\n",
       "      <td>0.001554</td>\n",
       "      <td>0.002773</td>\n",
       "      <td>0.166204</td>\n",
       "      <td>0.166204</td>\n",
       "      <td>0.980938</td>\n",
       "      <td>0.003177</td>\n",
       "      <td>0.003177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5260</td>\n",
       "      <td>0.998154</td>\n",
       "      <td>0.000923</td>\n",
       "      <td>0.710634</td>\n",
       "      <td>0.289366</td>\n",
       "      <td>0.966998</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>0.994712</td>\n",
       "      <td>0.000881</td>\n",
       "      <td>0.000881</td>\n",
       "      <td>0.569571</td>\n",
       "      <td>0.071738</td>\n",
       "      <td>0.071738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5775</td>\n",
       "      <td>0.979184</td>\n",
       "      <td>0.010408</td>\n",
       "      <td>0.710634</td>\n",
       "      <td>0.289366</td>\n",
       "      <td>0.358067</td>\n",
       "      <td>0.106989</td>\n",
       "      <td>0.106989</td>\n",
       "      <td>0.629860</td>\n",
       "      <td>0.061690</td>\n",
       "      <td>0.061690</td>\n",
       "      <td>0.838052</td>\n",
       "      <td>0.026991</td>\n",
       "      <td>0.026991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5914</td>\n",
       "      <td>0.952633</td>\n",
       "      <td>0.023683</td>\n",
       "      <td>0.710634</td>\n",
       "      <td>0.289366</td>\n",
       "      <td>0.875527</td>\n",
       "      <td>0.020745</td>\n",
       "      <td>0.020745</td>\n",
       "      <td>0.992704</td>\n",
       "      <td>0.001216</td>\n",
       "      <td>0.001216</td>\n",
       "      <td>0.041744</td>\n",
       "      <td>0.159709</td>\n",
       "      <td>0.159709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6203</td>\n",
       "      <td>0.850832</td>\n",
       "      <td>0.074584</td>\n",
       "      <td>0.710634</td>\n",
       "      <td>0.289366</td>\n",
       "      <td>0.898480</td>\n",
       "      <td>0.016920</td>\n",
       "      <td>0.016920</td>\n",
       "      <td>0.805778</td>\n",
       "      <td>0.032370</td>\n",
       "      <td>0.032370</td>\n",
       "      <td>0.583135</td>\n",
       "      <td>0.069478</td>\n",
       "      <td>0.069478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>6773</td>\n",
       "      <td>0.998456</td>\n",
       "      <td>0.000772</td>\n",
       "      <td>0.710634</td>\n",
       "      <td>0.289366</td>\n",
       "      <td>0.953735</td>\n",
       "      <td>0.007711</td>\n",
       "      <td>0.007711</td>\n",
       "      <td>0.955381</td>\n",
       "      <td>0.007436</td>\n",
       "      <td>0.007436</td>\n",
       "      <td>0.884944</td>\n",
       "      <td>0.019176</td>\n",
       "      <td>0.019176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>8464</td>\n",
       "      <td>0.969015</td>\n",
       "      <td>0.015492</td>\n",
       "      <td>0.710634</td>\n",
       "      <td>0.289366</td>\n",
       "      <td>0.648542</td>\n",
       "      <td>0.058576</td>\n",
       "      <td>0.058576</td>\n",
       "      <td>0.930846</td>\n",
       "      <td>0.011526</td>\n",
       "      <td>0.011526</td>\n",
       "      <td>0.299795</td>\n",
       "      <td>0.116701</td>\n",
       "      <td>0.116701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>8537</td>\n",
       "      <td>0.996471</td>\n",
       "      <td>0.001764</td>\n",
       "      <td>0.710634</td>\n",
       "      <td>0.289366</td>\n",
       "      <td>0.733788</td>\n",
       "      <td>0.044369</td>\n",
       "      <td>0.044369</td>\n",
       "      <td>0.987947</td>\n",
       "      <td>0.002009</td>\n",
       "      <td>0.002009</td>\n",
       "      <td>0.984497</td>\n",
       "      <td>0.002584</td>\n",
       "      <td>0.002584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>8848</td>\n",
       "      <td>0.978988</td>\n",
       "      <td>0.010506</td>\n",
       "      <td>0.710634</td>\n",
       "      <td>0.289366</td>\n",
       "      <td>0.974664</td>\n",
       "      <td>0.004223</td>\n",
       "      <td>0.004223</td>\n",
       "      <td>0.021691</td>\n",
       "      <td>0.163052</td>\n",
       "      <td>0.163052</td>\n",
       "      <td>0.130534</td>\n",
       "      <td>0.144911</td>\n",
       "      <td>0.144911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>9190</td>\n",
       "      <td>0.986072</td>\n",
       "      <td>0.006964</td>\n",
       "      <td>0.710634</td>\n",
       "      <td>0.289366</td>\n",
       "      <td>0.948923</td>\n",
       "      <td>0.008513</td>\n",
       "      <td>0.008513</td>\n",
       "      <td>0.950477</td>\n",
       "      <td>0.008254</td>\n",
       "      <td>0.008254</td>\n",
       "      <td>0.993734</td>\n",
       "      <td>0.001044</td>\n",
       "      <td>0.001044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>10172</td>\n",
       "      <td>0.618591</td>\n",
       "      <td>0.190705</td>\n",
       "      <td>0.710634</td>\n",
       "      <td>0.289366</td>\n",
       "      <td>0.813905</td>\n",
       "      <td>0.031016</td>\n",
       "      <td>0.031016</td>\n",
       "      <td>0.392101</td>\n",
       "      <td>0.101316</td>\n",
       "      <td>0.101316</td>\n",
       "      <td>0.373220</td>\n",
       "      <td>0.104463</td>\n",
       "      <td>0.104463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>11301</td>\n",
       "      <td>0.998071</td>\n",
       "      <td>0.000965</td>\n",
       "      <td>0.710634</td>\n",
       "      <td>0.289366</td>\n",
       "      <td>0.949085</td>\n",
       "      <td>0.008486</td>\n",
       "      <td>0.008486</td>\n",
       "      <td>0.991023</td>\n",
       "      <td>0.001496</td>\n",
       "      <td>0.001496</td>\n",
       "      <td>0.034544</td>\n",
       "      <td>0.160909</td>\n",
       "      <td>0.160909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>11378</td>\n",
       "      <td>0.989860</td>\n",
       "      <td>0.005070</td>\n",
       "      <td>0.710634</td>\n",
       "      <td>0.289366</td>\n",
       "      <td>0.338609</td>\n",
       "      <td>0.110232</td>\n",
       "      <td>0.110232</td>\n",
       "      <td>0.960068</td>\n",
       "      <td>0.006655</td>\n",
       "      <td>0.006655</td>\n",
       "      <td>0.993807</td>\n",
       "      <td>0.001032</td>\n",
       "      <td>0.001032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>12299</td>\n",
       "      <td>0.999220</td>\n",
       "      <td>0.000390</td>\n",
       "      <td>0.710634</td>\n",
       "      <td>0.289366</td>\n",
       "      <td>0.919767</td>\n",
       "      <td>0.013372</td>\n",
       "      <td>0.013372</td>\n",
       "      <td>0.960669</td>\n",
       "      <td>0.006555</td>\n",
       "      <td>0.006555</td>\n",
       "      <td>0.669746</td>\n",
       "      <td>0.055042</td>\n",
       "      <td>0.055042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>13106</td>\n",
       "      <td>0.561644</td>\n",
       "      <td>0.219178</td>\n",
       "      <td>0.710634</td>\n",
       "      <td>0.289366</td>\n",
       "      <td>0.222605</td>\n",
       "      <td>0.129566</td>\n",
       "      <td>0.129566</td>\n",
       "      <td>0.789782</td>\n",
       "      <td>0.035036</td>\n",
       "      <td>0.035036</td>\n",
       "      <td>0.321041</td>\n",
       "      <td>0.113160</td>\n",
       "      <td>0.113160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>13182</td>\n",
       "      <td>0.995607</td>\n",
       "      <td>0.002196</td>\n",
       "      <td>0.710634</td>\n",
       "      <td>0.289366</td>\n",
       "      <td>0.980198</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.204501</td>\n",
       "      <td>0.132583</td>\n",
       "      <td>0.132583</td>\n",
       "      <td>0.615995</td>\n",
       "      <td>0.064001</td>\n",
       "      <td>0.064001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>13250</td>\n",
       "      <td>0.999010</td>\n",
       "      <td>0.000495</td>\n",
       "      <td>0.710634</td>\n",
       "      <td>0.289366</td>\n",
       "      <td>0.930789</td>\n",
       "      <td>0.011535</td>\n",
       "      <td>0.011535</td>\n",
       "      <td>0.968437</td>\n",
       "      <td>0.005260</td>\n",
       "      <td>0.005260</td>\n",
       "      <td>0.678876</td>\n",
       "      <td>0.053521</td>\n",
       "      <td>0.053521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>13403</td>\n",
       "      <td>0.840666</td>\n",
       "      <td>0.079667</td>\n",
       "      <td>0.710634</td>\n",
       "      <td>0.289366</td>\n",
       "      <td>0.638029</td>\n",
       "      <td>0.060329</td>\n",
       "      <td>0.060329</td>\n",
       "      <td>0.942020</td>\n",
       "      <td>0.009663</td>\n",
       "      <td>0.009663</td>\n",
       "      <td>0.987108</td>\n",
       "      <td>0.002149</td>\n",
       "      <td>0.002149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>13623</td>\n",
       "      <td>0.996785</td>\n",
       "      <td>0.001608</td>\n",
       "      <td>0.710634</td>\n",
       "      <td>0.289366</td>\n",
       "      <td>0.416677</td>\n",
       "      <td>0.097220</td>\n",
       "      <td>0.097220</td>\n",
       "      <td>0.901302</td>\n",
       "      <td>0.016450</td>\n",
       "      <td>0.016450</td>\n",
       "      <td>0.037338</td>\n",
       "      <td>0.160444</td>\n",
       "      <td>0.160444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>14616</td>\n",
       "      <td>0.759020</td>\n",
       "      <td>0.120490</td>\n",
       "      <td>0.710634</td>\n",
       "      <td>0.289366</td>\n",
       "      <td>0.667752</td>\n",
       "      <td>0.055375</td>\n",
       "      <td>0.055375</td>\n",
       "      <td>0.949503</td>\n",
       "      <td>0.008416</td>\n",
       "      <td>0.008416</td>\n",
       "      <td>0.808516</td>\n",
       "      <td>0.031914</td>\n",
       "      <td>0.031914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>14831</td>\n",
       "      <td>0.929942</td>\n",
       "      <td>0.035029</td>\n",
       "      <td>0.710634</td>\n",
       "      <td>0.289366</td>\n",
       "      <td>0.856749</td>\n",
       "      <td>0.023875</td>\n",
       "      <td>0.023875</td>\n",
       "      <td>0.999237</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>0.994714</td>\n",
       "      <td>0.000881</td>\n",
       "      <td>0.000881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>14846</td>\n",
       "      <td>0.995472</td>\n",
       "      <td>0.002264</td>\n",
       "      <td>0.710634</td>\n",
       "      <td>0.289366</td>\n",
       "      <td>0.928398</td>\n",
       "      <td>0.011934</td>\n",
       "      <td>0.011934</td>\n",
       "      <td>0.809329</td>\n",
       "      <td>0.031778</td>\n",
       "      <td>0.031778</td>\n",
       "      <td>0.984055</td>\n",
       "      <td>0.002657</td>\n",
       "      <td>0.002657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>15404</td>\n",
       "      <td>0.994900</td>\n",
       "      <td>0.002550</td>\n",
       "      <td>0.710634</td>\n",
       "      <td>0.289366</td>\n",
       "      <td>0.757019</td>\n",
       "      <td>0.040497</td>\n",
       "      <td>0.040497</td>\n",
       "      <td>0.986661</td>\n",
       "      <td>0.002223</td>\n",
       "      <td>0.002223</td>\n",
       "      <td>0.993195</td>\n",
       "      <td>0.001134</td>\n",
       "      <td>0.001134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>15419</td>\n",
       "      <td>0.993021</td>\n",
       "      <td>0.003490</td>\n",
       "      <td>0.710634</td>\n",
       "      <td>0.289366</td>\n",
       "      <td>0.786809</td>\n",
       "      <td>0.035532</td>\n",
       "      <td>0.035532</td>\n",
       "      <td>0.877434</td>\n",
       "      <td>0.020428</td>\n",
       "      <td>0.020428</td>\n",
       "      <td>0.380480</td>\n",
       "      <td>0.103253</td>\n",
       "      <td>0.103253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>15620</td>\n",
       "      <td>0.920579</td>\n",
       "      <td>0.039711</td>\n",
       "      <td>0.710634</td>\n",
       "      <td>0.289366</td>\n",
       "      <td>0.771279</td>\n",
       "      <td>0.038120</td>\n",
       "      <td>0.038120</td>\n",
       "      <td>0.427091</td>\n",
       "      <td>0.095485</td>\n",
       "      <td>0.095485</td>\n",
       "      <td>0.004421</td>\n",
       "      <td>0.165930</td>\n",
       "      <td>0.165930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>16198</td>\n",
       "      <td>0.998401</td>\n",
       "      <td>0.000799</td>\n",
       "      <td>0.710634</td>\n",
       "      <td>0.289366</td>\n",
       "      <td>0.897888</td>\n",
       "      <td>0.017019</td>\n",
       "      <td>0.017019</td>\n",
       "      <td>0.955783</td>\n",
       "      <td>0.007370</td>\n",
       "      <td>0.007370</td>\n",
       "      <td>0.508866</td>\n",
       "      <td>0.081856</td>\n",
       "      <td>0.081856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>16202</td>\n",
       "      <td>0.998905</td>\n",
       "      <td>0.000548</td>\n",
       "      <td>0.710634</td>\n",
       "      <td>0.289366</td>\n",
       "      <td>0.976079</td>\n",
       "      <td>0.003987</td>\n",
       "      <td>0.003987</td>\n",
       "      <td>0.940295</td>\n",
       "      <td>0.009951</td>\n",
       "      <td>0.009951</td>\n",
       "      <td>0.689830</td>\n",
       "      <td>0.051695</td>\n",
       "      <td>0.051695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>16368</td>\n",
       "      <td>0.990521</td>\n",
       "      <td>0.004740</td>\n",
       "      <td>0.710634</td>\n",
       "      <td>0.289366</td>\n",
       "      <td>0.674784</td>\n",
       "      <td>0.054203</td>\n",
       "      <td>0.054203</td>\n",
       "      <td>0.738740</td>\n",
       "      <td>0.043543</td>\n",
       "      <td>0.043543</td>\n",
       "      <td>0.972796</td>\n",
       "      <td>0.004534</td>\n",
       "      <td>0.004534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>16450</td>\n",
       "      <td>0.969446</td>\n",
       "      <td>0.015277</td>\n",
       "      <td>0.710634</td>\n",
       "      <td>0.289366</td>\n",
       "      <td>0.978325</td>\n",
       "      <td>0.003612</td>\n",
       "      <td>0.003612</td>\n",
       "      <td>0.876570</td>\n",
       "      <td>0.020572</td>\n",
       "      <td>0.020572</td>\n",
       "      <td>0.657591</td>\n",
       "      <td>0.057068</td>\n",
       "      <td>0.057068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>16691</td>\n",
       "      <td>0.984319</td>\n",
       "      <td>0.007841</td>\n",
       "      <td>0.710634</td>\n",
       "      <td>0.289366</td>\n",
       "      <td>0.998099</td>\n",
       "      <td>0.000317</td>\n",
       "      <td>0.000317</td>\n",
       "      <td>0.992650</td>\n",
       "      <td>0.001225</td>\n",
       "      <td>0.001225</td>\n",
       "      <td>0.893257</td>\n",
       "      <td>0.017790</td>\n",
       "      <td>0.017790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>17439</td>\n",
       "      <td>0.993817</td>\n",
       "      <td>0.003091</td>\n",
       "      <td>0.710634</td>\n",
       "      <td>0.289366</td>\n",
       "      <td>0.917785</td>\n",
       "      <td>0.013703</td>\n",
       "      <td>0.013703</td>\n",
       "      <td>0.978143</td>\n",
       "      <td>0.003643</td>\n",
       "      <td>0.003643</td>\n",
       "      <td>0.842179</td>\n",
       "      <td>0.026303</td>\n",
       "      <td>0.026303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>19160</td>\n",
       "      <td>0.997487</td>\n",
       "      <td>0.001256</td>\n",
       "      <td>0.710634</td>\n",
       "      <td>0.289366</td>\n",
       "      <td>0.913909</td>\n",
       "      <td>0.014349</td>\n",
       "      <td>0.014349</td>\n",
       "      <td>0.275750</td>\n",
       "      <td>0.120708</td>\n",
       "      <td>0.120708</td>\n",
       "      <td>0.592851</td>\n",
       "      <td>0.067858</td>\n",
       "      <td>0.067858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>19263</td>\n",
       "      <td>0.993889</td>\n",
       "      <td>0.003056</td>\n",
       "      <td>0.710634</td>\n",
       "      <td>0.289366</td>\n",
       "      <td>0.995269</td>\n",
       "      <td>0.000789</td>\n",
       "      <td>0.000789</td>\n",
       "      <td>0.084790</td>\n",
       "      <td>0.152535</td>\n",
       "      <td>0.152535</td>\n",
       "      <td>0.654546</td>\n",
       "      <td>0.057576</td>\n",
       "      <td>0.057576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>19314</td>\n",
       "      <td>0.992279</td>\n",
       "      <td>0.003861</td>\n",
       "      <td>0.710634</td>\n",
       "      <td>0.289366</td>\n",
       "      <td>0.910562</td>\n",
       "      <td>0.014906</td>\n",
       "      <td>0.014906</td>\n",
       "      <td>0.992941</td>\n",
       "      <td>0.001176</td>\n",
       "      <td>0.001176</td>\n",
       "      <td>0.962955</td>\n",
       "      <td>0.006174</td>\n",
       "      <td>0.006174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>19344</td>\n",
       "      <td>0.965538</td>\n",
       "      <td>0.017231</td>\n",
       "      <td>0.710634</td>\n",
       "      <td>0.289366</td>\n",
       "      <td>0.918670</td>\n",
       "      <td>0.013555</td>\n",
       "      <td>0.013555</td>\n",
       "      <td>0.065614</td>\n",
       "      <td>0.155731</td>\n",
       "      <td>0.155731</td>\n",
       "      <td>0.985806</td>\n",
       "      <td>0.002366</td>\n",
       "      <td>0.002366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>19865</td>\n",
       "      <td>0.997974</td>\n",
       "      <td>0.001013</td>\n",
       "      <td>0.710634</td>\n",
       "      <td>0.289366</td>\n",
       "      <td>0.697486</td>\n",
       "      <td>0.050419</td>\n",
       "      <td>0.050419</td>\n",
       "      <td>0.561581</td>\n",
       "      <td>0.073070</td>\n",
       "      <td>0.073070</td>\n",
       "      <td>0.511624</td>\n",
       "      <td>0.081396</td>\n",
       "      <td>0.081396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>19916</td>\n",
       "      <td>0.999211</td>\n",
       "      <td>0.000394</td>\n",
       "      <td>0.710634</td>\n",
       "      <td>0.289366</td>\n",
       "      <td>0.687806</td>\n",
       "      <td>0.052032</td>\n",
       "      <td>0.052032</td>\n",
       "      <td>0.997257</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.982960</td>\n",
       "      <td>0.002840</td>\n",
       "      <td>0.002840</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    patient_id  bowel_healthy  bowel_injury  extravasation_healthy  \\\n",
       "0          263       0.996290      0.001855               0.710634   \n",
       "1          394       0.998264      0.000868               0.710634   \n",
       "2          470       0.997663      0.001169               0.710634   \n",
       "3          766       0.997165      0.001417               0.710634   \n",
       "4          878       0.979931      0.010035               0.710634   \n",
       "5         1900       0.998812      0.000594               0.710634   \n",
       "6         2288       0.985826      0.007087               0.710634   \n",
       "7         2940       0.959369      0.020315               0.710634   \n",
       "8         2978       0.982794      0.008603               0.710634   \n",
       "9         3881       0.998970      0.000515               0.710634   \n",
       "10        4313       0.606005      0.196997               0.710634   \n",
       "11        4453       0.973713      0.013143               0.710634   \n",
       "12        4791       0.978631      0.010685               0.710634   \n",
       "13        4813       0.972244      0.013878               0.710634   \n",
       "14        5260       0.998154      0.000923               0.710634   \n",
       "15        5775       0.979184      0.010408               0.710634   \n",
       "16        5914       0.952633      0.023683               0.710634   \n",
       "17        6203       0.850832      0.074584               0.710634   \n",
       "18        6773       0.998456      0.000772               0.710634   \n",
       "19        8464       0.969015      0.015492               0.710634   \n",
       "20        8537       0.996471      0.001764               0.710634   \n",
       "21        8848       0.978988      0.010506               0.710634   \n",
       "22        9190       0.986072      0.006964               0.710634   \n",
       "23       10172       0.618591      0.190705               0.710634   \n",
       "24       11301       0.998071      0.000965               0.710634   \n",
       "25       11378       0.989860      0.005070               0.710634   \n",
       "26       12299       0.999220      0.000390               0.710634   \n",
       "27       13106       0.561644      0.219178               0.710634   \n",
       "28       13182       0.995607      0.002196               0.710634   \n",
       "29       13250       0.999010      0.000495               0.710634   \n",
       "30       13403       0.840666      0.079667               0.710634   \n",
       "31       13623       0.996785      0.001608               0.710634   \n",
       "32       14616       0.759020      0.120490               0.710634   \n",
       "33       14831       0.929942      0.035029               0.710634   \n",
       "34       14846       0.995472      0.002264               0.710634   \n",
       "35       15404       0.994900      0.002550               0.710634   \n",
       "36       15419       0.993021      0.003490               0.710634   \n",
       "37       15620       0.920579      0.039711               0.710634   \n",
       "38       16198       0.998401      0.000799               0.710634   \n",
       "39       16202       0.998905      0.000548               0.710634   \n",
       "40       16368       0.990521      0.004740               0.710634   \n",
       "41       16450       0.969446      0.015277               0.710634   \n",
       "42       16691       0.984319      0.007841               0.710634   \n",
       "43       17439       0.993817      0.003091               0.710634   \n",
       "44       19160       0.997487      0.001256               0.710634   \n",
       "45       19263       0.993889      0.003056               0.710634   \n",
       "46       19314       0.992279      0.003861               0.710634   \n",
       "47       19344       0.965538      0.017231               0.710634   \n",
       "48       19865       0.997974      0.001013               0.710634   \n",
       "49       19916       0.999211      0.000394               0.710634   \n",
       "\n",
       "    extravasation_injury  kidney_healthy  kidney_low  kidney_high  \\\n",
       "0               0.289366        0.896853    0.017191     0.017191   \n",
       "1               0.289366        0.499183    0.083470     0.083470   \n",
       "2               0.289366        0.967554    0.005408     0.005408   \n",
       "3               0.289366        0.929134    0.011811     0.011811   \n",
       "4               0.289366        0.943247    0.009459     0.009459   \n",
       "5               0.289366        0.996052    0.000658     0.000658   \n",
       "6               0.289366        0.341038    0.109827     0.109827   \n",
       "7               0.289366        0.894200    0.017633     0.017633   \n",
       "8               0.289366        0.880377    0.019937     0.019937   \n",
       "9               0.289366        0.939118    0.010147     0.010147   \n",
       "10              0.289366        0.944253    0.009291     0.009291   \n",
       "11              0.289366        0.969590    0.005068     0.005068   \n",
       "12              0.289366        0.987716    0.002047     0.002047   \n",
       "13              0.289366        0.990678    0.001554     0.001554   \n",
       "14              0.289366        0.966998    0.005500     0.005500   \n",
       "15              0.289366        0.358067    0.106989     0.106989   \n",
       "16              0.289366        0.875527    0.020745     0.020745   \n",
       "17              0.289366        0.898480    0.016920     0.016920   \n",
       "18              0.289366        0.953735    0.007711     0.007711   \n",
       "19              0.289366        0.648542    0.058576     0.058576   \n",
       "20              0.289366        0.733788    0.044369     0.044369   \n",
       "21              0.289366        0.974664    0.004223     0.004223   \n",
       "22              0.289366        0.948923    0.008513     0.008513   \n",
       "23              0.289366        0.813905    0.031016     0.031016   \n",
       "24              0.289366        0.949085    0.008486     0.008486   \n",
       "25              0.289366        0.338609    0.110232     0.110232   \n",
       "26              0.289366        0.919767    0.013372     0.013372   \n",
       "27              0.289366        0.222605    0.129566     0.129566   \n",
       "28              0.289366        0.980198    0.003300     0.003300   \n",
       "29              0.289366        0.930789    0.011535     0.011535   \n",
       "30              0.289366        0.638029    0.060329     0.060329   \n",
       "31              0.289366        0.416677    0.097220     0.097220   \n",
       "32              0.289366        0.667752    0.055375     0.055375   \n",
       "33              0.289366        0.856749    0.023875     0.023875   \n",
       "34              0.289366        0.928398    0.011934     0.011934   \n",
       "35              0.289366        0.757019    0.040497     0.040497   \n",
       "36              0.289366        0.786809    0.035532     0.035532   \n",
       "37              0.289366        0.771279    0.038120     0.038120   \n",
       "38              0.289366        0.897888    0.017019     0.017019   \n",
       "39              0.289366        0.976079    0.003987     0.003987   \n",
       "40              0.289366        0.674784    0.054203     0.054203   \n",
       "41              0.289366        0.978325    0.003612     0.003612   \n",
       "42              0.289366        0.998099    0.000317     0.000317   \n",
       "43              0.289366        0.917785    0.013703     0.013703   \n",
       "44              0.289366        0.913909    0.014349     0.014349   \n",
       "45              0.289366        0.995269    0.000789     0.000789   \n",
       "46              0.289366        0.910562    0.014906     0.014906   \n",
       "47              0.289366        0.918670    0.013555     0.013555   \n",
       "48              0.289366        0.697486    0.050419     0.050419   \n",
       "49              0.289366        0.687806    0.052032     0.052032   \n",
       "\n",
       "    liver_healthy  liver_low  liver_high  spleen_healthy  spleen_low  \\\n",
       "0        0.949229   0.008462    0.008462        0.996306    0.000616   \n",
       "1        0.988489   0.001919    0.001919        0.989036    0.001827   \n",
       "2        0.607766   0.065372    0.065372        0.775050    0.037492   \n",
       "3        0.995938   0.000677    0.000677        0.537997    0.077000   \n",
       "4        0.960277   0.006620    0.006620        0.386555    0.102241   \n",
       "5        0.013177   0.164471    0.164471        0.958792    0.006868   \n",
       "6        0.742488   0.042919    0.042919        0.102959    0.149507   \n",
       "7        0.914503   0.014249    0.014249        0.946050    0.008992   \n",
       "8        0.773608   0.037732    0.037732        0.626991    0.062168   \n",
       "9        0.944011   0.009331    0.009331        0.847058    0.025490   \n",
       "10       0.981201   0.003133    0.003133        0.999301    0.000117   \n",
       "11       0.920355   0.013274    0.013274        0.983908    0.002682   \n",
       "12       0.020406   0.163266    0.163266        0.096275    0.150621   \n",
       "13       0.002773   0.166204    0.166204        0.980938    0.003177   \n",
       "14       0.994712   0.000881    0.000881        0.569571    0.071738   \n",
       "15       0.629860   0.061690    0.061690        0.838052    0.026991   \n",
       "16       0.992704   0.001216    0.001216        0.041744    0.159709   \n",
       "17       0.805778   0.032370    0.032370        0.583135    0.069478   \n",
       "18       0.955381   0.007436    0.007436        0.884944    0.019176   \n",
       "19       0.930846   0.011526    0.011526        0.299795    0.116701   \n",
       "20       0.987947   0.002009    0.002009        0.984497    0.002584   \n",
       "21       0.021691   0.163052    0.163052        0.130534    0.144911   \n",
       "22       0.950477   0.008254    0.008254        0.993734    0.001044   \n",
       "23       0.392101   0.101316    0.101316        0.373220    0.104463   \n",
       "24       0.991023   0.001496    0.001496        0.034544    0.160909   \n",
       "25       0.960068   0.006655    0.006655        0.993807    0.001032   \n",
       "26       0.960669   0.006555    0.006555        0.669746    0.055042   \n",
       "27       0.789782   0.035036    0.035036        0.321041    0.113160   \n",
       "28       0.204501   0.132583    0.132583        0.615995    0.064001   \n",
       "29       0.968437   0.005260    0.005260        0.678876    0.053521   \n",
       "30       0.942020   0.009663    0.009663        0.987108    0.002149   \n",
       "31       0.901302   0.016450    0.016450        0.037338    0.160444   \n",
       "32       0.949503   0.008416    0.008416        0.808516    0.031914   \n",
       "33       0.999237   0.000127    0.000127        0.994714    0.000881   \n",
       "34       0.809329   0.031778    0.031778        0.984055    0.002657   \n",
       "35       0.986661   0.002223    0.002223        0.993195    0.001134   \n",
       "36       0.877434   0.020428    0.020428        0.380480    0.103253   \n",
       "37       0.427091   0.095485    0.095485        0.004421    0.165930   \n",
       "38       0.955783   0.007370    0.007370        0.508866    0.081856   \n",
       "39       0.940295   0.009951    0.009951        0.689830    0.051695   \n",
       "40       0.738740   0.043543    0.043543        0.972796    0.004534   \n",
       "41       0.876570   0.020572    0.020572        0.657591    0.057068   \n",
       "42       0.992650   0.001225    0.001225        0.893257    0.017790   \n",
       "43       0.978143   0.003643    0.003643        0.842179    0.026303   \n",
       "44       0.275750   0.120708    0.120708        0.592851    0.067858   \n",
       "45       0.084790   0.152535    0.152535        0.654546    0.057576   \n",
       "46       0.992941   0.001176    0.001176        0.962955    0.006174   \n",
       "47       0.065614   0.155731    0.155731        0.985806    0.002366   \n",
       "48       0.561581   0.073070    0.073070        0.511624    0.081396   \n",
       "49       0.997257   0.000457    0.000457        0.982960    0.002840   \n",
       "\n",
       "    spleen_high  \n",
       "0      0.000616  \n",
       "1      0.001827  \n",
       "2      0.037492  \n",
       "3      0.077000  \n",
       "4      0.102241  \n",
       "5      0.006868  \n",
       "6      0.149507  \n",
       "7      0.008992  \n",
       "8      0.062168  \n",
       "9      0.025490  \n",
       "10     0.000117  \n",
       "11     0.002682  \n",
       "12     0.150621  \n",
       "13     0.003177  \n",
       "14     0.071738  \n",
       "15     0.026991  \n",
       "16     0.159709  \n",
       "17     0.069478  \n",
       "18     0.019176  \n",
       "19     0.116701  \n",
       "20     0.002584  \n",
       "21     0.144911  \n",
       "22     0.001044  \n",
       "23     0.104463  \n",
       "24     0.160909  \n",
       "25     0.001032  \n",
       "26     0.055042  \n",
       "27     0.113160  \n",
       "28     0.064001  \n",
       "29     0.053521  \n",
       "30     0.002149  \n",
       "31     0.160444  \n",
       "32     0.031914  \n",
       "33     0.000881  \n",
       "34     0.002657  \n",
       "35     0.001134  \n",
       "36     0.103253  \n",
       "37     0.165930  \n",
       "38     0.081856  \n",
       "39     0.051695  \n",
       "40     0.004534  \n",
       "41     0.057068  \n",
       "42     0.017790  \n",
       "43     0.026303  \n",
       "44     0.067858  \n",
       "45     0.057576  \n",
       "46     0.006174  \n",
       "47     0.002366  \n",
       "48     0.081396  \n",
       "49     0.002840  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "85973879-266e-4203-9b3a-84cffd131afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157\n",
      "157\n",
      "0.7960391366745849\n"
     ]
    }
   ],
   "source": [
    "# metrics\n",
    "import sklearn\n",
    "class ParticipantVisibleError(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "def normalize_probabilities_to_one(df: pd.DataFrame, group_columns: list) -> pd.DataFrame:\n",
    "    # Normalize the sum of each row's probabilities to 100%.\n",
    "    # 0.75, 0.75 => 0.5, 0.5\n",
    "    # 0.1, 0.1 => 0.5, 0.5\n",
    "    row_totals = df[group_columns].sum(axis=1)\n",
    "    if row_totals.min() == 0:\n",
    "        raise ParticipantVisibleError('All rows must contain at least one non-zero prediction')\n",
    "    for col in group_columns:\n",
    "        df[col] /= row_totals\n",
    "    return df\n",
    "\n",
    "\n",
    "def score(solution: pd.DataFrame, submission: pd.DataFrame, row_id_column_name: str) -> float:\n",
    "    '''\n",
    "    Pseudocode:\n",
    "    1. For every label group (liver, bowel, etc):\n",
    "        - Normalize the sum of each row's probabilities to 100%.\n",
    "        - Calculate the sample weighted log loss.\n",
    "    2. Derive a new any_injury label by taking the max of 1 - p(healthy) for each label group\n",
    "    3. Calculate the sample weighted log loss for the new label group\n",
    "    4. Return the average of all of the label group log losses as the final score.\n",
    "    '''\n",
    "    del solution[row_id_column_name]\n",
    "    # del submission[row_id_column_name]\n",
    "\n",
    "    # Run basic QC checks on the inputs\n",
    "    if not pd.api.types.is_numeric_dtype(submission.values):\n",
    "        raise ParticipantVisibleError('All submission values must be numeric')\n",
    "\n",
    "    if not np.isfinite(submission.values).all():\n",
    "        raise ParticipantVisibleError('All submission values must be finite')\n",
    "\n",
    "    if solution.min().min() < 0:\n",
    "        raise ParticipantVisibleError('All labels must be at least zero')\n",
    "    if submission.min().min() < 0:\n",
    "        raise ParticipantVisibleError('All predictions must be at least zero')\n",
    "\n",
    "    # Calculate the label group log losses\n",
    "    binary_targets = ['bowel', 'extravasation']\n",
    "    triple_level_targets = ['kidney', 'liver', 'spleen']\n",
    "    all_target_categories = binary_targets + triple_level_targets\n",
    "\n",
    "    label_group_losses = []\n",
    " \n",
    "    for category in all_target_categories:\n",
    "        \n",
    "        if category in binary_targets:\n",
    "            col_group = [f'{category}_healthy', f'{category}_injury']\n",
    "        else:\n",
    "            col_group = [f'{category}_healthy', f'{category}_low', f'{category}_high']\n",
    "\n",
    "        solution = normalize_probabilities_to_one(solution, col_group)\n",
    "\n",
    "        for col in col_group:\n",
    "            if col not in submission.columns:\n",
    "                raise ParticipantVisibleError(f'Missing submission column {col}')\n",
    "        submission = normalize_probabilities_to_one(submission, col_group)\n",
    "\n",
    "        label_group_losses.append(\n",
    "            sklearn.metrics.log_loss(\n",
    "                y_true=solution[col_group].values,\n",
    "                y_pred=submission[col_group].values,\n",
    "                sample_weight=solution[f'{category}_weight'].values\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Derive a new any_injury label by taking the max of 1 - p(healthy) for each label group\n",
    "    healthy_cols = [x + '_healthy' for x in all_target_categories]\n",
    "    any_injury_labels = (1 - solution[healthy_cols]).max(axis=1)\n",
    "    any_injury_predictions = (1 - submission[healthy_cols]).max(axis=1)\n",
    "    any_injury_loss = sklearn.metrics.log_loss(\n",
    "        y_true=any_injury_labels.values,\n",
    "        y_pred=any_injury_predictions.values,\n",
    "        sample_weight=solution['any_injury_weight'].values\n",
    "    )\n",
    "\n",
    "    label_group_losses.append(any_injury_loss)\n",
    "    return np.mean(label_group_losses)\n",
    "\n",
    "\n",
    "# Assign the appropriate weights to each category\n",
    "def create_training_solution(y_train):\n",
    "    sol_train = y_train.copy()\n",
    "    \n",
    "    # bowel healthy|injury sample weight = 1|2\n",
    "    sol_train['bowel_weight'] = np.where(sol_train['bowel_injury'] == 1, 2, 1)\n",
    "    \n",
    "    # extravasation healthy/injury sample weight = 1|6\n",
    "    sol_train['extravasation_weight'] = np.where(sol_train['extravasation_injury'] == 1, 6, 1)\n",
    "    \n",
    "    # kidney healthy|low|high sample weight = 1|2|4\n",
    "    sol_train['kidney_weight'] = np.where(sol_train['kidney_low'] == 1, 2, np.where(sol_train['kidney_high'] == 1, 4, 1))\n",
    "    \n",
    "    # liver healthy|low|high sample weight = 1|2|4\n",
    "    sol_train['liver_weight'] = np.where(sol_train['liver_low'] == 1, 2, np.where(sol_train['liver_high'] == 1, 4, 1))\n",
    "    \n",
    "    # spleen healthy|low|high sample weight = 1|2|4\n",
    "    sol_train['spleen_weight'] = np.where(sol_train['spleen_low'] == 1, 2, np.where(sol_train['spleen_high'] == 1, 4, 1))\n",
    "    \n",
    "    # any healthy|injury sample weight = 1|6\n",
    "    sol_train['any_injury_weight'] = np.where(sol_train['any_injury'] == 1, 6, 1)\n",
    "    return sol_train\n",
    "\n",
    "\n",
    "df1 = pd.read_csv('data/train.csv')\n",
    "df1 = pd.merge(df1, valid_, on='patient_id', how='inner')\n",
    "df1 = create_training_solution(df1)\n",
    "print(len(df1))\n",
    "print(len(sub_df))\n",
    "score = score(df1, sub_df, 'patient_id')\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4cc774e4-40b5-4e74-98be-0f14a7fc3537",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data1/ocr_ie/anaconda3/envs/rsna/lib/python3.8/site-packages/timm/models/_factory.py:114: UserWarning: Mapping deprecated model name tf_efficientnetv2_s_in21ft1k to current tf_efficientnetv2_s.in21k_ft_in1k.\n",
      "  model = create_fn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load cls_model succesfull for 1 models!\n"
     ]
    }
   ],
   "source": [
    "from itertools import repeat\n",
    "\n",
    "\n",
    "class SpatialDropout(nn.Module):\n",
    "    def __init__(self, drop=0.5):\n",
    "        super(SpatialDropout, self).__init__()\n",
    "        self.drop = drop\n",
    "        \n",
    "    def forward(self, inputs, noise_shape=None):\n",
    "        \"\"\"\n",
    "        @param: inputs, tensor\n",
    "        @param: noise_shape, tuple\n",
    "        \"\"\"\n",
    "        outputs = inputs.clone()\n",
    "        if noise_shape is None:\n",
    "            noise_shape = (inputs.shape[0], *repeat(1, inputs.dim()-2), inputs.shape[-1]) \n",
    "        \n",
    "        self.noise_shape = noise_shape\n",
    "        if not self.training or self.drop == 0:\n",
    "            return inputs\n",
    "        else:\n",
    "            noises = self._make_noises(inputs)\n",
    "            if self.drop == 1:\n",
    "                noises.fill_(0.0)\n",
    "            else:\n",
    "                noises.bernoulli_(1 - self.drop).div_(1 - self.drop)\n",
    "            noises = noises.expand_as(inputs)    \n",
    "            outputs.mul_(noises)\n",
    "            return outputs\n",
    "            \n",
    "    def _make_noises(self, inputs):\n",
    "        return inputs.new().resize_(self.noise_shape)\n",
    "\n",
    "\n",
    "class MLPAttentionNetwork(nn.Module):\n",
    " \n",
    "    def __init__(self, hidden_dim, attention_dim=None):\n",
    "        super(MLPAttentionNetwork, self).__init__()\n",
    " \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.attention_dim = attention_dim\n",
    "        if self.attention_dim is None:\n",
    "            self.attention_dim = self.hidden_dim\n",
    "        # W * x + b\n",
    "        self.proj_w = nn.Linear(self.hidden_dim, self.attention_dim, bias=True)\n",
    "        # v.T\n",
    "        self.proj_v = nn.Linear(self.attention_dim, 1, bias=False)\n",
    " \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        :param x: seq_len, batch_size, hidden_dim\n",
    "        :return: batch_size * seq_len, batch_size * hidden_dim\n",
    "        \"\"\"\n",
    "        # print(f\"x shape:{x.shape}\")\n",
    "        batch_size, seq_len, _ = x.size()\n",
    "        # flat_inputs = x.reshape(-1, self.hidden_dim) # (batch_size*seq_len, hidden_dim)\n",
    "        # print(f\"flat_inputs shape:{flat_inputs.shape}\")\n",
    "        \n",
    "        H = torch.tanh(self.proj_w(x)) # (batch_size, seq_len, hidden_dim)\n",
    "        # print(f\"H shape:{H.shape}\")\n",
    "        \n",
    "        att_scores = torch.softmax(self.proj_v(H),axis=1) # (batch_size, seq_len)\n",
    "        # print(f\"att_scores shape:{att_scores.shape}\")\n",
    "        \n",
    "        attn_x = (x * att_scores).sum(1) # (batch_size, hidden_dim)\n",
    "        # print(f\"attn_x shape:{attn_x.shape}\")\n",
    "        return attn_x\n",
    "\n",
    "class TimmModel2(nn.Module):\n",
    "    def __init__(self, backbone, pretrained=False):\n",
    "        super().__init__()\n",
    "        self.encoder = timm.create_model(\n",
    "            backbone,\n",
    "            in_chans=CFG.in_chans,\n",
    "            num_classes=CFG.out_dim,\n",
    "            features_only=False,\n",
    "            drop_rate=CFG.drop_rate,\n",
    "            drop_path_rate=CFG.drop_path_rate,\n",
    "            pretrained=pretrained\n",
    "        )\n",
    "        \n",
    "        hdim = self.encoder.conv_head.out_channels\n",
    "        self.encoder.classifier = nn.Identity()\n",
    "        \n",
    "        self.spatialdropout = SpatialDropout(CFG.dropout)\n",
    "        self.gru = nn.GRU(hdim, 256, 2, batch_first=True, bidirectional=True)\n",
    "        self.mlp_attention_layer = MLPAttentionNetwork(512)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(0),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(256, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):  # (bs, nslice, ch, sz, sz)\n",
    "        bs = x.shape[0]\n",
    "        x = x.view(bs * CFG.n_slice_per_c, CFG.in_chans, CFG.image_size_cls, CFG.image_size_cls)\n",
    "        feat = self.encoder(x)\n",
    "        feat = self.spatialdropout(feat)\n",
    "        feat = feat.view(bs, CFG.n_slice_per_c, -1)\n",
    "        feat, _ = self.gru(feat)\n",
    "        feat = self.mlp_attention_layer(feat) # [bs, 512]\n",
    "        # feat = feat.contiguous().view(bs * CFG.n_slice_per_c, -1)\n",
    "        feat = self.head(feat)\n",
    "        # feat = feat.view(bs, CFG.n_slice_per_c).contiguous()\n",
    "        # feat = self.mean_layer(feat)\n",
    "        feat = feat.view(bs, -1)\n",
    "        return feat\n",
    "\n",
    "\n",
    "# load cls model\n",
    "model_cls_path = 'weights'\n",
    "cls_models = []\n",
    "\n",
    "for idx_fold in range(1):\n",
    "    cls_model = TimmModel2(CFG.backbone_cls, pretrained=False)\n",
    "    load_cls_model_file = os.path.join(model_cls_path, f'filter_stage2_tf_efficientnetv2_s_in21ft1k_fold{idx_fold}_best_078.pth')\n",
    "    sd = torch.load(load_cls_model_file, map_location='cpu')\n",
    "    if 'model_state_dict' in sd.keys():\n",
    "        sd = sd['model_state_dict']\n",
    "    sd = {k[7:] if k.startswith('module.') else k: sd[k] for k in sd.keys()}\n",
    "    cls_model.load_state_dict(sd, strict=True)\n",
    "    cls_model = cls_model.to(device)\n",
    "    cls_model.eval()\n",
    "    cls_models.append(cls_model)\n",
    "print(f'load cls_model succesfull for {len(cls_models)} models!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dc823981-43d4-4837-928e-8a677e6fcaa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bowel\n",
      "      patient_id  study_id  bowel  kidney  liver  spleen  cid  fold\n",
      "6985       27289     24214      0       0      0       0    4     3\n",
      "torch.Size([1, 15, 6, 224, 224])\n",
      "pred: ====> tensor([[-5.1040]], device='cuda:0', grad_fn=<ViewBackward0>)\n",
      "logits: ====> [[0.00603601]]\n",
      "0.0060360073\n",
      "final label: ====> healthy\n"
     ]
    }
   ],
   "source": [
    "# prediction\n",
    "map_cls = {0: 'liver', 1: 'spleen', 2: 'kidney', 3: 'kidney', 4: 'bowel'}\n",
    "final_label = {0: 'healthy', 1: 'injury'}\n",
    "ww_df = pd.read_csv('data/stage1/train_cls.csv')\n",
    "# val\n",
    "# patient_id = 10937\n",
    "# study_id = 53000\n",
    "patient_id = 27289\n",
    "study_id = 24214\n",
    "cid = 4\n",
    "label = map_cls[cid]\n",
    "print(label)\n",
    "s1 = ww_df['patient_id'] == patient_id\n",
    "s2 = ww_df['study_id'] == study_id\n",
    "s3 = ww_df['cid'] == cid\n",
    "s = s1 & s2 & s3\n",
    "row = ww_df[s]\n",
    "print(row)\n",
    "label = row[label].values.tolist()[0]\n",
    "\n",
    "\n",
    "transforms_valid = albumentations.Compose([\n",
    "    albumentations.Resize(CFG.image_size_cls, CFG.image_size_cls),\n",
    "])\n",
    "\n",
    "images = []\n",
    "for nid in range(15):\n",
    "    image = np.load(f\"data/stage1/crop/{patient_id}_{study_id}_{cid}_{nid}.npy\")\n",
    "    image = transforms_valid(image=image)['image']\n",
    "    image = image.transpose(2, 0, 1).astype(np.float32) / 255.\n",
    "    images.append(image)\n",
    "\n",
    "images = np.stack(images, 0)\n",
    "images = torch.tensor(images).float()\n",
    "images = images.unsqueeze(0)\n",
    "images = images.to(CFG.device)\n",
    "print(images.shape)\n",
    "logits = cls_model(images)\n",
    "print('pred: ====>', logits)\n",
    "logits = logits.sigmoid().detach().cpu().numpy()\n",
    "print('logits: ====>', logits)\n",
    "print(logits.mean())\n",
    "print('final label: ====>', final_label[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02d0354b-4aaf-42a2-9a96-1d34389a1520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>study_id</th>\n",
       "      <th>bowel</th>\n",
       "      <th>kidney</th>\n",
       "      <th>liver</th>\n",
       "      <th>spleen</th>\n",
       "      <th>cid</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10004</td>\n",
       "      <td>51033</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10004</td>\n",
       "      <td>51033</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10004</td>\n",
       "      <td>51033</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10004</td>\n",
       "      <td>51033</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10004</td>\n",
       "      <td>51033</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient_id  study_id  bowel  kidney  liver  spleen  cid  fold\n",
       "0       10004     51033      0       1      0       1    0     4\n",
       "1       10004     51033      0       1      0       1    1     4\n",
       "2       10004     51033      0       1      0       1    2     4\n",
       "3       10004     51033      0       1      0       1    3     4\n",
       "4       10004     51033      0       1      0       1    4     4"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data/stage1/train_cls.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9d13563-395a-401b-96e7-dbc74d8b4c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = df[df['fold'] == 0]\n",
    "train_df = pd.read_csv('data/train.csv')\n",
    "sub_df = pd.merge(train_df, sub_df, on='patient_id', how='inner')\n",
    "sub_df = sub_df.groupby('patient_id').mean().reset_index()\n",
    "sub_df = sub_df.drop(['bowel', 'kidney', 'liver', 'spleen'], axis=1)\n",
    "sub_df.to_csv('data/stage1/fold0_offical.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a9fa2f-9491-40de-bfcc-63d2b51630fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
